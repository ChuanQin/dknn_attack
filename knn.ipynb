{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from skimage.transform import resize\n",
    "from imageio import imread, imwrite\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "from lib.utils import load_gtsrb\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[:, :, :, np.newaxis] / 255.\n",
    "X_test = X_test[:, :, :, np.newaxis] / 255.\n",
    "# y_train = y_train[:, np.newaxis]\n",
    "# y_test = y_test[:, np.newaxis]\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nn(Q, X, k):\n",
    "    assert Q.shape[1:] == X.shape[1:]\n",
    "    nn = np.zeros((len(Q), k), dtype=np.int32)\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    for i, q in enumerate(Q):\n",
    "        ind = np.argsort(np.sum((X - q)**2, axis=axis))[:k]\n",
    "        nn[i] = ind\n",
    "    return nn\n",
    "\n",
    "\n",
    "def classify(nn, y_X):\n",
    "    vote = np.array([np.argmax(np.bincount(y)) for y in y_X[nn]])\n",
    "    return vote\n",
    "\n",
    "\n",
    "def find_acc(nn, y_Q, y_X):\n",
    "    vote = classify(nn, y_X)\n",
    "    print(np.mean(vote == y_Q))\n",
    "    \n",
    "    \n",
    "def find_nn_diff_class(Q, y_Q, X, y_X, k):\n",
    "    target = np.zeros((len(Q), k), dtype=np.int32)\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    for i, (q, y_q) in enumerate(zip(Q, y_Q)):\n",
    "        ind = np.argsort(np.sum((X - q)**2, axis=axis))\n",
    "        target[i] = ind[y_X[ind] != y_q][:k]\n",
    "    return target\n",
    "\n",
    "\n",
    "def move_to_target(q, y_q, target, X, y_X, k, n_steps=5):\n",
    "    \"\"\"\n",
    "    Move in straight line to target with binary search.\n",
    "    Stop when adv is misclassified.\n",
    "    \"\"\"\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    line = target - q\n",
    "    hi = 1\n",
    "    lo = 0\n",
    "    adv = None\n",
    "    for step in range(n_steps):\n",
    "        mid = (hi + lo)/2\n",
    "        x_new = mid*line + q\n",
    "        new_neighbors = np.argsort(np.sum((X - x_new)**2, axis=axis))[:k]\n",
    "        y_pred = np.argmax(np.bincount(y_X[new_neighbors]))\n",
    "        if y_pred == y_q:\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "            adv = x_new\n",
    "    return adv\n",
    "            \n",
    "    \n",
    "def attack_v2(Q, y_Q, X, y_X, k, n_steps=5):\n",
    "    \"\"\"\n",
    "    Naive attack v2 (untargeted): \n",
    "    Complexity is O(k * n_X log (n_X) * n_Q * n_steps)\n",
    "    \n",
    "    1. Choose trianing sample of target class from X closest to query\n",
    "    2. Find closest sample of the same class to the mean of K\n",
    "    3. Add that sample to K\n",
    "    4. Repeat 2. - 3. until |K| = k/2 + 1\n",
    "    5. Move query closer to mean of K, terminate when query becomes\n",
    "       adversarial\n",
    "    \"\"\"\n",
    "    \n",
    "    nn = find_nn_diff_class(Q, y_Q, X, y_X, 1)\n",
    "    X_adv = np.zeros_like(Q)\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    \n",
    "    for i, (q, y_q) in enumerate(zip(Q, y_Q)):\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        n_neighbors = int(np.floor(k/2) + 1)\n",
    "        K = np.zeros((n_neighbors, ) + Q.shape[1:])\n",
    "                    \n",
    "        # Step 1.\n",
    "        K[0] = X[nn[i, 0]]\n",
    "        K_ind = [nn[i, 0]]\n",
    "\n",
    "        for j in range(1, n_neighbors):\n",
    "            \n",
    "            # Step 2.\n",
    "            mean = np.mean(K[:j], axis=0)\n",
    "            ind = np.argsort(np.sum((X - mean)**2, axis=axis))\n",
    "            new_nbs = ind[y_X[ind] != y_q]\n",
    "            \n",
    "            # Step 3.\n",
    "            for new_nb in new_nbs:\n",
    "                if new_nb not in K_ind:\n",
    "                    K_ind.append(new_nb)\n",
    "                    K[j] = X[new_nb]\n",
    "                    break\n",
    "                    \n",
    "        # Step 5.\n",
    "        mean = np.mean(K, axis=0)\n",
    "        X_adv[i] = move_to_target(q, y_q, mean, X, y_X, k, n_steps)\n",
    "        \n",
    "    return X_adv\n",
    "\n",
    "\n",
    "def attack_v3(Q, y_Q, X, y_X, k, n_repeats=100, n_steps=5):\n",
    "    \"\"\"\n",
    "    Naive attack v2 (untargeted): greeedy\n",
    "    Complexity is O(n_repeats * k * n_X * n_Q)\n",
    "    \n",
    "    1. Choose trianing sample of target class from X closest to query\n",
    "    2. Find closest sample of the same class to the mean of K\n",
    "    3. Add that sample to K\n",
    "    4. Repeat 2. - 3. until |K| = k/2 + 1\n",
    "    5. Move query closer to mean of K, terminate when query becomes\n",
    "       adversarial\n",
    "    6. Repeat 1. - 5. for n_repeats times\n",
    "    \"\"\"\n",
    "    \n",
    "    nn = find_nn_diff_class(Q, y_Q, X, y_X, 1)\n",
    "    X_adv = np.zeros_like(Q)\n",
    "    \n",
    "    for i, (q, y_q) in enumerate(zip(Q, y_Q)):\n",
    "        \n",
    "        n_neighbors = int(np.floor(k/2) + 1)\n",
    "        K = np.zeros((n_neighbors, ) + Q.shape[1:])\n",
    "        best_dist = 1e9\n",
    "        best_adv = None\n",
    "        \n",
    "        for _ in range(n_repeats):\n",
    "            \n",
    "            # Step 1.\n",
    "            K[0] = X[nn[i, 0]]\n",
    "            \n",
    "            for j in range(1, n_neighbors):\n",
    "                \n",
    "                # Step 2.\n",
    "                mean = np.mean(K[:j])\n",
    "                ind = np.argsort(np.sum((X - mean)**2, axis=(1, 2, 3)))\n",
    "                new_nb = ind[y_X[ind] != y_q][0]\n",
    "                \n",
    "                # Step 3.\n",
    "                K[j] = X[new_nb]\n",
    "                \n",
    "            # Step 5.\n",
    "            mean = np.mean(K)\n",
    "            adv = move_to_target(q, y_q, mean, X, y_X, k, n_steps)\n",
    "            if adv is not None:\n",
    "                dist = np.sqrt(np.sum((adv - q)**2))\n",
    "                if dist < best_dist:\n",
    "                    best_dist = dist\n",
    "                    best_adv = adv\n",
    "            \n",
    "        X_adv[i] = best_adv\n",
    "        \n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One NN with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "\n",
    "X_3 = X_train[y_train == 3]\n",
    "X_7 = X_train[y_train == 7]\n",
    "X_37 = X_train[(y_train == 3) | (y_train == 7)]\n",
    "y_37 = y_train[(y_train == 3) | (y_train == 7)]\n",
    "X_37_test = X_test[(y_test == 3) | (y_test == 7)]\n",
    "y_37_test = y_test[(y_test == 3) | (y_test == 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = np.zeros((len(X_37_test,)), dtype=np.int32)\n",
    "for i, x in enumerate(X_37_test):\n",
    "    ind = np.argmin(np.sum((X_37 - x)**2, axis=(1, 2, 3)))\n",
    "    nn[i] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946025515210991"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_37[nn] == y_37_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trivial attack for k = 1.  \n",
    "1) Find closest sample of target class  \n",
    "2) Do a line search on the line between a sample and its closest sample of target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.zeros((len(X_37_test,)), dtype=np.int32)\n",
    "for i, (x, y) in enumerate(zip(X_37_test, y_37_test)):\n",
    "    ind = np.argsort(np.sum((X_37 - x)**2, axis=(1, 2, 3)))\n",
    "    target[i] = ind[y_37[ind] != y_37_test[i]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "n_steps = 5\n",
    "adv = np.zeros_like(X_37_test)\n",
    "\n",
    "for i, (x, y) in enumerate(zip(X_37_test, y_37_test)):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    line = X_37[target[i]] - x\n",
    "    hi = 1\n",
    "    lo = 0\n",
    "    for step in range(n_steps):\n",
    "        mid = (hi + lo)/2\n",
    "        x_new = mid * line + x\n",
    "        new_neighbor = np.argmin(np.sum((X_37 - x_new)**2, axis=(1, 2, 3)))\n",
    "        if y_37[new_neighbor] == y:\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "            adv[i] = x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_adv = np.zeros((len(X_37_test,)), dtype=np.int32)\n",
    "for i, x in enumerate(adv):\n",
    "    ind = np.argmin(np.sum((X_37 - x)**2, axis=(1, 2, 3)))\n",
    "    nn_adv[i] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_37[nn_adv] == y_37_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.001860962268607\n"
     ]
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((X_37_test - adv)**2, axis=(1, 2, 3)))\n",
    "print(np.mean(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.239598717944386\n"
     ]
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((X_37_test - X_37[target])**2, axis=(1, 2, 3)))\n",
    "print(np.mean(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADcJJREFUeJzt3X+MHHUZx/HP0/PaYlsIP+QsUG3BUq2o1ZxVBA1aUSSQQkwa+gcpihyJEEWJAWrUJiSmwR8EfyGHNLRGK4oQmlgVLEY0QuXAAsUqrc0BLdc7agkUq+31+vjHTslZbr677M7u7PV5v5LL7s4zs/Nk4NPZ3e/ufM3dBSCeCWU3AKAchB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCva+XOJtokn6wprdwlEMp/9W/t871Wy7oNhd/MzpF0k6QOST9y9+Wp9Sdrit5nCxrZJYCE9b6u5nXrftlvZh2Svi/pE5LmSlpsZnPrfT4ArdXIe/75kra4+1Z33yfpZ5IWFtMWgGZrJPwnSnp21ONt2bL/Y2Y9ZtZnZn3D2tvA7gAUqemf9rt7r7t3u3t3pyY1e3cAatRI+LdLmjHq8UnZMgDjQCPhf1jSbDObZWYTJV0kaU0xbQFotrqH+tx9v5ldKem3qgz1rXD3JwvrDEBTNTTO7+5rJa0tqBcALcTXe4GgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiqoVl6zaxf0m5JI5L2u3t3EU0BaL6Gwp/5sLvvLOB5ALQQL/uBoBoNv0u618weMbOeIhoC0BqNvuw/0923m9nxku4zs7+7+wOjV8j+UeiRpMl6fYO7A1CUhs787r49ux2SdLek+WOs0+vu3e7e3alJjewOQIHqDr+ZTTGzaQfvS/qYpI1FNQaguRp52d8l6W4zO/g8P3X33xTSFYCmqzv87r5V0rsK7AVACzHUBwRF+IGgCD8QFOEHgiL8QFCEHwiqiF/14TA2ctZ7kvX+8ycm6298+1Bu7Q/vuLOung469f5Lk/U5n+vPrY288EJD+z4ccOYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5x8H7HVV/jO9a05uaeDMo5KbHnf+tmR99ZzvJuvHTjgiWT8gT9Qa8/eP/ChZP+/OhfnFBYzzc+YHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY528Dm1elfzP/ydP+mqx/vWtVke0cYnJDWw/7SG5t54F96T1X5oTIdfSEdG/Xn3x3bu0rem9y2wg48wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFXH+c1shaTzJA25+2nZsmMk3SFppqR+SYvcnR9I1+kXH/xhsv7OiR0t6uTVvvDcB5L1e7e8NVk/dk3+7/2PXP1Qcttt16X3veHK9LUGkFbLmf92SeccsuxaSevcfbakddljAONI1fC7+wOSdh2yeKGkldn9lZIuKLgvAE1W73v+LncfyO7vkNRVUD8AWqThD/zc3aX8C7WZWY+Z9ZlZ37D2Nro7AAWpN/yDZjZdkrLb3NkY3b3X3bvdvbtTk+rcHYCi1Rv+NZKWZPeXSLqnmHYAtErV8JvZakkPSppjZtvM7FJJyyWdbWabJX00ewxgHKk6zu/ui3NKCwruBU3w6z3TkvUv3bEkWZ91/aPp+t7HXnNPB3XMPjlZ/8Nnv1HlGdK/51/Wn7huv56r8tyHP77hBwRF+IGgCD8QFOEHgiL8QFCEHwiKS3e3gU9/56pk/aW3DSfrRzzbmVubtaI/ue3M7Q8m6/kTbNdm16dOz619ZenK3JokHVXl0tzVPPurmbm1Exjq48wPREX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzt8G3njjn9P1Bp57fwPb1uKZr6Yvr33/Z27IrR3XkX9Z71psGk5//2HG2p25tfyJw+PgzA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHOH1zHqack688sT/+mfuP7vpesH1BjY/kp133komR9ZOtTTdv34YAzPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXWc38xWSDpP0pC7n5YtWybpMknPZ6stdfe1zWoSaR1HHplbG7zo7cltv3j1z5P1RVOHquzdqtTzPTW8L1nv+VJ6PoNpzzxS975R25n/dknnjLH8Rnefl/0RfGCcqRp+d39A0q4W9AKghRp5z3+lmT1uZivM7OjCOgLQEvWG/2ZJp0iaJ2lA0rfyVjSzHjPrM7O+Ye2tc3cAilZX+N190N1H3P2ApFslzU+s2+vu3e7e3alJ9fYJoGB1hd/Mpo96eKGkjcW0A6BVahnqWy3pLEnHmdk2SV+TdJaZzVNlBud+SZc3sUcATVA1/O6+eIzFtzWhF9Rpyy2zcmtPfij9e/tm+9TTC3JrOz93UnLbqX3rk3WvqyMcxDf8gKAIPxAU4QeCIvxAUIQfCIrwA0Fx6e7DwKzj/5Vbm9DAT25r0WHp88euS47NrflTfDesTJz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvkPAzt2T8utDYzsSW57/56ZyfriaYPpnfuBdB1tizM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOP9h4KQrXsytffrNVyS33XPC5GR98U0/SNbv+88Rybq99HKyjvJw5geCIvxAUIQfCIrwA0ERfiAowg8ERfiBoKqO85vZDEmrJHWpMityr7vfZGbHSLpD0kxJ/ZIWufsLzWsVefZvfy63ZomaJA3ecHpD+7598Ixkff+OKtcDQGlqOfPvl3S1u8+V9H5JV5jZXEnXSlrn7rMlrcseAxgnqobf3Qfc/dHs/m5JmySdKGmhpJXZaislXdCsJgEU7zW95zezmZLeLWm9pC53H8hKO1R5WwBgnKg5/GY2VdIvJV3l7i+Nrrm7q/J5wFjb9ZhZn5n1DWtvQ80CKE5N4TezTlWC/xN3vytbPGhm07P6dElDY23r7r3u3u3u3Z2aVETPAApQNfxmZpJuk7TJ3b89qrRG0pLs/hJJ9xTfHoBmqeUnvWdIuljSE2a2IVu2VNJyST83s0slPS1pUXNaRCP+dVl6KO/WT97S0POvf+wtyfqp+ktDz4/mqRp+d/+TlDvJ+4Ji2wHQKnzDDwiK8ANBEX4gKMIPBEX4gaAIPxAUl+4eDyZ0JMs7L5ufW7vxmpuT254+aSRZf+HAf5P1udc/k6zvT1ZRJs78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/zjQP/1+eP4krTxku81bd+n33l1sv6WgYeatm80F2d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf5x4OLzf9+0577txTcl63N+MOZETK9IXw0A7YwzPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXWc38xmSFolqUuSS+p195vMbJmkyyQ9n6261N3XNqtR1KfaOP6Pv3Zesj518/oi20EbqeVLPvslXe3uj5rZNEmPmNl9We1Gd/9m89oD0CxVw+/uA5IGsvu7zWyTpBOb3RiA5npN7/nNbKakd0s6+FrwSjN73MxWmNnROdv0mFmfmfUNa29DzQIoTs3hN7Opkn4p6Sp3f0nSzZJOkTRPlVcG3xprO3fvdfdud+/u1KQCWgZQhJrCb2adqgT/J+5+lyS5+6C7j7j7AUm3SkpfZRJAW6kafjMzSbdJ2uTu3x61fPqo1S6UtLH49gA0Sy2f9p8h6WJJT5jZhmzZUkmLzWyeKsN//ZIub0qHqGrx1o/n1vb0jPlRzCumbmIoL6paPu3/kyQbo8SYPjCO8Q0/ICjCDwRF+IGgCD8QFOEHgiL8QFBcunsc+OM7J1dZY2edNUTGmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgjJ3b93OzJ6X9PSoRcepfQei27W3du1Lord6Fdnbm939DbWs2NLwv2rnZn3u3l1aAwnt2lu79iXRW73K6o2X/UBQhB8Iquzw95a8/5R27a1d+5LorV6l9Fbqe34A5Sn7zA+gJKWE38zOMbN/mNkWM7u2jB7ymFm/mT1hZhvMrK/kXlaY2ZCZbRy17Bgzu8/MNme36Wtzt7a3ZWa2PTt2G8zs3JJ6m2Fmvzezv5nZk2b2+Wx5qccu0Vcpx63lL/vNrEPSU5LOlrRN0sOSFrv731raSA4z65fU7e6ljwmb2YckvSxplbufli27QdIud1+e/cN5tLtf0ya9LZP0ctkzN2cTykwfPbO0pAskXaISj12ir0Uq4biVceafL2mLu291932SfiZpYQl9tD13f0DSrkMWL5S0Mru/UpX/eVoup7e24O4D7v5odn+3pIMzS5d67BJ9laKM8J8o6dlRj7epvab8dkn3mtkjZtZTdjNj6MqmTZekHZK6ymxmDFVnbm6lQ2aWbptjV8+M10XjA79XO9Pd3yPpE5KuyF7etiWvvGdrp+GammZubpUxZpZ+RZnHrt4Zr4tWRvi3S5ox6vFJ2bK24O7bs9shSXer/WYfHjw4SWp2O1RyP69op5mbx5pZWm1w7Nppxusywv+wpNlmNsvMJkq6SNKaEvp4FTObkn0QIzObIuljar/Zh9dIWpLdXyLpnhJ7+T/tMnNz3szSKvnYtd2M1+7e8j9J56ryif8/JX25jB5y+jpZ0mPZ35Nl9yZptSovA4dV+WzkUknHSlonabOk30k6po16+7GkJyQ9rkrQppfU25mqvKR/XNKG7O/cso9doq9Sjhvf8AOC4gM/ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB/Q+tGyBOvYxXKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "plt.imshow(X_37_test[i, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(adv[i, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(X_37[nn_adv[i], :, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## kNN with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941118743866536\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "nn = find_nn(X_37_test, X_37, k)\n",
    "find_acc(nn, y_37_test, y_37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "X_adv = attack_v2(X_37_test, y_37_test, \n",
    "                  X_37, y_37, \n",
    "                  k, n_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Check if any is None\n",
    "print(np.where(X_adv == None))\n",
    "\n",
    "nn_adv = find_nn(X_adv, X_37, k)\n",
    "find_acc(nn_adv, y_37_test, y_37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.905456878324329\n"
     ]
    }
   ],
   "source": [
    "dist = np.sqrt(np.sum((X_37_test - X_adv)**2, axis=(1, 2, 3)))\n",
    "print(np.mean(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "plt.imshow(X_37_test[i, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(X_adv[i, :, :, 0])\n",
    "plt.show()\n",
    "for nn_adv_k in nn_adv[i]:\n",
    "    plt.imshow(X_37[nn_adv_k, :, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## k-NN on 1st-Layer Representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1710 - acc: 0.9490 - val_loss: 0.0559 - val_acc: 0.9825\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0466 - acc: 0.9859 - val_loss: 0.0381 - val_acc: 0.9889\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0326 - acc: 0.9892 - val_loss: 0.0353 - val_acc: 0.9893\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0225 - acc: 0.9931 - val_loss: 0.0299 - val_acc: 0.9902\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0323 - val_acc: 0.9907\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0319 - val_acc: 0.9895\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0113 - acc: 0.9964 - val_loss: 0.0434 - val_acc: 0.9882\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0092 - acc: 0.9968 - val_loss: 0.0441 - val_acc: 0.9893\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0426 - val_acc: 0.9883\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0391 - val_acc: 0.9891\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0401 - val_acc: 0.9889\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0421 - val_acc: 0.9889\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0387 - val_acc: 0.9914\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0397 - val_acc: 0.9914\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0373 - val_acc: 0.9924\n",
      "10000/10000 [==============================] - 1s 79us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03731346611475783, 0.9924]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, Input, Activation\n",
    "\n",
    "inpt = Input(shape=(28, 28, 1))\n",
    "l1 = Conv2D(64, (8, 8), strides=(2, 2), padding='same', activation='relu')(inpt)\n",
    "l2 = Conv2D(128, (6, 6), strides=(2, 2), padding='same', activation='relu')(l1)\n",
    "l3 = Conv2D(128, (5, 5), strides=(1, 1), padding='valid', activation='relu')(l2)\n",
    "flat = Flatten()(l3)\n",
    "l4 = Dense(10, activation=None)(flat)\n",
    "out = Activation('softmax')(l4)\n",
    "\n",
    "model = Model(inputs=inpt, outputs=out)\n",
    "l1_rep = Model(inputs=inpt, outputs=l1)\n",
    "l2_rep = Model(inputs=inpt, outputs=l2)\n",
    "l3_rep = Model(inputs=inpt, outputs=l3)\n",
    "l4_rep = Model(inputs=inpt, outputs=l4)\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(1e-3),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "model.save_weights('keras_weights/mnist_cnn.h5')\n",
    "\n",
    "model.load_weights('keras_weights/mnist_cnn.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l1(X):\n",
    "    x = tf.placeholder(tf.float32, (None, 28, 28, 1))\n",
    "    y = l1_rep(x)\n",
    "    return sess.run(y, feed_dict={x: X})\n",
    "\n",
    "\n",
    "def get_all_rep(X):\n",
    "    x = tf.placeholder(tf.float32, (None, 28, 28, 1))\n",
    "    \n",
    "    l1 = l1_rep(x)\n",
    "    out_l1 = np.zeros((len(X), ) + tuple(l1.shape[1:]))\n",
    "    for i in range(int(np.ceil(len(X)/1000))):\n",
    "        out_l1[i*1000 : (i + 1)*1000] = sess.run(\n",
    "            l1, feed_dict={x: X[i*1000 : (i + 1)*1000]})\n",
    "        \n",
    "    l2 = l2_rep(x)\n",
    "    out_l2 = np.zeros((len(X), ) + tuple(l2.shape[1:]))\n",
    "    for i in range(int(np.ceil(len(X)/1000))):\n",
    "        out_l2[i*1000 : (i + 1)*1000] = sess.run(\n",
    "            l2, feed_dict={x: X[i*1000 : (i + 1)*1000]})\n",
    "        \n",
    "    l3 = l3_rep(x)\n",
    "    out_l3 = np.zeros((len(X), ) + tuple(l3.shape[1:]))\n",
    "    for i in range(int(np.ceil(len(X)/1000))):\n",
    "        out_l3[i*1000 : (i + 1)*1000] = sess.run(\n",
    "            l3, feed_dict={x: X[i*1000 : (i + 1)*1000]})\n",
    "        \n",
    "    l4 = l4_rep(x)\n",
    "    out_l4 = np.zeros((len(X), ) + tuple(l4.shape[1:]))\n",
    "    for i in range(int(np.ceil(len(X)/1000))):\n",
    "        out_l4[i*1000 : (i + 1)*1000] = sess.run(\n",
    "            l4, feed_dict={x: X[i*1000 : (i + 1)*1000]})\n",
    "        \n",
    "    return [out_l1, out_l2, out_l3, out_l4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_layer1 = K.function([model.input, K.learning_phase()], [model.layers[0].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_37_l1 = get_layer1([X_37, 0])[0]\n",
    "X_37_test_l1 = get_layer1([X_37_test, 0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "nn_l1 = find_nn(X_37_test_l1, X_37_l1, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936211972522081\n"
     ]
    }
   ],
   "source": [
    "find_acc(nn_l1, y_37_test, y_37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibrate and compute $\\Omega_\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly chosen calibrate set 75 samples from each class\n",
    "ind_cal = np.zeros((750, ), dtype=np.int32)\n",
    "for i in range(10):\n",
    "    ind = np.where(y_test == i)[0]\n",
    "    np.random.shuffle(ind)\n",
    "    ind_cal[i*75 : (i + 1)*75] = ind[:75]\n",
    "ind_test = np.arange(len(X_test), dtype=np.int32)\n",
    "ind_test = np.setdiff1d(ind_test, ind_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cal = X_test[ind_cal]\n",
    "y_cal = y_test[ind_cal]\n",
    "X_test = X_test[ind_test]\n",
    "y_test = y_test[ind_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_train = get_all_rep(X_train)\n",
    "rep_test = get_all_rep(X_test)\n",
    "rep_cal = get_all_rep(X_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "  20\n",
      "  21\n",
      "  22\n",
      "  23\n",
      "  24\n",
      "  25\n",
      "  26\n",
      "  27\n",
      "  28\n",
      "  29\n",
      "  30\n",
      "  31\n",
      "  32\n",
      "  33\n",
      "  34\n",
      "  35\n",
      "  36\n",
      "  37\n",
      "  38\n",
      "  39\n",
      "  40\n",
      "  41\n",
      "  42\n",
      "  43\n",
      "  44\n",
      "  45\n",
      "  46\n",
      "  47\n",
      "  48\n",
      "  49\n",
      "  50\n",
      "  51\n",
      "  52\n",
      "  53\n",
      "  54\n",
      "  55\n",
      "  56\n",
      "  57\n",
      "  58\n",
      "  59\n",
      "  60\n",
      "  61\n",
      "  62\n",
      "  63\n",
      "  64\n",
      "  65\n",
      "  66\n",
      "  67\n",
      "  68\n",
      "  69\n",
      "  70\n",
      "  71\n",
      "  72\n",
      "  73\n",
      "  74\n",
      "  75\n",
      "  76\n",
      "  77\n",
      "  78\n",
      "  79\n",
      "  80\n",
      "  81\n",
      "  82\n",
      "  83\n",
      "  84\n",
      "  85\n",
      "  86\n",
      "  87\n",
      "  88\n",
      "  89\n",
      "  90\n",
      "  91\n",
      "  92\n",
      "  93\n",
      "  94\n",
      "  95\n",
      "  96\n",
      "  97\n",
      "  98\n",
      "  99\n",
      "  100\n",
      "  101\n",
      "  102\n",
      "  103\n",
      "  104\n",
      "  105\n",
      "  106\n",
      "  107\n",
      "  108\n",
      "  109\n",
      "  110\n",
      "  111\n",
      "  112\n",
      "  113\n",
      "  114\n",
      "  115\n",
      "  116\n",
      "  117\n",
      "  118\n",
      "  119\n",
      "  120\n",
      "  121\n",
      "  122\n",
      "  123\n",
      "  124\n",
      "  125\n",
      "  126\n",
      "  127\n",
      "  128\n",
      "  129\n",
      "  130\n",
      "  131\n",
      "  132\n",
      "  133\n",
      "  134\n",
      "  135\n",
      "  136\n",
      "  137\n",
      "  138\n",
      "  139\n",
      "  140\n",
      "  141\n",
      "  142\n",
      "  143\n",
      "  144\n",
      "  145\n",
      "  146\n",
      "  147\n",
      "  148\n",
      "  149\n",
      "  150\n",
      "  151\n",
      "  152\n",
      "  153\n",
      "  154\n",
      "  155\n",
      "  156\n",
      "  157\n",
      "  158\n",
      "  159\n",
      "  160\n",
      "  161\n",
      "  162\n",
      "  163\n",
      "  164\n",
      "  165\n",
      "  166\n",
      "  167\n",
      "  168\n",
      "  169\n",
      "  170\n",
      "  171\n",
      "  172\n",
      "  173\n",
      "  174\n",
      "  175\n",
      "  176\n",
      "  177\n",
      "  178\n",
      "  179\n",
      "  180\n",
      "  181\n",
      "  182\n",
      "  183\n",
      "  184\n",
      "  185\n",
      "  186\n",
      "  187\n",
      "  188\n",
      "  189\n",
      "  190\n",
      "  191\n",
      "  192\n",
      "  193\n",
      "  194\n",
      "  195\n",
      "  196\n",
      "  197\n",
      "  198\n",
      "  199\n",
      "  200\n",
      "  201\n",
      "  202\n",
      "  203\n",
      "  204\n",
      "  205\n",
      "  206\n",
      "  207\n",
      "  208\n",
      "  209\n",
      "  210\n",
      "  211\n",
      "  212\n",
      "  213\n",
      "  214\n",
      "  215\n",
      "  216\n",
      "  217\n",
      "  218\n",
      "  219\n",
      "  220\n",
      "  221\n",
      "  222\n",
      "  223\n",
      "  224\n",
      "  225\n",
      "  226\n",
      "  227\n",
      "  228\n",
      "  229\n",
      "  230\n",
      "  231\n",
      "  232\n",
      "  233\n",
      "  234\n",
      "  235\n",
      "  236\n",
      "  237\n",
      "  238\n",
      "  239\n",
      "  240\n",
      "  241\n",
      "  242\n",
      "  243\n",
      "  244\n",
      "  245\n",
      "  246\n",
      "  247\n",
      "  248\n",
      "  249\n",
      "  250\n",
      "  251\n",
      "  252\n",
      "  253\n",
      "  254\n",
      "  255\n",
      "  256\n",
      "  257\n",
      "  258\n",
      "  259\n",
      "  260\n",
      "  261\n",
      "  262\n",
      "  263\n",
      "  264\n",
      "  265\n",
      "  266\n",
      "  267\n",
      "  268\n",
      "  269\n",
      "  270\n",
      "  271\n",
      "  272\n",
      "  273\n",
      "  274\n",
      "  275\n",
      "  276\n",
      "  277\n",
      "  278\n",
      "  279\n",
      "  280\n",
      "  281\n",
      "  282\n",
      "  283\n",
      "  284\n",
      "  285\n",
      "  286\n",
      "  287\n",
      "  288\n",
      "  289\n",
      "  290\n",
      "  291\n",
      "  292\n",
      "  293\n",
      "  294\n",
      "  295\n",
      "  296\n",
      "  297\n",
      "  298\n",
      "  299\n",
      "  300\n",
      "  301\n",
      "  302\n",
      "  303\n",
      "  304\n",
      "  305\n",
      "  306\n",
      "  307\n",
      "  308\n",
      "  309\n",
      "  310\n",
      "  311\n",
      "  312\n",
      "  313\n",
      "  314\n",
      "  315\n",
      "  316\n",
      "  317\n",
      "  318\n",
      "  319\n",
      "  320\n",
      "  321\n",
      "  322\n",
      "  323\n",
      "  324\n",
      "  325\n",
      "  326\n",
      "  327\n",
      "  328\n",
      "  329\n",
      "  330\n",
      "  331\n",
      "  332\n",
      "  333\n",
      "  334\n",
      "  335\n",
      "  336\n",
      "  337\n",
      "  338\n",
      "  339\n",
      "  340\n",
      "  341\n",
      "  342\n",
      "  343\n",
      "  344\n",
      "  345\n",
      "  346\n",
      "  347\n",
      "  348\n",
      "  349\n",
      "  350\n",
      "  351\n",
      "  352\n",
      "  353\n",
      "  354\n",
      "  355\n",
      "  356\n",
      "  357\n",
      "  358\n",
      "  359\n",
      "  360\n",
      "  361\n",
      "  362\n",
      "  363\n",
      "  364\n",
      "  365\n",
      "  366\n",
      "  367\n",
      "  368\n",
      "  369\n",
      "  370\n",
      "  371\n",
      "  372\n",
      "  373\n",
      "  374\n",
      "  375\n",
      "  376\n",
      "  377\n",
      "  378\n",
      "  379\n",
      "  380\n",
      "  381\n",
      "  382\n",
      "  383\n",
      "  384\n",
      "  385\n",
      "  386\n",
      "  387\n",
      "  388\n",
      "  389\n",
      "  390\n",
      "  391\n",
      "  392\n",
      "  393\n",
      "  394\n",
      "  395\n",
      "  396\n",
      "  397\n",
      "  398\n",
      "  399\n",
      "  400\n",
      "  401\n",
      "  402\n",
      "  403\n",
      "  404\n",
      "  405\n",
      "  406\n",
      "  407\n",
      "  408\n",
      "  409\n",
      "  410\n",
      "  411\n",
      "  412\n",
      "  413\n",
      "  414\n",
      "  415\n",
      "  416\n",
      "  417\n",
      "  418\n",
      "  419\n",
      "  420\n",
      "  421\n",
      "  422\n",
      "  423\n",
      "  424\n",
      "  425\n",
      "  426\n",
      "  427\n",
      "  428\n",
      "  429\n",
      "  430\n",
      "  431\n",
      "  432\n",
      "  433\n",
      "  434\n",
      "  435\n",
      "  436\n",
      "  437\n",
      "  438\n",
      "  439\n",
      "  440\n",
      "  441\n",
      "  442\n",
      "  443\n",
      "  444\n",
      "  445\n",
      "  446\n",
      "  447\n",
      "  448\n",
      "  449\n",
      "  450\n",
      "  451\n",
      "  452\n",
      "  453\n",
      "  454\n",
      "  455\n",
      "  456\n",
      "  457\n",
      "  458\n",
      "  459\n",
      "  460\n",
      "  461\n",
      "  462\n",
      "  463\n",
      "  464\n",
      "  465\n",
      "  466\n",
      "  467\n",
      "  468\n",
      "  469\n",
      "  470\n",
      "  471\n",
      "  472\n",
      "  473\n",
      "  474\n",
      "  475\n",
      "  476\n",
      "  477\n",
      "  478\n",
      "  479\n",
      "  480\n",
      "  481\n",
      "  482\n",
      "  483\n",
      "  484\n",
      "  485\n",
      "  486\n",
      "  487\n",
      "  488\n",
      "  489\n",
      "  490\n",
      "  491\n",
      "  492\n",
      "  493\n",
      "  494\n",
      "  495\n",
      "  496\n",
      "  497\n",
      "  498\n",
      "  499\n",
      "  500\n",
      "  501\n",
      "  502\n",
      "  503\n",
      "  504\n",
      "  505\n",
      "  506\n",
      "  507\n",
      "  508\n",
      "  509\n",
      "  510\n",
      "  511\n",
      "  512\n",
      "  513\n",
      "  514\n",
      "  515\n",
      "  516\n",
      "  517\n",
      "  518\n",
      "  519\n",
      "  520\n",
      "  521\n",
      "  522\n",
      "  523\n",
      "  524\n",
      "  525\n",
      "  526\n",
      "  527\n",
      "  528\n",
      "  529\n",
      "  530\n",
      "  531\n",
      "  532\n",
      "  533\n",
      "  534\n",
      "  535\n",
      "  536\n",
      "  537\n",
      "  538\n",
      "  539\n",
      "  540\n",
      "  541\n",
      "  542\n",
      "  543\n",
      "  544\n",
      "  545\n",
      "  546\n",
      "  547\n",
      "  548\n",
      "  549\n",
      "  550\n",
      "  551\n",
      "  552\n",
      "  553\n",
      "  554\n",
      "  555\n",
      "  556\n",
      "  557\n",
      "  558\n",
      "  559\n",
      "  560\n",
      "  561\n",
      "  562\n",
      "  563\n",
      "  564\n",
      "  565\n",
      "  566\n",
      "  567\n",
      "  568\n",
      "  569\n",
      "  570\n",
      "  571\n",
      "  572\n",
      "  573\n",
      "  574\n",
      "  575\n",
      "  576\n",
      "  577\n",
      "  578\n",
      "  579\n",
      "  580\n",
      "  581\n",
      "  582\n",
      "  583\n",
      "  584\n",
      "  585\n",
      "  586\n",
      "  587\n",
      "  588\n",
      "  589\n",
      "  590\n",
      "  591\n",
      "  592\n",
      "  593\n",
      "  594\n",
      "  595\n",
      "  596\n",
      "  597\n",
      "  598\n",
      "  599\n",
      "  600\n",
      "  601\n",
      "  602\n",
      "  603\n",
      "  604\n",
      "  605\n",
      "  606\n",
      "  607\n",
      "  608\n",
      "  609\n",
      "  610\n",
      "  611\n",
      "  612\n",
      "  613\n",
      "  614\n",
      "  615\n",
      "  616\n",
      "  617\n",
      "  618\n",
      "  619\n",
      "  620\n",
      "  621\n",
      "  622\n",
      "  623\n",
      "  624\n",
      "  625\n",
      "  626\n",
      "  627\n",
      "  628\n",
      "  629\n",
      "  630\n",
      "  631\n",
      "  632\n",
      "  633\n",
      "  634\n",
      "  635\n",
      "  636\n",
      "  637\n",
      "  638\n",
      "  639\n",
      "  640\n",
      "  641\n",
      "  642\n",
      "  643\n",
      "  644\n",
      "  645\n",
      "  646\n",
      "  647\n",
      "  648\n",
      "  649\n",
      "  650\n",
      "  651\n",
      "  652\n",
      "  653\n",
      "  654\n",
      "  655\n",
      "  656\n",
      "  657\n",
      "  658\n",
      "  659\n",
      "  660\n",
      "  661\n",
      "  662\n",
      "  663\n",
      "  664\n",
      "  665\n",
      "  666\n",
      "  667\n",
      "  668\n",
      "  669\n",
      "  670\n",
      "  671\n",
      "  672\n",
      "  673\n",
      "  674\n",
      "  675\n",
      "  676\n",
      "  677\n",
      "  678\n",
      "  679\n",
      "  680\n",
      "  681\n",
      "  682\n",
      "  683\n",
      "  684\n",
      "  685\n",
      "  686\n",
      "  687\n",
      "  688\n",
      "  689\n",
      "  690\n",
      "  691\n",
      "  692\n",
      "  693\n",
      "  694\n",
      "  695\n",
      "  696\n",
      "  697\n",
      "  698\n",
      "  699\n",
      "  700\n",
      "  701\n",
      "  702\n",
      "  703\n",
      "  704\n",
      "  705\n",
      "  706\n",
      "  707\n",
      "  708\n",
      "  709\n",
      "  710\n",
      "  711\n",
      "  712\n",
      "  713\n",
      "  714\n",
      "  715\n",
      "  716\n",
      "  717\n",
      "  718\n",
      "  719\n",
      "  720\n",
      "  721\n",
      "  722\n",
      "  723\n",
      "  724\n",
      "  725\n",
      "  726\n",
      "  727\n",
      "  728\n",
      "  729\n",
      "  730\n",
      "  731\n",
      "  732\n",
      "  733\n",
      "  734\n",
      "  735\n",
      "  736\n",
      "  737\n",
      "  738\n",
      "  739\n",
      "  740\n",
      "  741\n",
      "  742\n",
      "  743\n",
      "  744\n",
      "  745\n",
      "  746\n",
      "  747\n",
      "  748\n",
      "  749\n",
      "1\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "  20\n",
      "  21\n",
      "  22\n",
      "  23\n",
      "  24\n",
      "  25\n",
      "  26\n",
      "  27\n",
      "  28\n",
      "  29\n",
      "  30\n",
      "  31\n",
      "  32\n",
      "  33\n",
      "  34\n",
      "  35\n",
      "  36\n",
      "  37\n",
      "  38\n",
      "  39\n",
      "  40\n",
      "  41\n",
      "  42\n",
      "  43\n",
      "  44\n",
      "  45\n",
      "  46\n",
      "  47\n",
      "  48\n",
      "  49\n",
      "  50\n",
      "  51\n",
      "  52\n",
      "  53\n",
      "  54\n",
      "  55\n",
      "  56\n",
      "  57\n",
      "  58\n",
      "  59\n",
      "  60\n",
      "  61\n",
      "  62\n",
      "  63\n",
      "  64\n",
      "  65\n",
      "  66\n",
      "  67\n",
      "  68\n",
      "  69\n",
      "  70\n",
      "  71\n",
      "  72\n",
      "  73\n",
      "  74\n",
      "  75\n",
      "  76\n",
      "  77\n",
      "  78\n",
      "  79\n",
      "  80\n",
      "  81\n",
      "  82\n",
      "  83\n",
      "  84\n",
      "  85\n",
      "  86\n",
      "  87\n",
      "  88\n",
      "  89\n",
      "  90\n",
      "  91\n",
      "  92\n",
      "  93\n",
      "  94\n",
      "  95\n",
      "  96\n",
      "  97\n",
      "  98\n",
      "  99\n",
      "  100\n",
      "  101\n",
      "  102\n",
      "  103\n",
      "  104\n",
      "  105\n",
      "  106\n",
      "  107\n",
      "  108\n",
      "  109\n",
      "  110\n",
      "  111\n",
      "  112\n",
      "  113\n",
      "  114\n",
      "  115\n",
      "  116\n",
      "  117\n",
      "  118\n",
      "  119\n",
      "  120\n",
      "  121\n",
      "  122\n",
      "  123\n",
      "  124\n",
      "  125\n",
      "  126\n",
      "  127\n",
      "  128\n",
      "  129\n",
      "  130\n",
      "  131\n",
      "  132\n",
      "  133\n",
      "  134\n",
      "  135\n",
      "  136\n",
      "  137\n",
      "  138\n",
      "  139\n",
      "  140\n",
      "  141\n",
      "  142\n",
      "  143\n",
      "  144\n",
      "  145\n",
      "  146\n",
      "  147\n",
      "  148\n",
      "  149\n",
      "  150\n",
      "  151\n",
      "  152\n",
      "  153\n",
      "  154\n",
      "  155\n",
      "  156\n",
      "  157\n",
      "  158\n",
      "  159\n",
      "  160\n",
      "  161\n",
      "  162\n",
      "  163\n",
      "  164\n",
      "  165\n",
      "  166\n",
      "  167\n",
      "  168\n",
      "  169\n",
      "  170\n",
      "  171\n",
      "  172\n",
      "  173\n",
      "  174\n",
      "  175\n",
      "  176\n",
      "  177\n",
      "  178\n",
      "  179\n",
      "  180\n",
      "  181\n",
      "  182\n",
      "  183\n",
      "  184\n",
      "  185\n",
      "  186\n",
      "  187\n",
      "  188\n",
      "  189\n",
      "  190\n",
      "  191\n",
      "  192\n",
      "  193\n",
      "  194\n",
      "  195\n",
      "  196\n",
      "  197\n",
      "  198\n",
      "  199\n",
      "  200\n",
      "  201\n",
      "  202\n",
      "  203\n",
      "  204\n",
      "  205\n",
      "  206\n",
      "  207\n",
      "  208\n",
      "  209\n",
      "  210\n",
      "  211\n",
      "  212\n",
      "  213\n",
      "  214\n",
      "  215\n",
      "  216\n",
      "  217\n",
      "  218\n",
      "  219\n",
      "  220\n",
      "  221\n",
      "  222\n",
      "  223\n",
      "  224\n",
      "  225\n",
      "  226\n",
      "  227\n",
      "  228\n",
      "  229\n",
      "  230\n",
      "  231\n",
      "  232\n",
      "  233\n",
      "  234\n",
      "  235\n",
      "  236\n",
      "  237\n",
      "  238\n",
      "  239\n",
      "  240\n",
      "  241\n",
      "  242\n",
      "  243\n",
      "  244\n",
      "  245\n",
      "  246\n",
      "  247\n",
      "  248\n",
      "  249\n",
      "  250\n",
      "  251\n",
      "  252\n",
      "  253\n",
      "  254\n",
      "  255\n",
      "  256\n",
      "  257\n",
      "  258\n",
      "  259\n",
      "  260\n",
      "  261\n",
      "  262\n",
      "  263\n",
      "  264\n",
      "  265\n",
      "  266\n",
      "  267\n",
      "  268\n",
      "  269\n",
      "  270\n",
      "  271\n",
      "  272\n",
      "  273\n",
      "  274\n",
      "  275\n",
      "  276\n",
      "  277\n",
      "  278\n",
      "  279\n",
      "  280\n",
      "  281\n",
      "  282\n",
      "  283\n",
      "  284\n",
      "  285\n",
      "  286\n",
      "  287\n",
      "  288\n",
      "  289\n",
      "  290\n",
      "  291\n",
      "  292\n",
      "  293\n",
      "  294\n",
      "  295\n",
      "  296\n",
      "  297\n",
      "  298\n",
      "  299\n",
      "  300\n",
      "  301\n",
      "  302\n",
      "  303\n",
      "  304\n",
      "  305\n",
      "  306\n",
      "  307\n",
      "  308\n",
      "  309\n",
      "  310\n",
      "  311\n",
      "  312\n",
      "  313\n",
      "  314\n",
      "  315\n",
      "  316\n",
      "  317\n",
      "  318\n",
      "  319\n",
      "  320\n",
      "  321\n",
      "  322\n",
      "  323\n",
      "  324\n",
      "  325\n",
      "  326\n",
      "  327\n",
      "  328\n",
      "  329\n",
      "  330\n",
      "  331\n",
      "  332\n",
      "  333\n",
      "  334\n",
      "  335\n",
      "  336\n",
      "  337\n",
      "  338\n",
      "  339\n",
      "  340\n",
      "  341\n",
      "  342\n",
      "  343\n",
      "  344\n",
      "  345\n",
      "  346\n",
      "  347\n",
      "  348\n",
      "  349\n",
      "  350\n",
      "  351\n",
      "  352\n",
      "  353\n",
      "  354\n",
      "  355\n",
      "  356\n",
      "  357\n",
      "  358\n",
      "  359\n",
      "  360\n",
      "  361\n",
      "  362\n",
      "  363\n",
      "  364\n",
      "  365\n",
      "  366\n",
      "  367\n",
      "  368\n",
      "  369\n",
      "  370\n",
      "  371\n",
      "  372\n",
      "  373\n",
      "  374\n",
      "  375\n",
      "  376\n",
      "  377\n",
      "  378\n",
      "  379\n",
      "  380\n",
      "  381\n",
      "  382\n",
      "  383\n",
      "  384\n",
      "  385\n",
      "  386\n",
      "  387\n",
      "  388\n",
      "  389\n",
      "  390\n",
      "  391\n",
      "  392\n",
      "  393\n",
      "  394\n",
      "  395\n",
      "  396\n",
      "  397\n",
      "  398\n",
      "  399\n",
      "  400\n",
      "  401\n",
      "  402\n",
      "  403\n",
      "  404\n",
      "  405\n",
      "  406\n",
      "  407\n",
      "  408\n",
      "  409\n",
      "  410\n",
      "  411\n",
      "  412\n",
      "  413\n",
      "  414\n",
      "  415\n",
      "  416\n",
      "  417\n",
      "  418\n",
      "  419\n",
      "  420\n",
      "  421\n",
      "  422\n",
      "  423\n",
      "  424\n",
      "  425\n",
      "  426\n",
      "  427\n",
      "  428\n",
      "  429\n",
      "  430\n",
      "  431\n",
      "  432\n",
      "  433\n",
      "  434\n",
      "  435\n",
      "  436\n",
      "  437\n",
      "  438\n",
      "  439\n",
      "  440\n",
      "  441\n",
      "  442\n",
      "  443\n",
      "  444\n",
      "  445\n",
      "  446\n",
      "  447\n",
      "  448\n",
      "  449\n",
      "  450\n",
      "  451\n",
      "  452\n",
      "  453\n",
      "  454\n",
      "  455\n",
      "  456\n",
      "  457\n",
      "  458\n",
      "  459\n",
      "  460\n",
      "  461\n",
      "  462\n",
      "  463\n",
      "  464\n",
      "  465\n",
      "  466\n",
      "  467\n",
      "  468\n",
      "  469\n",
      "  470\n",
      "  471\n",
      "  472\n",
      "  473\n",
      "  474\n",
      "  475\n",
      "  476\n",
      "  477\n",
      "  478\n",
      "  479\n",
      "  480\n",
      "  481\n",
      "  482\n",
      "  483\n",
      "  484\n",
      "  485\n",
      "  486\n",
      "  487\n",
      "  488\n",
      "  489\n",
      "  490\n",
      "  491\n",
      "  492\n",
      "  493\n",
      "  494\n",
      "  495\n",
      "  496\n",
      "  497\n",
      "  498\n",
      "  499\n",
      "  500\n",
      "  501\n",
      "  502\n",
      "  503\n",
      "  504\n",
      "  505\n",
      "  506\n",
      "  507\n",
      "  508\n",
      "  509\n",
      "  510\n",
      "  511\n",
      "  512\n",
      "  513\n",
      "  514\n",
      "  515\n",
      "  516\n",
      "  517\n",
      "  518\n",
      "  519\n",
      "  520\n",
      "  521\n",
      "  522\n",
      "  523\n",
      "  524\n",
      "  525\n",
      "  526\n",
      "  527\n",
      "  528\n",
      "  529\n",
      "  530\n",
      "  531\n",
      "  532\n",
      "  533\n",
      "  534\n",
      "  535\n",
      "  536\n",
      "  537\n",
      "  538\n",
      "  539\n",
      "  540\n",
      "  541\n",
      "  542\n",
      "  543\n",
      "  544\n",
      "  545\n",
      "  546\n",
      "  547\n",
      "  548\n",
      "  549\n",
      "  550\n",
      "  551\n",
      "  552\n",
      "  553\n",
      "  554\n",
      "  555\n",
      "  556\n",
      "  557\n",
      "  558\n",
      "  559\n",
      "  560\n",
      "  561\n",
      "  562\n",
      "  563\n",
      "  564\n",
      "  565\n",
      "  566\n",
      "  567\n",
      "  568\n",
      "  569\n",
      "  570\n",
      "  571\n",
      "  572\n",
      "  573\n",
      "  574\n",
      "  575\n",
      "  576\n",
      "  577\n",
      "  578\n",
      "  579\n",
      "  580\n",
      "  581\n",
      "  582\n",
      "  583\n",
      "  584\n",
      "  585\n",
      "  586\n",
      "  587\n",
      "  588\n",
      "  589\n",
      "  590\n",
      "  591\n",
      "  592\n",
      "  593\n",
      "  594\n",
      "  595\n",
      "  596\n",
      "  597\n",
      "  598\n",
      "  599\n",
      "  600\n",
      "  601\n",
      "  602\n",
      "  603\n",
      "  604\n",
      "  605\n",
      "  606\n",
      "  607\n",
      "  608\n",
      "  609\n",
      "  610\n",
      "  611\n",
      "  612\n",
      "  613\n",
      "  614\n",
      "  615\n",
      "  616\n",
      "  617\n",
      "  618\n",
      "  619\n",
      "  620\n",
      "  621\n",
      "  622\n",
      "  623\n",
      "  624\n",
      "  625\n",
      "  626\n",
      "  627\n",
      "  628\n",
      "  629\n",
      "  630\n",
      "  631\n",
      "  632\n",
      "  633\n",
      "  634\n",
      "  635\n",
      "  636\n",
      "  637\n",
      "  638\n",
      "  639\n",
      "  640\n",
      "  641\n",
      "  642\n",
      "  643\n",
      "  644\n",
      "  645\n",
      "  646\n",
      "  647\n",
      "  648\n",
      "  649\n",
      "  650\n",
      "  651\n",
      "  652\n",
      "  653\n",
      "  654\n",
      "  655\n",
      "  656\n",
      "  657\n",
      "  658\n",
      "  659\n",
      "  660\n",
      "  661\n",
      "  662\n",
      "  663\n",
      "  664\n",
      "  665\n",
      "  666\n",
      "  667\n",
      "  668\n",
      "  669\n",
      "  670\n",
      "  671\n",
      "  672\n",
      "  673\n",
      "  674\n",
      "  675\n",
      "  676\n",
      "  677\n",
      "  678\n",
      "  679\n",
      "  680\n",
      "  681\n",
      "  682\n",
      "  683\n",
      "  684\n",
      "  685\n",
      "  686\n",
      "  687\n",
      "  688\n",
      "  689\n",
      "  690\n",
      "  691\n",
      "  692\n",
      "  693\n",
      "  694\n",
      "  695\n",
      "  696\n",
      "  697\n",
      "  698\n",
      "  699\n",
      "  700\n",
      "  701\n",
      "  702\n",
      "  703\n",
      "  704\n",
      "  705\n",
      "  706\n",
      "  707\n",
      "  708\n",
      "  709\n",
      "  710\n",
      "  711\n",
      "  712\n",
      "  713\n",
      "  714\n",
      "  715\n",
      "  716\n",
      "  717\n",
      "  718\n",
      "  719\n",
      "  720\n",
      "  721\n",
      "  722\n",
      "  723\n",
      "  724\n",
      "  725\n",
      "  726\n",
      "  727\n",
      "  728\n",
      "  729\n",
      "  730\n",
      "  731\n",
      "  732\n",
      "  733\n",
      "  734\n",
      "  735\n",
      "  736\n",
      "  737\n",
      "  738\n",
      "  739\n",
      "  740\n",
      "  741\n",
      "  742\n",
      "  743\n",
      "  744\n",
      "  745\n",
      "  746\n",
      "  747\n",
      "  748\n",
      "  749\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Compute Omega multiset\n",
    "omega = []\n",
    "\n",
    "for i in range(4):\n",
    "    print(i)\n",
    "    nn = find_nn(rep_cal[i], rep_train[i], 75)\n",
    "    bincount = [np.bincount(y, minlength=10) for y in y_train[nn]]\n",
    "    o_lambda = []\n",
    "    for j, b in enumerate(bincount):\n",
    "        print('  ' + str(j))\n",
    "        label = y_cal[j]\n",
    "        o_lambda.append(75 - b[label])\n",
    "    omega.append(np.array(o_lambda))\n",
    "omega = np.array(omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(omega, open(\"A.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pickle.load(open(\"A.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify on test set\n",
    "def omega_classify(A, rep, rep_train, y_train):\n",
    "    \n",
    "    alphas = []\n",
    "    for i in range(4):\n",
    "        nn = find_nn(rep[i], rep_train[i], 75)\n",
    "        bincount = [np.bincount(y, minlength=10) for y in y_train[nn]]\n",
    "        alpha = np.zeros((len(bincount), 10))\n",
    "        for j, b in enumerate(bincount):\n",
    "            alpha[j] = np.array([75 - b[label] for label in range(10)])\n",
    "        alphas.append(alpha)\n",
    "    alphas = np.array(alphas)\n",
    "    return alphas, np.sum(alphas, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_test_37 = [r[(y_test == 3) | (y_test == 7)] for r in rep_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-53c369b7068d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momega_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrep_test_37\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrep_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-30345eb8c124>\u001b[0m in \u001b[0;36momega_classify\u001b[0;34m(A, rep, rep_train, y_train)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m75\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0malphas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "all_bins, alphas = omega_classify(A, rep_test_37, rep_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack on k=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nn_by_dist(Q, X, dist):\n",
    "    axis = np.arange(1, Q.ndim)\n",
    "    nn = []\n",
    "    for i, q in enumerate(Q):\n",
    "        ind = np.sum((X - q)**2, axis=axis) <= dist\n",
    "        nn.append(np.where(ind)[0])\n",
    "    return nn\n",
    "\n",
    "\n",
    "class BaselineAttack(object):\n",
    "    \n",
    "    def __init__(self, sess, model, get_rep, X, X_rep, y_X, \n",
    "                 pert_norm=2, batch_size=1000, lr=1e-3, \n",
    "                 abort_early=True, init_const=1, min_dist=1,\n",
    "                 pert_bound=0.3):\n",
    "    \n",
    "        self.sess = sess\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.X_rep = X_rep\n",
    "        self.y_X = y_X\n",
    "        self.batch_size = batch_size\n",
    "        self.abort_early = abort_early\n",
    "        self.init_const = init_const\n",
    "        self.min_dist = min_dist\n",
    "        self.pert_norm = pert_norm\n",
    "        self.pert_bound = pert_bound\n",
    "        \n",
    "        input_ndim = X.ndim\n",
    "        input_axis = np.arange(1, input_ndim)\n",
    "        input_shape = (batch_size, ) + X.shape[1:]\n",
    "        rep_ndim = X_rep.ndim\n",
    "        rep_axis = np.arange(1, rep_ndim)\n",
    "        rep_shape = (batch_size, ) + X_rep.shape[1:]\n",
    "\n",
    "        # Objective variable\n",
    "        modifier = tf.Variable(np.zeros(input_shape), dtype=tf.float32)\n",
    "\n",
    "        # These are variables to be more efficient in sending data to tf\n",
    "        q_var = tf.Variable(np.zeros(input_shape), dtype=tf.float32, name='q_var')\n",
    "        target_var = tf.Variable(np.zeros(rep_shape), dtype=tf.float32, name='target_var')\n",
    "        const_var = tf.Variable(\n",
    "            np.zeros(batch_size), dtype=tf.float32, name='const_var')\n",
    "\n",
    "        # and here's what we use to assign them\n",
    "        self.assign_q = tf.placeholder(tf.float32, input_shape, name='assign_q')\n",
    "        self.assign_target = tf.placeholder(tf.float32, rep_shape, name='assign_target')\n",
    "        self.assign_const = tf.placeholder(\n",
    "            tf.float32, [batch_size], name='assign_const')\n",
    "\n",
    "        # Clip to ensure pixel value is between 0 and 1\n",
    "        self.new_q = tf.clip_by_value(q_var + modifier, 0., 1.)\n",
    "        # Get reprentation tensor\n",
    "        self.rep = get_rep(self.new_q)\n",
    "\n",
    "        # L2 loss\n",
    "        self.l2dist = tf.reduce_sum(tf.square(modifier), input_axis)\n",
    "        dist_loss = tf.reduce_sum(tf.square(self.rep - target_var), rep_axis)\n",
    "        self.dist_loss = tf.maximum(0., dist_loss - self.min_dist**2)\n",
    "        \n",
    "        # Setup optimizer\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        if pert_norm == 2:\n",
    "            # For L-2 norm constraint, we use Adam optimizer with\n",
    "            # a penalty term\n",
    "            self.loss = tf.reduce_mean(const_var*self.dist_loss + self.l2dist)\n",
    "            optimizer = tf.train.AdamOptimizer(lr)\n",
    "            self.train_step = optimizer.minimize(self.loss, var_list=[modifier])\n",
    "        elif pert_norm == np.inf:\n",
    "            # For L-inf norm constraint, we use L-BFGS-B optimizer \n",
    "            # to provide correct bound, optimizer setup is moved to attack()\n",
    "            self.loss = tf.reduce_mean(self.dist_loss)\n",
    "            self.modifier = modifier\n",
    "        else:\n",
    "            raise ValueError('Invalid choice for perturbation norm!')\n",
    "            \n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "\n",
    "        self.setup = []\n",
    "        self.setup.append(q_var.assign(self.assign_q))\n",
    "        self.setup.append(target_var.assign(self.assign_target))\n",
    "        self.setup.append(const_var.assign(self.assign_const))\n",
    "        self.init = tf.variables_initializer(var_list=[modifier] + new_vars)\n",
    "        \n",
    "    def attack(self, Q, Q_rep, y_Q, const=1, bin_search_steps=5, max_iter=200):\n",
    "        r = []\n",
    "        for i in range(0, len(Q), self.batch_size):\n",
    "            print(\"Running Baseline Attack on instance {} of {}\".format(\n",
    "                i, len(Q)))\n",
    "            r.extend(self.attack_batch(Q[i:i + self.batch_size],\n",
    "                                       Q_rep[i:i + self.batch_size],\n",
    "                                       y_Q[i:i + self.batch_size],\n",
    "                                       const=const,\n",
    "                                       bin_search_steps=bin_search_steps,\n",
    "                                       max_iter=max_iter))\n",
    "        return np.array(r)\n",
    "\n",
    "        \n",
    "    def attack_batch(self, Q, Q_rep, y_Q, const=1, bin_search_steps=5, max_iter=200):   \n",
    "        \n",
    "        # Find closest rep of different class\n",
    "        print(\"  Finding nn representation as target...\")\n",
    "        nn = find_nn_diff_class(Q_rep, y_Q, self.X_rep, self.y_X, 1)\n",
    "        target_rep = np.squeeze(self.X_rep[nn])\n",
    "        # Find nn to target rep to save nn search time during optimization\n",
    "        # check_rep = find_nn(target_rep, self.X_rep, 100)\n",
    "        \n",
    "        # ============ Optimizing with L-inf norm constraints =========== #\n",
    "        # L-BFGS-B optimizer only needs to be called once\n",
    "        if self.pert_norm == np.inf:\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            target_rep_batch = target_rep[:self.batch_size]\n",
    "            const = np.ones(self.batch_size) * self.init_const\n",
    "            \n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            self.sess.run(\n",
    "                self.setup, {\n",
    "                    self.assign_q: Q_batch,\n",
    "                    self.assign_target: target_rep_batch,\n",
    "                    self.assign_const: const\n",
    "                })\n",
    "            \n",
    "            # Set up variables bound and optimizer\n",
    "            upper_bound = np.minimum(self.pert_bound, 1 - Q_batch)\n",
    "            lower_bound = np.maximum(-self.pert_bound, -Q_batch)\n",
    "            var_to_bounds = {self.modifier: (lower_bound, upper_bound)}\n",
    "            optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                self.loss, \n",
    "                var_list=[self.modifier], \n",
    "                var_to_bounds=var_to_bounds, \n",
    "                method='L-BFGS-B')\n",
    "            \n",
    "            # Call optimizer\n",
    "            optimizer.minimize(self.sess)\n",
    "            return self.sess.run(self.new_q)\n",
    "            \n",
    "        # ============= Optimizing with L2 norm constraints ============ #\n",
    "        o_bestl2 = [1e9] * self.batch_size\n",
    "        o_bestadv = np.zeros_like(Q[:self.batch_size])\n",
    "        \n",
    "        # Set the lower and upper bounds\n",
    "        lower_bound = np.zeros(self.batch_size)\n",
    "        const = np.ones(self.batch_size) * self.init_const\n",
    "        upper_bound = np.ones(self.batch_size) * 1e9\n",
    "       \n",
    "        for outer_step in range(bin_search_steps):\n",
    "\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            target_rep_batch = target_rep[:self.batch_size]\n",
    "            \n",
    "            bestl2 = [1e9] * self.batch_size\n",
    "            bestadv = np.zeros_like(Q_batch)\n",
    "            print(\"  Binary search step {} of {}\".format(\n",
    "                outer_step, bin_search_steps))\n",
    "\n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            self.sess.run(\n",
    "                self.setup, {\n",
    "                    self.assign_q: Q_batch,\n",
    "                    self.assign_target: target_rep_batch,\n",
    "                    self.assign_const: const\n",
    "                })\n",
    "\n",
    "            prev = 1e6\n",
    "            for iteration in range(max_iter):\n",
    "                # Take one step in optimization\n",
    "                _, l, l2s, dls, reps, qs = self.sess.run([self.train_step, \n",
    "                                                          self.loss, \n",
    "                                                          self.l2dist,\n",
    "                                                          self.dist_loss,\n",
    "                                                          self.rep, \n",
    "                                                          self.new_q])\n",
    "                \n",
    "                if iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    print((\"    Iteration {} of {}: loss={:.3g} l2={:.3g}\").format(\n",
    "                        iteration, max_iter, l, np.mean(l2s)))\n",
    "                \n",
    "                # Abort early if stop improving\n",
    "                if self.abort_early and iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    if l > prev * .9999:\n",
    "                        print(\"    Failed to make progress; stop early\")\n",
    "                        break\n",
    "                    prev = l\n",
    "                \n",
    "                # Check termination condition\n",
    "                # nn = find_nn(reps, self.X_rep, 1)\n",
    "                # y_pred = classify(nn, self.y_X)\n",
    "                # suc_ind = np.where(y_pred != y_Q)[0]\n",
    "                suc_ind = np.where(dls <= 1e-3)[0]\n",
    "                for ind in suc_ind:\n",
    "                    if l2s[ind] < bestl2[ind]:\n",
    "                        bestl2[ind] = l2s[ind]\n",
    "                        bestadv[ind] = qs[ind]                    \n",
    "\n",
    "                        \n",
    "            # Adjust const according to results\n",
    "            for e in range(self.batch_size):\n",
    "                if bestl2[e] < 1e9:\n",
    "                    # Success, divide const by two\n",
    "                    upper_bound[e] = min(upper_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    if bestl2[e] < o_bestl2[e]:\n",
    "                        o_bestl2[e] = bestl2[e]\n",
    "                        o_bestadv[e] = bestadv[e]\n",
    "                else:\n",
    "                    # Failure, either multiply by 10 if no solution found yet\n",
    "                    #          or do binary search with the known upper bound\n",
    "                    lower_bound[e] = max(lower_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    else:\n",
    "                        const[e] *= 10\n",
    "                        \n",
    "        return o_bestadv\n",
    "\n",
    "# picking closest rep is not efficient\n",
    "\n",
    "# implement random restart\n",
    "\n",
    "# Implement outer loop for baseline attack to bin search min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BaselineAttack(sess, model, l1_rep, \n",
    "                          X_37, X_37_l1, y_37, \n",
    "                          pert_norm=2,\n",
    "                          batch_size=5, \n",
    "                          lr=1e-2, \n",
    "                          abort_early=True,\n",
    "                          init_const=1, \n",
    "                          min_dist=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 5\n",
      "  Finding nn representation as target...\n",
      "  Binary search step 0 of 5\n",
      "    Iteration 0 of 500: loss=101 l2=0\n",
      "    Iteration 50 of 500: loss=25.1 l2=12.5\n",
      "    Iteration 100 of 500: loss=18.8 l2=15.6\n",
      "    Iteration 150 of 500: loss=17.5 l2=17.5\n",
      "    Iteration 200 of 500: loss=17.4 l2=17.3\n",
      "    Iteration 250 of 500: loss=17.4 l2=17.3\n",
      "    Failed to make progress; stop early\n",
      "  Binary search step 1 of 5\n",
      "    Iteration 0 of 500: loss=50.5 l2=0\n",
      "    Iteration 50 of 500: loss=17.7 l2=9.08\n",
      "    Iteration 100 of 500: loss=16.5 l2=10.8\n",
      "    Iteration 150 of 500: loss=16.4 l2=11.2\n",
      "    Iteration 200 of 500: loss=16.4 l2=11.2\n",
      "    Failed to make progress; stop early\n",
      "  Binary search step 2 of 5\n",
      "    Iteration 0 of 500: loss=67 l2=0\n",
      "    Iteration 50 of 500: loss=21.2 l2=10.1\n",
      "    Iteration 100 of 500: loss=17.8 l2=13.5\n",
      "    Iteration 150 of 500: loss=17.3 l2=14.6\n",
      "    Iteration 200 of 500: loss=17.2 l2=14.7\n",
      "    Iteration 250 of 500: loss=17.2 l2=14.7\n",
      "    Iteration 300 of 500: loss=17.2 l2=14.6\n",
      "    Failed to make progress; stop early\n",
      "  Binary search step 3 of 5\n",
      "    Iteration 0 of 500: loss=67.6 l2=0\n",
      "    Iteration 50 of 500: loss=21.8 l2=10.2\n",
      "    Iteration 100 of 500: loss=18.3 l2=14\n",
      "    Iteration 150 of 500: loss=17.7 l2=15.5\n",
      "    Iteration 200 of 500: loss=17.4 l2=16.4\n",
      "    Iteration 250 of 500: loss=17.4 l2=16.6\n",
      "    Iteration 300 of 500: loss=17.4 l2=16.6\n",
      "    Failed to make progress; stop early\n",
      "  Binary search step 4 of 5\n",
      "    Iteration 0 of 500: loss=71.9 l2=0\n",
      "    Iteration 50 of 500: loss=22.6 l2=10.6\n",
      "    Iteration 100 of 500: loss=18.5 l2=14.7\n",
      "    Iteration 150 of 500: loss=17.5 l2=16.8\n",
      "    Iteration 200 of 500: loss=17.3 l2=17.1\n",
      "    Iteration 250 of 500: loss=17.3 l2=17.2\n",
      "    Iteration 300 of 500: loss=17.3 l2=17.1\n",
      "    Failed to make progress; stop early\n"
     ]
    }
   ],
   "source": [
    "X_adv = baseline.attack(X_37_test[:5], X_37_test_l1[:5], y_37_test[:5], \n",
    "                        const=1, \n",
    "                        bin_search_steps=5, \n",
    "                        max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BaselineAttack(sess, model, l1_rep, \n",
    "                          X_37, X_37_l1, y_37, \n",
    "                          pert_norm=np.inf,\n",
    "                          batch_size=5, \n",
    "                          lr=1e-2, \n",
    "                          abort_early=True,\n",
    "                          init_const=1, \n",
    "                          min_dist=1,\n",
    "                          pert_bound=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 5\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 37.350212\n",
      "  Number of iterations: 87\n",
      "  Number of functions evaluations: 107\n"
     ]
    }
   ],
   "source": [
    "X_adv = baseline.attack(X_37_test[:5], X_37_test_l1[:5], y_37_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99598867, 0.9355945 , 0.99215686, 0.99607843, 0.99607843])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(X_adv - X_37_test[:5]), axis=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adv.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_adv_l1 = get_l1(X_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = find_nn_diff_class(X_37_test_l1[:5], y_37_test[:5], X_37_l1, y_37, 1)\n",
    "target_rep = np.squeeze(X_37_l1[nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.998856, 25.000402, 24.990017, 24.998325, 24.997124],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((X_adv_l1 - target_rep)**2, axis=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = find_nn(X_adv_l1, X_37_l1, 1)\n",
    "nn_rep = np.squeeze(X_37_l1[nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.998856, 25.000402, 24.990017, 24.998325, 24.997124],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((X_adv_l1 - nn_rep)**2, axis=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = find_nn(X_adv_l1, X_37_l1, 5)\n",
    "nn5_rep = np.squeeze(X_37_l1[nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.990017, 78.16258 , 82.02327 , 85.29616 , 87.17379 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((X_adv_l1[2] - nn5_rep[2])**2, axis=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 7, 7, 7, 7],\n",
       "       [3, 7, 7, 7, 7],\n",
       "       [7, 7, 7, 7, 7],\n",
       "       [3, 7, 7, 7, 7],\n",
       "       [7, 7, 7, 7, 7]], dtype=uint8)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_37[nn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 24.998856,  86.93029 , 144.90533 ,  72.729675,  82.97179 ],\n",
       "       [110.412735,  40.690693, 219.753   , 143.90091 , 136.95364 ],\n",
       "       [141.7977  ,  96.08033 ,  82.02327 , 136.07146 ,  95.27412 ],\n",
       "       [111.96751 , 137.09079 , 133.85623 ,  44.808296, 157.14606 ],\n",
       "       [ 95.179596, 115.18753 , 151.34016 , 105.466385,  58.554752]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((X_adv_l1 - nn5_rep)**2, axis=(2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([102.87587, 112.11878, 200.72572, 100.779  , 113.49605],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((X_37_test_l1[:5] - target_rep)**2, axis=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEkVJREFUeJzt3W9oVXeaB/DvUzXxv9amplalnUqxtb5whmC3KItt18Etgk7pH1sQt5RxXkzLDgyyxQG39FVZdmbw1UCGkbFTR6cwI1ooW7uyEKTLYCyu1ST+6RCrIcZ/tWpqa6PPvshxiDbnea733HPPic/3A2K8T869v9zcr+cmz/n9fqKqIKJ47ip6AERUDIafKCiGnygohp8oKIafKCiGnygohp8oKIafKCiGnyio0fV8MBHh5YREOVNVqeTzMp35RWSZiBwWkWMi8kaW+yKi+pJqr+0XkVEAjgBYCuAkgL0AXlLVDuMYnvmJclaPM/9CAMdU9W+qehXANgArMtwfEdVRlvDPBHBiyL9PJrfdRETWiki7iLRneCwiqrHcf+Gnqq0AWgG+7Scqkyxn/h4As4f8e1ZyGxGNAFnCvxfAwyLyPRFpALAKwM7aDIuI8lb1235VHRCR1wB8CGAUgE2qeqhmI7tNo0fbX8rAwIBZHzNmTNXHZ10NadSoUWbdu3/ra7969WpVY6oVkfRfPHvPedFjv9NV3eqr6sFy/Jmf4R9e0QFi+OuvLhf5ENHIxfATBcXwEwXF8BMFxfATBcXwEwVVqlaf1RYCsrfUqP7uuiv9/OJ9v69du1b1fQP26+VOfi2x1UdEJoafKCiGnygohp8oKIafKCiGnyioui7dnSev7dPQ0GDWv/7661oOhxLXr19PrY0bN8481mv1NTY2mnXre+q1GfOeUeg9frVup4XJMz9RUAw/UVAMP1FQDD9RUAw/UVAMP1FQDD9RUKXq83ur2For6Fr9ZMC/DsDru1p177G9fvQ333xj1u9UV65cyXS897xbrxdvtWdP1unnZZhSzDM/UVAMP1FQDD9RUAw/UVAMP1FQDD9RUAw/UVCZmp0i0g3gEoBrAAZUtSXj/VVd93Z89XrCY8eONetWX3jy5MnmsT09PWY9q3vuuSe15j2nZ8+erfVwasab79/U1GTWrfn8Wefre7s+e9cwZFlW3LpmxXudD1WLi3yeVNXyvoKIaFh8208UVNbwK4BdIrJPRNbWYkBEVB9Z3/YvVtUeEZkO4CMR6VLVtqGfkPynwP8YiEom05lfVXuSv08D2A5g4TCf06qqLVl/GUhEtVV1+EVkgohMuvExgB8COFirgRFRvrK87W8GsD1pJY0G8EdV/a+ajIqIclf3LbqtvrM3597qYXprAWS9DqDIOffz588360888URq7fHHHzeP3bNnj1n/8ssvzfqHH35o1q1evfecNjc3m3Xve2r14r2vy3s9ffvtt2b9q6++MutZ1jKwMqSq3KKbiGwMP1FQDD9RUAw/UVAMP1FQDD9RUKVauttr9Vl1bwtur97f32/WrZbVo48+ah7rLRO9atUqs3758mWzbrWVdu3aZR7rPS/nz58369737Ny5c2bd4n3d999/v1m3WmLWNGjAb+V5Yxs/frxZz9Lqs55zb1vzm+6n6hEQ0YjG8BMFxfATBcXwEwXF8BMFxfATBcXwEwVV9z5/liWLLd7y2d4US28p53Xr1qXWvGW/H3nkEbP+/PPPm3XveTlw4EBqra2tLbUGAAsXfmfxpZt4026PHz9u1tvb21NrDzzwgHms93V7z+vhw4dTa++99555rLfc+pQpU8y6tWw4YF8/kXX770rxzE8UFMNPFBTDTxQUw08UFMNPFBTDTxQUw08UVKnm83tzkRsbG1Nr3lLM3vxsz9atW1Nr8+bNM4/t7u42697y1941CFZfeOrUqeax06dPN+tLliwx694S1xMnTkytffHFF+ax3loD3nLr1vfFWw792LFjZt36ugC/z299bV4fP+v24jfwzE8UFMNPFBTDTxQUw08UFMNPFBTDTxQUw08UlNvnF5FNAJYDOK2q85PbpgH4E4AHAXQDeEFV7aZtBbyesdX/tK4BAPzeqLcdtLX+fEdHh3msNzf80KFDZj1P27dvN+vLly8362fPnjXrXV1dqTWvV26tBQAA77//vlm35tx7+xF460N46xx4azxY1zjcztr7WVRy5v89gGW33PYGgN2q+jCA3cm/iWgEccOvqm0Abv1vcgWAzcnHmwGsrPG4iChn1f7M36yqvcnHpwDY75mJqHQyX9uvqioiqT+Mi8haAGuzPg4R1Va1Z/4+EZkBAMnfp9M+UVVbVbVFVVuqfCwiykG14d8JYE3y8RoAO2ozHCKqFzf8IrIVwP8CmCsiJ0XkVQBvA1gqIkcB/FPybyIaQdyf+VX1pZTS0zUei7vX+8DAQGrNm88/erT9pXp92zFjxqTWvL3Wvb7t3Llzzbo3t3zSpEmptUuXLpnHPvbYY2bdu/7hxIkTZn3atGmptSNHjpjHLlt2a4f5Zt51Ap2dnak1bw2FGTNmmHXrtQjY14V4x3vXrHhrBVSKV/gRBcXwEwXF8BMFxfATBcXwEwXF8BMFVaqlu72lmC3edGDvvq1WHmBPwfSOvXDhglk/c+aMWfdahd79W8aNG2fWvamv3lbVVjvOa5dZ26ID/nLsW7ZsSa3NnDnTPNZrcVrbfwP+suNWe7hWrTwPz/xEQTH8REEx/ERBMfxEQTH8REEx/ERBMfxEQZWqz++x+t1eL9ybLuz12i3WFtlA/ZZiHo7Xr/amxWa5/gGwp1I//bQ9K7y/v9+se9OV+/r6UmvetNne3l6z7j22d/2D9bx416x4088rxTM/UVAMP1FQDD9RUAw/UVAMP1FQDD9RUAw/UVCl6vN787utfrrXG/Xu21va2zrem1depFmzZpl1b4lqr9998eLFqu9/9erV5rGff/65Wd+wYYNZt14TTU1N5rHe1uPetR3e82KtL1GmLbqJ6A7E8BMFxfATBcXwEwXF8BMFxfATBcXwEwXl9vlFZBOA5QBOq+r85LY3AfwYwI1J8OtV9YOsg/F6p5asvdEsj53lGoG8dXR0mHVva3Nv7rh3/LPPPptaGzt2rHnswYMHzfpnn31m1q2tz7OuFeB9T6dOnWrWrb0WvL0UrHX9VdU8dqhKzvy/BzDcRum/VtUFyZ/MwSei+nLDr6ptAOxtW4hoxMnyM/9rInJARDaJyN01GxER1UW14f8NgDkAFgDoBfDLtE8UkbUi0i4i7VU+FhHloKrwq2qfql5T1esAfgtgofG5raraoqot1Q6SiGqvqvCLyNCpWj8CYP9alohKp5JW31YASwA0ichJAP8OYImILACgALoB/CTHMRJRDuR2+oKZH0ykfg9WR97a9mWe75+3bdu2pdYWLFhgHrty5UqzfvLkSbNu9dqz7uPgXVdizdcH8r32Q1UrumiFV/gRBcXwEwXF8BMFxfATBcXwEwXF8BMFVaqlu7PwpuR6LU1v6W+rtRO5lffcc8+Z9SeffDK1tmPHDvPYrq4us37vvfeadWu6sff99tq3V65cMesTJkww61arr6GhwTz26tWrZr1SPPMTBcXwEwXF8BMFxfATBcXwEwXF8BMFxfATBXXH9PmzTk3Ocny9+rLVyLqs+H333WfWX3/9dbM+fvz41NrGjRvNYz3etFrr+gvv+3358mWz7l0H4C0NbqnX64VnfqKgGH6ioBh+oqAYfqKgGH6ioBh+oqAYfqKg7pg+f1beUsuWvPuykydPNuvWdQZev9nr87/yyitm3bsOoLOzM7Xmbe/t8bbRtubUe1uPZ12OvbGx0axbj+8tK57ltXrT49TkXohoxGH4iYJi+ImCYviJgmL4iYJi+ImCYviJgnL7/CIyG8A7AJoBKIBWVd0oItMA/AnAgwC6Abygql/kN9R8eev+W7L2Zb3jra2mAXvuube+/OLFi836vHnzzPqcOXPM+rp161JrU6ZMMY/1tsn2evUXLlxIrY0bN848NsvrAfDHZqlVH99TyZl/AMDPVXUegH8A8FMRmQfgDQC7VfVhALuTfxPRCOGGX1V7VfWT5ONLADoBzASwAsDm5NM2A1iZ1yCJqPZu62d+EXkQwPcB/BVAs6r2JqVTGPyxgIhGiIqv7ReRiQD+DOBnqnpx6M9EqqoiMuyiaCKyFsDarAMlotqq6MwvImMwGPwtqvqX5OY+EZmR1GcAOD3csaraqqotqtpSiwETUW244ZfBU/zvAHSq6q+GlHYCWJN8vAaAveUqEZVKJW/7FwFYDeBTEdmf3LYewNsA3hORVwEcB/BCPkOsD2/5bav94k3vtJavBrJN/wTslpbn5ZdfNusvvviiWX/33XfN+scff5xaO3r0qHlsnlOlsy717vHat1kev1Zjd8OvqnsApDU9n67JKIio7niFH1FQDD9RUAw/UVAMP1FQDD9RUAw/UVBcujvh9dK9vq3FWx7bm17qLVFtXYOwYcMG89innnrKrO/du9esf/DBB2bd6uXnveS5tfy29/3O2kuv17TcLHjmJwqK4ScKiuEnCorhJwqK4ScKiuEnCorhJwoqTJ/fW4rZ6+tafX6vp2ttFQ0A586dM+uelpb0RZIWLVpkHjt37lyzbi29DQD79u0z6+fPnzfrWYwebb98r127VvV9jxo1KtN9Z3291QPP/ERBMfxEQTH8REEx/ERBMfxEQTH8REEx/ERBhenz59lX9ebjW/PKAWD69OlmvampyayvX78+teb18T3WuvsAcPbs2Uz3b/GeN2+/hCyyXCMAlKOP7+GZnygohp8oKIafKCiGnygohp8oKIafKCiGnygot88vIrMBvAOgGYACaFXVjSLyJoAfAziTfOp6VbUXcR/BrLX3vfn8Xr/am/u9dOlSs/7QQw+l1vr6+sxj29razHp7e7tZ9/rZ1loGV65cMY/Ns4/vPeeekdDH91Rykc8AgJ+r6iciMgnAPhH5KKn9WlX/M7/hEVFe3PCrai+A3uTjSyLSCWBm3gMjonzd1s/8IvIggO8D+Gty02sickBENonI3SnHrBWRdhGx3z8SUV1VHH4RmQjgzwB+pqoXAfwGwBwACzD4zuCXwx2nqq2q2qKq6QvNEVHdVRR+ERmDweBvUdW/AICq9qnqNVW9DuC3ABbmN0wiqjU3/DL4a9HfAehU1V8NuX3GkE/7EYCDtR8eEeWlkt/2LwKwGsCnIrI/uW09gJdEZAEG23/dAH6SywhHgPHjx5t1rxXobeHd09Nj1js6OlJrXV1d5rFvvfWWWW9sbDTrkyZNMutWS6y/v988Nk93Qqsuq0p+278HwHBN0Tu2p08UAa/wIwqK4ScKiuEnCorhJwqK4ScKiuEnCkrq2e8UkdweLOuWyA0NDVUf703Z9bZ79rbwPnXqlFnPwuvje8uKe9NysyztbW2LDmTbVj3r0txlpqoVzVfmmZ8oKIafKCiGnygohp8oKIafKCiGnygohp8oqHr3+c8AOD7kpiYA+e3xnE1Zx1bWcQEcW7VqObYHVPXeSj6xruH/zoOLtJd1bb+yjq2s4wI4tmoVNTa+7ScKiuEnCqro8LcW/PiWso6trOMCOLZqFTK2Qn/mJ6LiFH3mJ6KCFBJ+EVkmIodF5JiIvFHEGNKISLeIfCoi+4veYizZBu20iBwccts0EflIRI4mfw+7TVpBY3tTRHqS526/iDxT0Nhmi8j/iEiHiBwSkX9Nbi/0uTPGVcjzVve3/SIyCsARAEsBnASwF8BLqpq++HwdiUg3gBZVLbwnLCL/COAygHdUdX5y238AOK+qbyf/cd6tqv9WkrG9CeBy0Ts3JxvKzBi6szSAlQD+BQU+d8a4XkABz1sRZ/6FAI6p6t9U9SqAbQBWFDCO0lPVNgDnb7l5BYDNycebMfjiqbuUsZWCqvaq6ifJx5cA3NhZutDnzhhXIYoI/0wAJ4b8+yTKteW3AtglIvtEZG3RgxlGc7JtOgCcAtBc5GCG4e7cXE+37Cxdmueumh2va42/8Puuxar6AwD/DOCnydvbUtLBn9nK1K6paOfmehlmZ+m/K/K5q3bH61orIvw9AGYP+fes5LZSUNWe5O/TALajfLsP993YJDX5+3TB4/m7Mu3cPNzO0ijBc1emHa+LCP9eAA+LyPdEpAHAKgA7CxjHd4jIhOQXMRCRCQB+iPLtPrwTwJrk4zUAdhQ4lpuUZefmtJ2lUfBzV7odr1W17n8APIPB3/h/BuAXRYwhZVwPAfi/5M+hoscGYCsG3wZ+i8HfjbwK4B4AuwEcBfDfAKaVaGx/APApgAMYDNqMgsa2GINv6Q8A2J/8eabo584YVyHPG6/wIwqKv/AjCorhJwqK4ScKiuEnCorhJwqK4ScKiuEnCorhJwrq/wGQf8Gv6DC8kwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "plt.imshow(X_adv[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_37_test[i,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
