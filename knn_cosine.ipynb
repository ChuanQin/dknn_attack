{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from skimage.transform import resize\n",
    "from imageio import imread, imwrite\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "from lib.utils import load_gtsrb\n",
    "\n",
    "from lib.lib_knn import *\n",
    "from lib.knn_attack import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "set_session(sess)\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "import timeit\n",
    "import falconn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[:, :, :, np.newaxis] / 255.\n",
    "X_test = X_test[:, :, :, np.newaxis] / 255.\n",
    "# y_train = y_train[:, np.newaxis]\n",
    "# y_test = y_test[:, np.newaxis]\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nm = X_train/np.sqrt(np.sum(X_train**2, axis=(1, 2, 3), keepdims=True))\n",
    "X_test_nm = X_test/np.sqrt(np.sum(X_test**2, axis=(1, 2, 3), keepdims=True))\n",
    "X_train_nm = X_train_nm.reshape(-1, 784)\n",
    "X_test_nm = X_test_nm.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine(u, v):\n",
    "    \"\"\"\n",
    "    Asssume normalized inputs\n",
    "    \"\"\"\n",
    "    assert u.ndim >= v.ndim\n",
    "    v_rs = v.reshape(-1)\n",
    "    if u.ndim > v.ndim:\n",
    "        u_rs = u.reshape(len(u), -1)\n",
    "#         cdist = np.array([cosine(u_i, v_rs) for u_i in u_rs])\n",
    "        cdist = np.array([1 - np.dot(u_i, v_rs) for u_i in u_rs])\n",
    "    else:\n",
    "        u_rs = u.reshape(-1)\n",
    "#         cdist = cosine(u_rs, v_rs)\n",
    "        cdist = 1 - np.dot(u_rs, v_rs)\n",
    "    return cdist\n",
    "\n",
    "\n",
    "def find_nn(Q, X, k):\n",
    "    assert Q.shape[1:] == X.shape[1:]\n",
    "    nn = np.zeros((len(Q), k), dtype=np.int32)\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    for i, q in enumerate(Q):\n",
    "        ind = np.argsort(compute_cosine(X, q))[:k]\n",
    "        nn[i] = ind\n",
    "    return nn\n",
    "\n",
    "\n",
    "def classify(nn, y_X):\n",
    "    vote = np.array([np.argmax(np.bincount(y)) for y in y_X[nn]])\n",
    "    return vote\n",
    "\n",
    "\n",
    "def find_acc(nn, y_Q, y_X):\n",
    "    vote = classify(nn, y_X)\n",
    "    print(np.mean(vote == y_Q))\n",
    "    \n",
    "    \n",
    "def find_nn_diff_class(Q, y_Q, X, y_X, k):\n",
    "    target = np.zeros((len(Q), k), dtype=np.int32)\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    for i, (q, y_q) in enumerate(zip(Q, y_Q)):\n",
    "        ind = np.argsort(compute_cosine(X, q))\n",
    "        target[i] = ind[y_X[ind] != y_q][:k]\n",
    "    return target\n",
    "\n",
    "\n",
    "def move_to_target(q, y_q, target, X, y_X, k, n_steps=5):\n",
    "    \"\"\"\n",
    "    Move in straight line to target with binary search.\n",
    "    Stop when adv is misclassified.\n",
    "    \"\"\"\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    line = target - q\n",
    "    hi = 1\n",
    "    lo = 0\n",
    "    adv = None\n",
    "    for step in range(n_steps):\n",
    "        mid = (hi + lo)/2\n",
    "        x_new = mid*line + q\n",
    "        new_neighbors = np.argsort(np.sum((X - x_new)**2, axis=axis))[:k]\n",
    "        y_pred = np.argmax(np.bincount(y_X[new_neighbors]))\n",
    "        if y_pred == y_q:\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "            adv = x_new\n",
    "    return adv\n",
    "            \n",
    "    \n",
    "def attack_v2(Q, y_Q, X, y_X, k, n_steps=5):\n",
    "    \"\"\"\n",
    "    Naive attack v2 (untargeted): \n",
    "    Complexity is O(k * n_X log (n_X) * n_Q * n_steps)\n",
    "    \n",
    "    1. Choose trianing sample of target class from X closest to query\n",
    "    2. Find closest sample of the same class to the mean of K\n",
    "    3. Add that sample to K\n",
    "    4. Repeat 2. - 3. until |K| = k/2 + 1\n",
    "    5. Move query closer to mean of K, terminate when query becomes\n",
    "       adversarial\n",
    "    \"\"\"\n",
    "    \n",
    "    nn = find_nn_diff_class(Q, y_Q, X, y_X, 1)\n",
    "    X_adv = np.zeros_like(Q)\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    \n",
    "    for i, (q, y_q) in enumerate(zip(Q, y_Q)):\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        n_neighbors = int(np.floor(k/2) + 1)\n",
    "        K = np.zeros((n_neighbors, ) + Q.shape[1:])\n",
    "                    \n",
    "        # Step 1.\n",
    "        K[0] = X[nn[i, 0]]\n",
    "        K_ind = [nn[i, 0]]\n",
    "\n",
    "        for j in range(1, n_neighbors):\n",
    "            \n",
    "            # Step 2.\n",
    "            mean = np.mean(K[:j], axis=0)\n",
    "            ind = np.argsort(np.sum((X - mean)**2, axis=axis))\n",
    "            new_nbs = ind[y_X[ind] != y_q]\n",
    "            \n",
    "            # Step 3.\n",
    "            for new_nb in new_nbs:\n",
    "                if new_nb not in K_ind:\n",
    "                    K_ind.append(new_nb)\n",
    "                    K[j] = X[new_nb]\n",
    "                    break\n",
    "                    \n",
    "        # Step 5.\n",
    "        mean = np.mean(K, axis=0)\n",
    "        X_adv[i] = move_to_target(q, y_q, mean, X, y_X, k, n_steps)\n",
    "        \n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing k, l, num_probe: https://github.com/FALCONN-LIB/FALCONN/wiki/LSH-Primer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_lsh(X, num_probes=100):\n",
    "    assert X.ndim == 2\n",
    "    params_cp = falconn.LSHConstructionParameters()\n",
    "    params_cp.dimension = X.shape[1]\n",
    "    params_cp.lsh_family = falconn.LSHFamily.CrossPolytope\n",
    "    params_cp.distance_function = falconn.DistanceFunction.EuclideanSquared\n",
    "    params_cp.l = 100\n",
    "    params_cp.num_rotations = 1\n",
    "    params_cp.seed = 1234\n",
    "    params_cp.num_setup_threads = 0\n",
    "    params_cp.storage_hash_table = falconn.StorageHashTable.BitPackedFlatHashTable\n",
    "    falconn.compute_number_of_hash_functions(16, params_cp)\n",
    "    \n",
    "    table = falconn.LSHIndex(params_cp)\n",
    "    table.setup(X)\n",
    "    query_object = table.construct_query_object()\n",
    "    query_object.set_num_probes(num_probes)\n",
    "    \n",
    "    return query_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cp = falconn.LSHConstructionParameters()\n",
    "params_cp.dimension = 784\n",
    "params_cp.lsh_family = falconn.LSHFamily.CrossPolytope\n",
    "params_cp.distance_function = falconn.DistanceFunction.EuclideanSquared\n",
    "params_cp.l = 50\n",
    "# we set one rotation, since the data is dense enough,\n",
    "# for sparse data set it to 2\n",
    "params_cp.num_rotations = 1\n",
    "params_cp.seed = 1234\n",
    "# we want to use all the available threads to set up\n",
    "params_cp.num_setup_threads = 0\n",
    "params_cp.storage_hash_table = falconn.StorageHashTable.BitPackedFlatHashTable\n",
    "# we build 18-bit hashes so that each table has\n",
    "# 2^18 bins; this is a good choise since 2^18 is of the same\n",
    "# order of magnitude as the number of data points\n",
    "falconn.compute_number_of_hash_functions(16, params_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = falconn.LSHIndex(params_cp)\n",
    "table.setup(X_train_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_object = table.construct_query_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_object.set_num_probes(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "402.54560889001004\n"
     ]
    }
   ],
   "source": [
    "# k=1, l=50, t=50\n",
    "nn_lsh = np.zeros((len(X_test), 75))\n",
    "t1 = timeit.default_timer()\n",
    "for i, x in enumerate(X_test_nm):\n",
    "    nn_lsh[i] = query_object.find_k_nearest_neighbors(x, 75)\n",
    "t2 = timeit.default_timer()\n",
    "acc = np.mean(nn_lsh == nn)\n",
    "print(acc)\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989744\n",
      "161.95659640501253\n"
     ]
    }
   ],
   "source": [
    "# k=2, l=200, t=200\n",
    "nn_lsh = np.zeros((len(X_test), 75))\n",
    "t1 = timeit.default_timer()\n",
    "for i, x in enumerate(X_test_nm):\n",
    "    nn_lsh[i] = query_object.find_k_nearest_neighbors(x, 75)\n",
    "t2 = timeit.default_timer()\n",
    "acc = np.mean(nn_lsh == nn)\n",
    "print(acc)\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973226666666667\n",
      "208.35451043001376\n"
     ]
    }
   ],
   "source": [
    "# k=2, l=300, t=300\n",
    "nn_lsh = np.zeros((len(X_test), 75))\n",
    "t1 = timeit.default_timer()\n",
    "for i, x in enumerate(X_test_nm):\n",
    "    nn_lsh[i] = query_object.find_k_nearest_neighbors(x, 75)\n",
    "t2 = timeit.default_timer()\n",
    "acc = np.mean(nn_lsh == nn)\n",
    "print(acc)\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "902.5806880800519\n"
     ]
    }
   ],
   "source": [
    "nn_lsh = np.zeros((len(X_test), 75))\n",
    "t1 = timeit.default_timer()\n",
    "for i, x in enumerate(X_test_nm):\n",
    "    nn_lsh[i] = np.argsort(compute_cosine(X_train_nm, x))[:75]\n",
    "t2 = timeit.default_timer()\n",
    "acc = np.mean(nn_lsh == nn)\n",
    "print(acc)\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8886093333333334\n",
      "107.8704757199157\n"
     ]
    }
   ],
   "source": [
    "nn_lsh = np.zeros((len(X_test), 75))\n",
    "t1 = timeit.default_timer()\n",
    "for i, x in enumerate(X_test_nm):\n",
    "    nn_lsh[i] = query_object.find_k_nearest_neighbors(x, 75)\n",
    "t2 = timeit.default_timer()\n",
    "acc = np.mean(nn_lsh == nn)\n",
    "print(acc)\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "0.9517306666666666\n",
      "161.63525019795634\n",
      "775\n",
      "0.9716373333333334\n",
      "188.16776536405087\n",
      "887\n",
      "0.9776586666666667\n",
      "197.0630873311311\n",
      "943\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-e84822e09d7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnn_lsh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_k_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_lsh\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/falconn/__init__.py\u001b[0m in \u001b[0;36mfind_k_nearest_neighbors\u001b[0;34m(self, query, k)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'k must be positive rather than {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_entity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_k_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_near_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hi = 1e3\n",
    "lo = 1e2\n",
    "import timeit\n",
    "\n",
    "for _ in range(5):\n",
    "    probe = int((hi + lo) / 2)\n",
    "    print(probe)\n",
    "#     params_cp.l = probe\n",
    "#     table = falconn.LSHIndex(params_cp)\n",
    "#     table.setup(X_train_nm)\n",
    "#     query_object = table.construct_query_object()\n",
    "    query_object.set_num_probes(probe)\n",
    "    \n",
    "    nn_lsh = np.zeros((len(X_test), 75))\n",
    "    t1 = timeit.default_timer()\n",
    "    for i, x in enumerate(X_test_nm):\n",
    "        nn_lsh[i] = query_object.find_k_nearest_neighbors(x, 75)\n",
    "    t2 = timeit.default_timer()\n",
    "    acc = np.mean(nn_lsh == nn)\n",
    "    print(acc)\n",
    "    print(t2 - t1)\n",
    "    if acc > 0.9999:\n",
    "        hi = probe\n",
    "        best_probe = probe\n",
    "    else:\n",
    "        lo = probe\n",
    "\n",
    "print(best_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8886093333333334\n",
      "102.53956407611258\n",
      "0.9874973333333333\n"
     ]
    }
   ],
   "source": [
    "# Ignore order and only consider set of NN\n",
    "\n",
    "# k=2, l=50, t=100\n",
    "nn_lsh = np.zeros((len(X_test), 75))\n",
    "t1 = timeit.default_timer()\n",
    "for i, x in enumerate(X_test_nm):\n",
    "    nn_lsh[i] = query_object.find_k_nearest_neighbors(x, 75)\n",
    "t2 = timeit.default_timer()\n",
    "\n",
    "acc = np.mean(nn_lsh == nn)\n",
    "print(acc)\n",
    "print(t2 - t1)\n",
    "\n",
    "cor = 0\n",
    "for i in range(len(X_test)):\n",
    "    for n in nn_lsh[i]:\n",
    "        if n in nn[i]:\n",
    "            cor += 1\n",
    "print(cor / (len(X_test)*75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7475853333333333\n",
      "65.3898569450248\n",
      "0.9645013333333333\n"
     ]
    }
   ],
   "source": [
    "# k=2, l=50, t=50\n",
    "nn_lsh = np.zeros((len(X_test), 75))\n",
    "t1 = timeit.default_timer()\n",
    "for i, x in enumerate(X_test_nm):\n",
    "    nn_lsh[i] = query_object.find_k_nearest_neighbors(x, 75)\n",
    "t2 = timeit.default_timer()\n",
    "\n",
    "acc = np.mean(nn_lsh == nn)\n",
    "print(acc)\n",
    "print(t2 - t1)\n",
    "\n",
    "cor = 0\n",
    "for i in range(len(X_test)):\n",
    "    for n in nn_lsh[i]:\n",
    "        if n in nn[i]:\n",
    "            cor += 1\n",
    "print(cor / (len(X_test)*75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = np.zeros((len(X_test), 75))\n",
    "for i, x in enumerate(X_test_nm):\n",
    "    nn[i] = np.argsort(compute_cosine(X_train, x))[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = pickle.load(open(\"nn_test_cosine.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 139us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03731346611475783, 0.9924]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, Input, Activation\n",
    "\n",
    "inpt = Input(shape=(28, 28, 1))\n",
    "l1 = Conv2D(64, (8, 8), strides=(2, 2), padding='same', activation='relu')(inpt)\n",
    "l2 = Conv2D(128, (6, 6), strides=(2, 2), padding='same', activation='relu')(l1)\n",
    "l3 = Conv2D(128, (5, 5), strides=(1, 1), padding='valid', activation='relu')(l2)\n",
    "flat = Flatten()(l3)\n",
    "l4 = Dense(10, activation=None)(flat)\n",
    "out = Activation('softmax')(l4)\n",
    "\n",
    "model = Model(inputs=inpt, outputs=out)\n",
    "l1_rep = Model(inputs=inpt, outputs=l1)\n",
    "l2_rep = Model(inputs=inpt, outputs=l2)\n",
    "l3_rep = Model(inputs=inpt, outputs=l3)\n",
    "l4_rep = Model(inputs=inpt, outputs=l4)\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(1e-3),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=15,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_test, y_test))\n",
    "\n",
    "# model.save_weights('keras_weights/mnist_cnn.h5')\n",
    "\n",
    "model.load_weights('keras_weights/mnist_cnn.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_ts = [l1_rep, l2_rep, l3_rep, l4_rep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly chosen calibrate set 75 samples from each class\n",
    "ind_cal = np.zeros((750, ), dtype=np.int32)\n",
    "for i in range(10):\n",
    "    ind = np.where(y_test == i)[0]\n",
    "    np.random.shuffle(ind)\n",
    "    ind_cal[i*75 : (i + 1)*75] = ind[:75]\n",
    "ind_test = np.arange(len(X_test), dtype=np.int32)\n",
    "ind_test = np.setdiff1d(ind_test, ind_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cal = X_test[ind_cal]\n",
    "y_cal = y_test[ind_cal]\n",
    "X_test = X_test[ind_test]\n",
    "y_test = y_test[ind_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_train_nm = get_all_rep_nm(sess, X_train, rep_ts)\n",
    "rep_test_nm = get_all_rep_nm(sess, X_test, rep_ts)\n",
    "rep_cal_nm = get_all_rep_nm(sess, X_cal, rep_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy of LSH on representation of cal set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = []\n",
    "for l in range(len(rep_cal_nm)):\n",
    "    nnl = np.zeros((len(rep_cal_nm[0]), 75))\n",
    "    for i, x in enumerate(rep_cal_nm[l]):\n",
    "        nnl[i] = np.argsort(compute_cosine(rep_train_nm[l], x))[:75]\n",
    "    nn.append(nnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.5414222222222222\n",
      "29.703716783085838\n",
      "0.9038933333333333\n",
      "1\n",
      "0.4805333333333333\n",
      "10.252685402985662\n",
      "0.8605155555555556\n",
      "2\n",
      "0.8453155555555556\n",
      "3.362640169914812\n",
      "0.9736177777777778\n",
      "3\n",
      "0.9565688888888889\n",
      "1.0621919420082122\n",
      "0.9951288888888888\n"
     ]
    }
   ],
   "source": [
    "for l, rep in enumerate(rep_train_nm):\n",
    "    \n",
    "    print(l)\n",
    "    query = setup_lsh(rep, 50)\n",
    "    nn_lsh = np.zeros((len(rep_cal_nm[l]), 75))\n",
    "    \n",
    "    t1 = timeit.default_timer()\n",
    "    for i, x in enumerate(rep_cal_nm[l]):\n",
    "        nn_lsh[i] = query.find_k_nearest_neighbors(x, 75)\n",
    "    t2 = timeit.default_timer()\n",
    "    acc = np.mean(nn_lsh == nn[l])\n",
    "    print(acc)\n",
    "    print(t2 - t1)\n",
    "    cor = 0\n",
    "    for i in range(len(rep_cal_nm[l])):\n",
    "        for n in nn_lsh[i]:\n",
    "            if n in nn[l][i]:\n",
    "                cor += 1\n",
    "    print(cor / (len(rep_cal_nm[l])*75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.7146488888888889\n",
      "52.47372901183553\n",
      "0.9571733333333333\n",
      "1\n",
      "0.6457777777777778\n",
      "19.432745156111196\n",
      "0.9277333333333333\n",
      "2\n",
      "0.9175644444444444\n",
      "5.8617943280842155\n",
      "0.9886222222222222\n",
      "3\n",
      "0.9655111111111111\n",
      "1.452528720954433\n",
      "0.9961066666666667\n"
     ]
    }
   ],
   "source": [
    "for l, rep in enumerate(rep_train_nm):\n",
    "    \n",
    "    print(l)\n",
    "    query = setup_lsh(rep, 100)\n",
    "    nn_lsh = np.zeros((len(rep_cal_nm[l]), 75))\n",
    "    \n",
    "    t1 = timeit.default_timer()\n",
    "    for i, x in enumerate(rep_cal_nm[l]):\n",
    "        nn_lsh[i] = query.find_k_nearest_neighbors(x, 75)\n",
    "    t2 = timeit.default_timer()\n",
    "    acc = np.mean(nn_lsh == nn[l])\n",
    "    print(acc)\n",
    "    print(t2 - t1)\n",
    "    cor = 0\n",
    "    for i in range(len(rep_cal_nm[l])):\n",
    "        for n in nn_lsh[i]:\n",
    "            if n in nn[l][i]:\n",
    "                cor += 1\n",
    "    print(cor / (len(rep_cal_nm[l])*75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.81344\n",
      "51.455603271955624\n",
      "0.9736177777777778\n",
      "1\n",
      "0.7333866666666666\n",
      "18.230628283927217\n",
      "0.9495644444444444\n",
      "2\n",
      "0.9523911111111111\n",
      "5.156674404162914\n",
      "0.9939555555555556\n",
      "3\n",
      "0.9674311111111111\n",
      "1.8746885349974036\n",
      "0.9968\n"
     ]
    }
   ],
   "source": [
    "# l=100\n",
    "\n",
    "for l, rep in enumerate(rep_train_nm):\n",
    "    \n",
    "    print(l)\n",
    "    query = setup_lsh(rep, 100)\n",
    "    nn_lsh = np.zeros((len(rep_cal_nm[l]), 75))\n",
    "    \n",
    "    t1 = timeit.default_timer()\n",
    "    for i, x in enumerate(rep_cal_nm[l]):\n",
    "        nn_lsh[i] = query.find_k_nearest_neighbors(x, 75)\n",
    "    t2 = timeit.default_timer()\n",
    "    acc = np.mean(nn_lsh == nn[l])\n",
    "    print(acc)\n",
    "    print(t2 - t1)\n",
    "    cor = 0\n",
    "    for i in range(len(rep_cal_nm[l])):\n",
    "        for n in nn_lsh[i]:\n",
    "            if n in nn[l][i]:\n",
    "                cor += 1\n",
    "    print(cor / (len(rep_cal_nm[l])*75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy of deep kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = []\n",
    "for rep in rep_train_nm:\n",
    "    query.append(setup_lsh(rep, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute multiset A from cal set\n",
    "A = []\n",
    "\n",
    "for l in range(4):\n",
    "    print(l)\n",
    "    nn = query_nn(query[l], rep_cal_nm[l], 75)\n",
    "    bincount = [np.bincount(y, minlength=10) for y in y_train[nn]]\n",
    "    A_l = []\n",
    "    for j, b in enumerate(bincount):\n",
    "        label = y_cal[j]\n",
    "        A_l.append(75 - b[label])\n",
    "    A.append(np.array(A_l))\n",
    "A = np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(A, open(\"A_cosine_lsh.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pickle.load(open(\"A_cosine_lsh.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas, sum_alphas = dknn_classify(A, rep_test_nm, query, y_train)\n",
    "alphas, sum_alphas = dknn_classify(rep_test_nm, query, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sum = np.sum(A, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   3,  80,   2,\n",
       "         0,   0,   0,   2,   0,   0,   0,   0,   8,   0,   8,   2,   0,\n",
       "         0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   3,  10,   0,\n",
       "         3,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "         0,   0, 207,   0,   0,   0,   0,   0,  25,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,  84,   2,\n",
       "         0,   1,   6,  93,   0,   0,   0,   1,   0,  15,   0,   0,   1,\n",
       "         2,   1, 133,   0,   0,  10,  12,   0,  13,   0,   2,   2,  19,\n",
       "        21,   1,   0,   0,   1,   0,   0,   0, 271,  10,   5,   0,  13,\n",
       "        46,   0,   7, 101,   0,   0,  31,   1,   0,  10,   0,   0,   4,\n",
       "         0,  76,   0,   0,   0,   0,   0,   0,   0, 111,  11,   0,   0,\n",
       "         1,  15,  11,   3,   2,  10,   0,   1,   9,   0,  13,   1,   0,\n",
       "         0,   0,   1,  82,   0,  33,  86,   0,   8,  46,  24,   0,   2,\n",
       "        42,   0,   3,   3,   0,   1,  74,   0,   5,   1,   9,   3,   0,\n",
       "        69,   0,  12,   4,   0,   0,  77,   1,   0,   0,  12,  13,   0,\n",
       "         9, 119,   0,  73,  12,   5,  69,   0,   0,   2,   4,   0,  17,\n",
       "         1,   0,   0,  22,   4,  33,   0,   4,   2,   5,   2,   0,   9,\n",
       "         2,   0,  55,   4,  30,  42,   7,  19,   0,   0,   7,   4,   1,\n",
       "         8,   4,   0,   5,   0,  36,   1,   0,   0,  20,   0,  78,   0,\n",
       "         0,   0,   0,   0,  14,   0,   1,   0,   0,   2,   0,   3,  12,\n",
       "         3,   7,   1,   0,  92, 109,   2,   0,  33,   7,  11,   3,   1,\n",
       "         0,   3,  16,  52,  13,   5,   0,  14,   2,  28,  14,  44,  20,\n",
       "         0,   0,  30,   5,   1,   0,   0,   0,   0,   0,  80,   3,   0,\n",
       "         0,   0,   0,  19,  25,   0,  42,   0,   0,   2,  11,   0,   1,\n",
       "         4,   2,   3,  11,   1,   7,  26,  13,   7,   3,   1,   0,   0,\n",
       "        12,  15,  23,   1,   1,   0,  21,   0,  60,   0,  32,   0,   8,\n",
       "        13,   9,  12,  29,   0,   0,   0,  24,   0,   1,   1,  10,  11,\n",
       "         0,  34,   1,   0,   0,   2,   0,  25,  21,   0,   0,   0,   0,\n",
       "         6,  13,   5,   3,  44,   8,   0,  13,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  64,   4,   0,   0,   0,   0,   1,   0,   0,\n",
       "         0,   1,   0,  16,   0,   0,   9,   0,   1,   6,   0,   0,   0,\n",
       "         5,   0,   0,  30,   6,   1,   0,   1,   0,   0,   0,   0,   0,\n",
       "        61,   0,   0,   0,   0,   0,   0,   3,   1,  12,   0,   4,   0,\n",
       "         0,   2,   0,   0,   0,   0, 256,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   1,   0,  16,   0,   0,   0,   1,   0,   0,   0,  39,\n",
       "         0,   0,   0,  14,   3,  29,   0,   0,  14,   0,  17,   3,   4,\n",
       "         0,   0,   0,   0,   0, 218,   0,   0,  32,   0,  16,   0, 121,\n",
       "         0,  38,   0,   0,  53,   1,   0,   0,   0,  31,   0,   0,   0,\n",
       "         0,   0,   0,   0,  86,  11,   0,   2,   0,   0,  21,   0,   0,\n",
       "         0,   1,   0,   0,   0,   2,   4,   9,   1,   0,   2,  24,   5,\n",
       "         0,   2,  18,   0,   0,   0,   2,   1,  14,   0,   0,   0,   0,\n",
       "        95,   2,   0,   0,   0,   0,   1,   0,   0,   7,   0,   4,  11,\n",
       "         1, 114,  34,   0,   0,  46,   4,   1,  43,   0,  38,   3,   1,\n",
       "         0,   0,   0,   2,  62,   2,  39,  87,   3,   1,  16,  38,  26,\n",
       "         6,   3,   1,   3,   9,   0,  50,   1,   2,   0,  63,   0,  49,\n",
       "         0,   0,   0,  93,   0, 138,  13,   3,   0,  63,  26,  29,   5,\n",
       "        52,   0,   0,  46,   4,  11,   7,   0,   1, 129,   2,   2,   0,\n",
       "         4,   1,   4,  18,   0,   1,   2,   1,  65,   1,   1,  16,  61,\n",
       "         0,  22,   2,  12,   2,   1,   1,   1,   0,   0,  28,   3,   5,\n",
       "        90,   0,   2,  71,   2,   0,   1,   0,  10,  11,   6,   0,   0,\n",
       "         1,   3,  47,   2,   9,   0,   0,   6, 173, 120,  19,  14,   0,\n",
       "         0,   1,   0,   0,   1,   9,   5,   1,  11])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros((len(X_test), 10))\n",
    "sum_A = np.sum(A, 0)\n",
    "\n",
    "for i, s in enumerate(sum_alphas):\n",
    "    p[i] = np.array([np.sum(ss <= sum_A) for ss in s]) / len(sum_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 832.,  744., 1039.,  799.,  777.,    0.,    0.,    0.,    0.,\n",
       "        5059.]),\n",
       " array([0.00533333, 0.1048    , 0.20426667, 0.30373333, 0.4032    ,\n",
       "        0.50266667, 0.60213333, 0.7016    , 0.80106667, 0.90053333,\n",
       "        1.        ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.max(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.47866667, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883243243243244"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.argmax(p, 1) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(alphas, open(\"alphas_test.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Attack Baseline (from paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = X_train[y_train == 3]\n",
    "X_7 = X_train[y_train == 7]\n",
    "X_37 = X_train[(y_train == 3) | (y_train == 7)]\n",
    "y_37 = y_train[(y_train == 3) | (y_train == 7)]\n",
    "X_37_test = X_test[(y_test == 3) | (y_test == 7)]\n",
    "y_37_test = y_test[(y_test == 3) | (y_test == 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_37_test = [rep[(y_test == 3) | (y_test == 7)] for rep in rep_test_nm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineAttack(object):\n",
    "    \n",
    "    def __init__(self, sess, model, get_rep, X, X_rep, y_X, \n",
    "                 pert_norm=2, batch_size=1000, lr=1e-3, \n",
    "                 abort_early=True, init_const=1, min_dist=1,\n",
    "                 pert_bound=0.3):\n",
    "        \"\"\"\n",
    "        X_rep must be normalized\n",
    "        \"\"\"\n",
    "    \n",
    "        self.sess = sess\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.X_rep = X_rep\n",
    "        self.y_X = y_X\n",
    "        self.batch_size = batch_size\n",
    "        self.abort_early = abort_early\n",
    "        self.init_const = init_const\n",
    "        self.min_dist = min_dist\n",
    "        self.pert_norm = pert_norm\n",
    "        self.pert_bound = pert_bound\n",
    "        \n",
    "        input_ndim = X.ndim\n",
    "        input_axis = np.arange(1, input_ndim)\n",
    "        input_shape = (batch_size, ) + X.shape[1:]\n",
    "        rep_ndim = X_rep.ndim\n",
    "        rep_axis = np.arange(1, rep_ndim)\n",
    "        rep_shape = (batch_size, ) + X_rep.shape[1:]\n",
    "\n",
    "        # Objective variable\n",
    "        modifier = tf.Variable(np.zeros(input_shape), dtype=tf.float32)\n",
    "\n",
    "        # These are variables to be more efficient in sending data to tf\n",
    "        q_var = tf.Variable(np.zeros(input_shape), dtype=tf.float32, name='q_var')\n",
    "        target_var = tf.Variable(np.zeros(rep_shape), dtype=tf.float32, name='target_var')\n",
    "        const_var = tf.Variable(\n",
    "            np.zeros(batch_size), dtype=tf.float32, name='const_var')\n",
    "\n",
    "        # and here's what we use to assign them\n",
    "        self.assign_q = tf.placeholder(tf.float32, input_shape, name='assign_q')\n",
    "        self.assign_target = tf.placeholder(tf.float32, rep_shape, name='assign_target')\n",
    "        self.assign_const = tf.placeholder(\n",
    "            tf.float32, [batch_size], name='assign_const')\n",
    "\n",
    "        # Clip to ensure pixel value is between 0 and 1\n",
    "        self.new_q = tf.clip_by_value(q_var + modifier, 0., 1.)\n",
    "        # Get reprentation tensor\n",
    "        rep = get_rep(self.new_q)\n",
    "        rep = tf.reshape(rep, [batch_size, -1])\n",
    "        self.rep = rep / tf.norm(rep, axis=1, keepdims=True)\n",
    "\n",
    "        # L2 perturbation loss\n",
    "        l2dist = tf.reduce_sum(tf.square(modifier), input_axis)\n",
    "        self.l2dist = tf.maximum(0., l2dist - self.pert_bound**2)\n",
    "        # Similarity loss\n",
    "        dist_loss = tf.reduce_sum(tf.square(self.rep - target_var), rep_axis)\n",
    "        self.dist_loss = tf.maximum(0., dist_loss - self.min_dist**2)\n",
    "        \n",
    "        # Setup optimizer\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        if pert_norm == 2:\n",
    "            # For L-2 norm constraint, we use Adam optimizer with\n",
    "            # a penalty term\n",
    "            self.loss = tf.reduce_mean(const_var*self.dist_loss + self.l2dist)\n",
    "            optimizer = tf.train.AdamOptimizer(lr)\n",
    "            self.train_step = optimizer.minimize(self.loss, var_list=[modifier])\n",
    "        elif pert_norm == np.inf:\n",
    "            # For L-inf norm constraint, we use L-BFGS-B optimizer \n",
    "            # to provide correct bound, optimizer setup is moved to attack()\n",
    "            self.loss = tf.reduce_mean(self.dist_loss)\n",
    "            self.modifier = modifier\n",
    "        else:\n",
    "            raise ValueError('Invalid choice for perturbation norm!')\n",
    "            \n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "\n",
    "        self.setup = []\n",
    "        self.setup.append(q_var.assign(self.assign_q))\n",
    "        self.setup.append(target_var.assign(self.assign_target))\n",
    "        self.setup.append(const_var.assign(self.assign_const))\n",
    "        self.init = tf.variables_initializer(var_list=[modifier] + new_vars)\n",
    "        \n",
    "    def attack(self, Q, Q_rep, y_Q, bin_search_steps=5, max_iter=200):\n",
    "        r = []\n",
    "        for i in range(0, len(Q), self.batch_size):\n",
    "            print(\"Running Baseline Attack on instance {} of {}\".format(\n",
    "                i, len(Q)))\n",
    "            r.extend(self.attack_batch(Q[i:i + self.batch_size],\n",
    "                                       Q_rep[i:i + self.batch_size],\n",
    "                                       y_Q[i:i + self.batch_size],\n",
    "                                       bin_search_steps=bin_search_steps,\n",
    "                                       max_iter=max_iter))\n",
    "        return np.array(r)\n",
    "\n",
    "        \n",
    "    def attack_batch(self, Q, Q_rep, y_Q, bin_search_steps=5, max_iter=200):   \n",
    "        \n",
    "        # Find closest rep of different class\n",
    "        print(\"  Finding nn representation as target...\")\n",
    "        nn = find_nn_diff_class(Q_rep, y_Q, self.X_rep, self.y_X, 1)\n",
    "        target_rep = np.squeeze(self.X_rep[nn])\n",
    "        # Find nn to target rep to save nn search time during optimization\n",
    "        # check_rep = find_nn(target_rep, self.X_rep, 100)\n",
    "        \n",
    "        # ============ Optimizing with L-inf norm constraints =========== #\n",
    "        # L-BFGS-B optimizer only needs to be called once\n",
    "        if self.pert_norm == np.inf:\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            target_rep_batch = target_rep[:self.batch_size]\n",
    "            const = np.ones(self.batch_size) * self.init_const\n",
    "            \n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            self.sess.run(\n",
    "                self.setup, {\n",
    "                    self.assign_q: Q_batch,\n",
    "                    self.assign_target: target_rep_batch,\n",
    "                    self.assign_const: const\n",
    "                })\n",
    "            \n",
    "            # Set up variables bound and optimizer\n",
    "            upper_bound = np.minimum(self.pert_bound, 1 - Q_batch)\n",
    "            lower_bound = np.maximum(-self.pert_bound, -Q_batch)\n",
    "            var_to_bounds = {self.modifier: (lower_bound, upper_bound)}\n",
    "            optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                self.loss, \n",
    "                var_list=[self.modifier], \n",
    "                var_to_bounds=var_to_bounds, \n",
    "                method='L-BFGS-B')\n",
    "            \n",
    "            # Call optimizer\n",
    "            optimizer.minimize(self.sess)\n",
    "            return self.sess.run(self.new_q)\n",
    "            \n",
    "        # ============= Optimizing with L2 norm constraints ============ #\n",
    "        o_bestl2 = [1e9] * self.batch_size\n",
    "        o_bestadv = np.zeros_like(Q[:self.batch_size])\n",
    "        \n",
    "        # Set the lower and upper bounds\n",
    "        lower_bound = np.zeros(self.batch_size)\n",
    "        const = np.ones(self.batch_size) * self.init_const\n",
    "        upper_bound = np.ones(self.batch_size) * 1e9\n",
    "       \n",
    "        for outer_step in range(bin_search_steps):\n",
    "\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            target_rep_batch = target_rep[:self.batch_size]\n",
    "            \n",
    "            bestl2 = [1e9] * self.batch_size\n",
    "            bestadv = np.zeros_like(Q_batch)\n",
    "            print(\"  Binary search step {} of {}\".format(\n",
    "                outer_step, bin_search_steps))\n",
    "\n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            self.sess.run(\n",
    "                self.setup, {\n",
    "                    self.assign_q: Q_batch,\n",
    "                    self.assign_target: target_rep_batch,\n",
    "                    self.assign_const: const\n",
    "                })\n",
    "\n",
    "            prev = 1e6\n",
    "            for iteration in range(max_iter):\n",
    "                # Take one step in optimization\n",
    "                _, l, l2s, dls, reps, qs = self.sess.run([self.train_step, \n",
    "                                                          self.loss, \n",
    "                                                          self.l2dist,\n",
    "                                                          self.dist_loss,\n",
    "                                                          self.rep, \n",
    "                                                          self.new_q])\n",
    "                \n",
    "                if iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    print((\"    Iteration {} of {}: loss={:.3g} l2={:.3g}\").format(\n",
    "                        iteration, max_iter, l, np.mean(l2s)))\n",
    "                \n",
    "                # Abort early if stop improving\n",
    "                if self.abort_early and iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    if l > prev * .9999:\n",
    "                        print(\"    Failed to make progress; stop early\")\n",
    "                        break\n",
    "                    prev = l\n",
    "                \n",
    "                # Check termination condition\n",
    "                suc_ind = np.where(dls <= 1e-1)[0]\n",
    "                for ind in suc_ind:\n",
    "                    if l2s[ind] < bestl2[ind]:\n",
    "                        bestl2[ind] = l2s[ind]\n",
    "                        bestadv[ind] = qs[ind]\n",
    "\n",
    "                        \n",
    "            # Adjust const according to results\n",
    "            for e in range(self.batch_size):\n",
    "                if bestl2[e] < 1e9:\n",
    "                    # Success, divide const by two\n",
    "                    upper_bound[e] = min(upper_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    if bestl2[e] < o_bestl2[e]:\n",
    "                        o_bestl2[e] = bestl2[e]\n",
    "                        o_bestadv[e] = bestadv[e]\n",
    "                else:\n",
    "                    # Failure, either multiply by 10 if no solution found yet\n",
    "                    #          or do binary search with the known upper bound\n",
    "                    lower_bound[e] = max(lower_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    else:\n",
    "                        const[e] *= 10\n",
    "                        \n",
    "        return o_bestadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BaselineAttack(sess, model, l1_rep, \n",
    "                          X_train, rep_train_nm[0], y_train, \n",
    "                          pert_norm=np.inf,\n",
    "                          batch_size=5, \n",
    "                          min_dist=0.1,\n",
    "                          pert_bound=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 5\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.169774\n",
      "  Number of iterations: 56\n",
      "  Number of functions evaluations: 57\n"
     ]
    }
   ],
   "source": [
    "X_adv = baseline.attack(X_37_test[:5], rep_37_test[0][:5], y_37_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BaselineAttack(sess, model, l1_rep, \n",
    "                          X_train, rep_train_nm[0], y_train, \n",
    "                          pert_norm=2,\n",
    "                          batch_size=5, \n",
    "                          lr=1e-2, \n",
    "                          abort_early=True,\n",
    "                          init_const=1, \n",
    "                          min_dist=0.1,\n",
    "                          pert_bound=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 5\n",
      "  Finding nn representation as target...\n",
      "  Binary search step 0 of 5\n",
      "    Iteration 0 of 500: loss=0.625 l2=0\n",
      "    Iteration 50 of 500: loss=0.616 l2=0.00928\n",
      "    Iteration 100 of 500: loss=0.616 l2=0.0093\n",
      "    Failed to make progress; stop early\n",
      "  Binary search step 1 of 5\n",
      "    Iteration 0 of 500: loss=6.25 l2=0\n",
      "    Iteration 50 of 500: loss=5.43 l2=0.747\n",
      "    Iteration 100 of 500: loss=5.43 l2=0.754\n",
      "    Iteration 150 of 500: loss=5.43 l2=0.754\n",
      "    Failed to make progress; stop early\n",
      "  Binary search step 2 of 5\n",
      "    Iteration 0 of 500: loss=62.5 l2=0\n",
      "    Iteration 50 of 500: loss=24.1 l2=12.6\n",
      "    Iteration 100 of 500: loss=22 l2=15.2\n",
      "    Iteration 150 of 500: loss=22 l2=15.2\n",
      "    Iteration 200 of 500: loss=22 l2=15.2\n",
      "    Failed to make progress; stop early\n",
      "  Binary search step 3 of 5\n",
      "    Iteration 0 of 500: loss=270 l2=0\n",
      "    Iteration 50 of 500: loss=70.4 l2=14.1\n",
      "    Iteration 100 of 500: loss=28.2 l2=20.8\n",
      "    Iteration 150 of 500: loss=24.1 l2=20.8\n",
      "    Iteration 200 of 500: loss=23.8 l2=20.5\n",
      "    Iteration 250 of 500: loss=23.7 l2=20.4\n",
      "    Iteration 300 of 500: loss=23.7 l2=20.4\n",
      "    Iteration 350 of 500: loss=23.7 l2=20.4\n",
      "    Iteration 400 of 500: loss=23.7 l2=20.3\n",
      "    Iteration 450 of 500: loss=23.7 l2=20.3\n",
      "    Failed to make progress; stop early\n",
      "  Binary search step 4 of 5\n",
      "    Iteration 0 of 500: loss=155 l2=0\n",
      "    Iteration 50 of 500: loss=45.3 l2=12.8\n",
      "    Iteration 100 of 500: loss=25.1 l2=18.4\n",
      "    Iteration 150 of 500: loss=23.1 l2=19.2\n",
      "    Iteration 200 of 500: loss=22.9 l2=19.1\n",
      "    Iteration 250 of 500: loss=22.9 l2=19.1\n",
      "    Iteration 300 of 500: loss=22.9 l2=19.1\n",
      "    Iteration 350 of 500: loss=22.9 l2=19.1\n",
      "    Failed to make progress; stop early\n"
     ]
    }
   ],
   "source": [
    "X_adv = baseline.attack(X_37_test[:5], rep_37_test[0][:5], y_37_test[:5],\n",
    "                        bin_search_steps=5, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9b6a03a9b0>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_adv[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9b6a1a0908>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_37_test[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test[:5], query, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 5, 7, 3])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.56837978, 3.73891273, 3.92854395, 3.50711337, 3.50198879])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((X_adv - X_37_test[:5])**2, (1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(get_all_rep_nm(X_adv)[0]**2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BaselineAttack(sess, model, l1_rep, \n",
    "                          X_train, rep_train_nm[0], y_train, \n",
    "                          pert_norm=np.inf,\n",
    "                          batch_size=32,\n",
    "                          min_dist=0.1,\n",
    "                          pert_bound=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.176595\n",
      "  Number of iterations: 48\n",
      "  Number of functions evaluations: 49\n",
      "Running Baseline Attack on instance 32 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.149688\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n",
      "Running Baseline Attack on instance 64 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.147744\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n",
      "Running Baseline Attack on instance 96 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.168224\n",
      "  Number of iterations: 55\n",
      "  Number of functions evaluations: 56\n",
      "Running Baseline Attack on instance 128 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.157305\n",
      "  Number of iterations: 57\n",
      "  Number of functions evaluations: 58\n",
      "Running Baseline Attack on instance 160 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.143879\n",
      "  Number of iterations: 37\n",
      "  Number of functions evaluations: 38\n",
      "Running Baseline Attack on instance 192 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.153194\n",
      "  Number of iterations: 66\n",
      "  Number of functions evaluations: 67\n",
      "Running Baseline Attack on instance 224 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.152457\n",
      "  Number of iterations: 46\n",
      "  Number of functions evaluations: 47\n",
      "Running Baseline Attack on instance 256 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.135973\n",
      "  Number of iterations: 43\n",
      "  Number of functions evaluations: 44\n",
      "Running Baseline Attack on instance 288 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.140412\n",
      "  Number of iterations: 38\n",
      "  Number of functions evaluations: 39\n",
      "Running Baseline Attack on instance 320 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.156321\n",
      "  Number of iterations: 57\n",
      "  Number of functions evaluations: 58\n",
      "Running Baseline Attack on instance 352 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.161749\n",
      "  Number of iterations: 45\n",
      "  Number of functions evaluations: 46\n",
      "Running Baseline Attack on instance 384 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.159886\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n",
      "Running Baseline Attack on instance 416 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.147712\n",
      "  Number of iterations: 41\n",
      "  Number of functions evaluations: 42\n",
      "Running Baseline Attack on instance 448 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.149143\n",
      "  Number of iterations: 49\n",
      "  Number of functions evaluations: 50\n",
      "Running Baseline Attack on instance 480 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.163736\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n",
      "Running Baseline Attack on instance 512 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.163350\n",
      "  Number of iterations: 54\n",
      "  Number of functions evaluations: 55\n",
      "Running Baseline Attack on instance 544 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.153746\n",
      "  Number of iterations: 36\n",
      "  Number of functions evaluations: 37\n",
      "Running Baseline Attack on instance 576 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.152573\n",
      "  Number of iterations: 56\n",
      "  Number of functions evaluations: 57\n",
      "Running Baseline Attack on instance 608 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.168292\n",
      "  Number of iterations: 63\n",
      "  Number of functions evaluations: 64\n",
      "Running Baseline Attack on instance 640 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.143227\n",
      "  Number of iterations: 37\n",
      "  Number of functions evaluations: 38\n",
      "Running Baseline Attack on instance 672 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.178077\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n",
      "Running Baseline Attack on instance 704 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.155946\n",
      "  Number of iterations: 49\n",
      "  Number of functions evaluations: 50\n",
      "Running Baseline Attack on instance 736 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.155648\n",
      "  Number of iterations: 40\n",
      "  Number of functions evaluations: 41\n",
      "Running Baseline Attack on instance 768 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.158288\n",
      "  Number of iterations: 47\n",
      "  Number of functions evaluations: 48\n",
      "Running Baseline Attack on instance 800 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.173412\n",
      "  Number of iterations: 46\n",
      "  Number of functions evaluations: 47\n",
      "Running Baseline Attack on instance 832 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.168301\n",
      "  Number of iterations: 46\n",
      "  Number of functions evaluations: 47\n",
      "Running Baseline Attack on instance 864 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.162482\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 896 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.168110\n",
      "  Number of iterations: 49\n",
      "  Number of functions evaluations: 50\n",
      "Running Baseline Attack on instance 928 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.148064\n",
      "  Number of iterations: 50\n",
      "  Number of functions evaluations: 51\n",
      "Running Baseline Attack on instance 960 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.150963\n",
      "  Number of iterations: 43\n",
      "  Number of functions evaluations: 44\n",
      "Running Baseline Attack on instance 992 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.137520\n",
      "  Number of iterations: 48\n",
      "  Number of functions evaluations: 49\n",
      "Running Baseline Attack on instance 1024 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.130621\n",
      "  Number of iterations: 34\n",
      "  Number of functions evaluations: 35\n",
      "Running Baseline Attack on instance 1056 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.162135\n",
      "  Number of iterations: 37\n",
      "  Number of functions evaluations: 38\n",
      "Running Baseline Attack on instance 1088 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.162441\n",
      "  Number of iterations: 50\n",
      "  Number of functions evaluations: 51\n",
      "Running Baseline Attack on instance 1120 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.176906\n",
      "  Number of iterations: 29\n",
      "  Number of functions evaluations: 30\n",
      "Running Baseline Attack on instance 1152 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.160168\n",
      "  Number of iterations: 40\n",
      "  Number of functions evaluations: 41\n",
      "Running Baseline Attack on instance 1184 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.140179\n",
      "  Number of iterations: 56\n",
      "  Number of functions evaluations: 57\n",
      "Running Baseline Attack on instance 1216 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.141432\n",
      "  Number of iterations: 66\n",
      "  Number of functions evaluations: 67\n",
      "Running Baseline Attack on instance 1248 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.154038\n",
      "  Number of iterations: 34\n",
      "  Number of functions evaluations: 35\n",
      "Running Baseline Attack on instance 1280 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.155873\n",
      "  Number of iterations: 58\n",
      "  Number of functions evaluations: 59\n",
      "Running Baseline Attack on instance 1312 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.143053\n",
      "  Number of iterations: 51\n",
      "  Number of functions evaluations: 52\n",
      "Running Baseline Attack on instance 1344 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.119295\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 40\n",
      "Running Baseline Attack on instance 1376 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.134122\n",
      "  Number of iterations: 38\n",
      "  Number of functions evaluations: 39\n",
      "Running Baseline Attack on instance 1408 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.154006\n",
      "  Number of iterations: 36\n",
      "  Number of functions evaluations: 37\n",
      "Running Baseline Attack on instance 1440 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.179955\n",
      "  Number of iterations: 34\n",
      "  Number of functions evaluations: 35\n",
      "Running Baseline Attack on instance 1472 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.163777\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 40\n",
      "Running Baseline Attack on instance 1504 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.136925\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 40\n",
      "Running Baseline Attack on instance 1536 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.164346\n",
      "  Number of iterations: 42\n",
      "  Number of functions evaluations: 43\n",
      "Running Baseline Attack on instance 1568 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.166892\n",
      "  Number of iterations: 43\n",
      "  Number of functions evaluations: 44\n",
      "Running Baseline Attack on instance 1600 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.139727\n",
      "  Number of iterations: 41\n",
      "  Number of functions evaluations: 42\n",
      "Running Baseline Attack on instance 1632 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.150088\n",
      "  Number of iterations: 43\n",
      "  Number of functions evaluations: 44\n",
      "Running Baseline Attack on instance 1664 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.170355\n",
      "  Number of iterations: 38\n",
      "  Number of functions evaluations: 39\n",
      "Running Baseline Attack on instance 1696 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.213783\n",
      "  Number of iterations: 46\n",
      "  Number of functions evaluations: 47\n",
      "Running Baseline Attack on instance 1728 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.165039\n",
      "  Number of iterations: 41\n",
      "  Number of functions evaluations: 42\n",
      "Running Baseline Attack on instance 1760 of 1888\n",
      "  Finding nn representation as target...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.174235\n",
      "  Number of iterations: 61\n",
      "  Number of functions evaluations: 62\n",
      "Running Baseline Attack on instance 1792 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.139979\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 40\n",
      "Running Baseline Attack on instance 1824 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.135444\n",
      "  Number of iterations: 33\n",
      "  Number of functions evaluations: 34\n",
      "Running Baseline Attack on instance 1856 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.116585\n",
      "  Number of iterations: 37\n",
      "  Number of functions evaluations: 38\n"
     ]
    }
   ],
   "source": [
    "X_adv = baseline.attack(X_37_test, rep_37_test[0], y_37_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6091101694915254\n",
      "[7 7 5 ... 3 7 3]\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test, query, y_train)\n",
    "print(acc)\n",
    "print(np.argmax(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "i = 19\n",
    "plt.imshow(X_37_test[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_adv[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "print(np.argmax(p, 1)[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Slightly improved baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nn_diff_class_l2(Q, y_Q, X, y_X, k):\n",
    "    target = np.zeros((len(Q), k), dtype=np.int32)\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    for i, (q, y_q) in enumerate(zip(Q, y_Q)):\n",
    "        ind = np.argsort(np.sum((X - q)**2, axis=axis))\n",
    "        target[i] = ind[y_X[ind] != y_q][:k]\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackV2(object):\n",
    "    \n",
    "    def __init__(self, sess, model, get_rep, X, X_rep, y_X, \n",
    "                 pert_norm=2, batch_size=1000, lr=1e-3, \n",
    "                 abort_early=True, init_const=1, min_dist=1,\n",
    "                 pert_bound=0.3):\n",
    "        \"\"\"\n",
    "        X_rep must be normalized\n",
    "        \"\"\"\n",
    "    \n",
    "        self.sess = sess\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.X_rep = X_rep\n",
    "        self.y_X = y_X\n",
    "        self.batch_size = batch_size\n",
    "        self.abort_early = abort_early\n",
    "        self.init_const = init_const\n",
    "        self.min_dist = min_dist\n",
    "        self.pert_norm = pert_norm\n",
    "        self.pert_bound = pert_bound\n",
    "        \n",
    "        input_ndim = X.ndim\n",
    "        input_axis = np.arange(1, input_ndim)\n",
    "        input_shape = (batch_size, ) + X.shape[1:]\n",
    "        rep_ndim = X_rep.ndim\n",
    "        rep_axis = np.arange(1, rep_ndim)\n",
    "        rep_shape = (batch_size, ) + X_rep.shape[1:]\n",
    "\n",
    "        # Objective variable\n",
    "        modifier = tf.Variable(np.zeros(input_shape), dtype=tf.float32)\n",
    "\n",
    "        # These are variables to be more efficient in sending data to tf\n",
    "        q_var = tf.Variable(np.zeros(input_shape), dtype=tf.float32, name='q_var')\n",
    "        target_var = tf.Variable(np.zeros(rep_shape), dtype=tf.float32, name='target_var')\n",
    "        const_var = tf.Variable(\n",
    "            np.zeros(batch_size), dtype=tf.float32, name='const_var')\n",
    "\n",
    "        # and here's what we use to assign them\n",
    "        self.assign_q = tf.placeholder(tf.float32, input_shape, name='assign_q')\n",
    "        self.assign_target = tf.placeholder(tf.float32, rep_shape, name='assign_target')\n",
    "        self.assign_const = tf.placeholder(\n",
    "            tf.float32, [batch_size], name='assign_const')\n",
    "\n",
    "        # Clip to ensure pixel value is between 0 and 1\n",
    "        self.new_q = tf.clip_by_value(q_var + modifier, 0., 1.)\n",
    "        # Get reprentation tensor\n",
    "        rep = get_rep(self.new_q)\n",
    "        rep = tf.reshape(rep, [batch_size, -1])\n",
    "        self.rep = rep / tf.norm(rep, axis=1, keepdims=True)\n",
    "\n",
    "        # L2 perturbation loss\n",
    "        l2dist = tf.reduce_sum(tf.square(modifier), input_axis)\n",
    "        self.l2dist = tf.maximum(0., l2dist - self.pert_bound**2)\n",
    "        # Similarity loss\n",
    "        dist_loss = tf.reduce_sum(tf.square(self.rep - target_var), rep_axis)\n",
    "        self.dist_loss = tf.maximum(0., dist_loss - self.min_dist**2)\n",
    "        \n",
    "        # Setup optimizer\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        if pert_norm == 2:\n",
    "            # For L-2 norm constraint, we use Adam optimizer with\n",
    "            # a penalty term\n",
    "            self.loss = tf.reduce_mean(const_var*self.dist_loss + self.l2dist)\n",
    "            optimizer = tf.train.AdamOptimizer(lr)\n",
    "            self.train_step = optimizer.minimize(self.loss, var_list=[modifier])\n",
    "        elif pert_norm == np.inf:\n",
    "            # For L-inf norm constraint, we use L-BFGS-B optimizer \n",
    "            # to provide correct bound, optimizer setup is moved to attack()\n",
    "            self.loss = tf.reduce_mean(self.dist_loss)\n",
    "            self.modifier = modifier\n",
    "        else:\n",
    "            raise ValueError('Invalid choice for perturbation norm!')\n",
    "            \n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "\n",
    "        self.setup = []\n",
    "        self.setup.append(q_var.assign(self.assign_q))\n",
    "        self.setup.append(target_var.assign(self.assign_target))\n",
    "        self.setup.append(const_var.assign(self.assign_const))\n",
    "        self.init = tf.variables_initializer(var_list=[modifier] + new_vars)\n",
    "        \n",
    "    def attack(self, Q, Q_rep, y_Q, bin_search_steps=5, max_iter=200):\n",
    "        r = []\n",
    "        for i in range(0, len(Q), self.batch_size):\n",
    "            print(\"Running Baseline Attack on instance {} of {}\".format(\n",
    "                i, len(Q)))\n",
    "            r.extend(self.attack_batch(Q[i:i + self.batch_size],\n",
    "                                       Q_rep[i:i + self.batch_size],\n",
    "                                       y_Q[i:i + self.batch_size],\n",
    "                                       bin_search_steps=bin_search_steps,\n",
    "                                       max_iter=max_iter))\n",
    "        return np.array(r)\n",
    "\n",
    "        \n",
    "    def attack_batch(self, Q, Q_rep, y_Q, bin_search_steps=5, max_iter=200):   \n",
    "        \n",
    "        # Find closest rep of different class\n",
    "        print(\"  Finding nn representation as target...\")\n",
    "        \n",
    "#         nn = find_nn_diff_class(Q_rep, y_Q, self.X_rep, self.y_X, 1)\n",
    "        nn = find_nn_diff_class_l2(Q, y_Q, self.X, self.y_X, 1)\n",
    "\n",
    "        target_rep = np.squeeze(self.X_rep[nn])\n",
    "        # Find nn to target rep to save nn search time during optimization\n",
    "        # check_rep = find_nn(target_rep, self.X_rep, 100)\n",
    "        \n",
    "        # ============ Optimizing with L-inf norm constraints =========== #\n",
    "        # L-BFGS-B optimizer only needs to be called once\n",
    "        if self.pert_norm == np.inf:\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            target_rep_batch = target_rep[:self.batch_size]\n",
    "            const = np.ones(self.batch_size) * self.init_const\n",
    "            \n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            self.sess.run(\n",
    "                self.setup, {\n",
    "                    self.assign_q: Q_batch,\n",
    "                    self.assign_target: target_rep_batch,\n",
    "                    self.assign_const: const\n",
    "                })\n",
    "            \n",
    "            # Set up variables bound and optimizer\n",
    "            upper_bound = np.minimum(self.pert_bound, 1 - Q_batch)\n",
    "            lower_bound = np.maximum(-self.pert_bound, -Q_batch)\n",
    "            var_to_bounds = {self.modifier: (lower_bound, upper_bound)}\n",
    "            optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                self.loss, \n",
    "                var_list=[self.modifier], \n",
    "                var_to_bounds=var_to_bounds, \n",
    "                method='L-BFGS-B')\n",
    "            \n",
    "            # Call optimizer\n",
    "            optimizer.minimize(self.sess)\n",
    "            return self.sess.run(self.new_q)\n",
    "            \n",
    "        # ============= Optimizing with L2 norm constraints ============ #\n",
    "        o_bestl2 = [1e9] * self.batch_size\n",
    "        o_bestadv = np.zeros_like(Q[:self.batch_size])\n",
    "        \n",
    "        # Set the lower and upper bounds\n",
    "        lower_bound = np.zeros(self.batch_size)\n",
    "        const = np.ones(self.batch_size) * self.init_const\n",
    "        upper_bound = np.ones(self.batch_size) * 1e9\n",
    "       \n",
    "        for outer_step in range(bin_search_steps):\n",
    "\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            target_rep_batch = target_rep[:self.batch_size]\n",
    "            \n",
    "            bestl2 = [1e9] * self.batch_size\n",
    "            bestadv = np.zeros_like(Q_batch)\n",
    "            print(\"  Binary search step {} of {}\".format(\n",
    "                outer_step, bin_search_steps))\n",
    "\n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            self.sess.run(\n",
    "                self.setup, {\n",
    "                    self.assign_q: Q_batch,\n",
    "                    self.assign_target: target_rep_batch,\n",
    "                    self.assign_const: const\n",
    "                })\n",
    "\n",
    "            prev = 1e6\n",
    "            for iteration in range(max_iter):\n",
    "                # Take one step in optimization\n",
    "                _, l, l2s, dls, reps, qs = self.sess.run([self.train_step, \n",
    "                                                          self.loss, \n",
    "                                                          self.l2dist,\n",
    "                                                          self.dist_loss,\n",
    "                                                          self.rep, \n",
    "                                                          self.new_q])\n",
    "                \n",
    "                if iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    print((\"    Iteration {} of {}: loss={:.3g} l2={:.3g}\").format(\n",
    "                        iteration, max_iter, l, np.mean(l2s)))\n",
    "                \n",
    "                # Abort early if stop improving\n",
    "                if self.abort_early and iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    if l > prev * .9999:\n",
    "                        print(\"    Failed to make progress; stop early\")\n",
    "                        break\n",
    "                    prev = l\n",
    "                \n",
    "                # Check termination condition\n",
    "                # nn = find_nn(reps, self.X_rep, 1)\n",
    "                # y_pred = classify(nn, self.y_X)\n",
    "                # suc_ind = np.where(y_pred != y_Q)[0]\n",
    "                suc_ind = np.where(dls <= 1e-1)[0]\n",
    "                for ind in suc_ind:\n",
    "                    if l2s[ind] < bestl2[ind]:\n",
    "                        bestl2[ind] = l2s[ind]\n",
    "                        bestadv[ind] = qs[ind]\n",
    "\n",
    "                        \n",
    "            # Adjust const according to results\n",
    "            for e in range(self.batch_size):\n",
    "                if bestl2[e] < 1e9:\n",
    "                    # Success, divide const by two\n",
    "                    upper_bound[e] = min(upper_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    if bestl2[e] < o_bestl2[e]:\n",
    "                        o_bestl2[e] = bestl2[e]\n",
    "                        o_bestadv[e] = bestadv[e]\n",
    "                else:\n",
    "                    # Failure, either multiply by 10 if no solution found yet\n",
    "                    #          or do binary search with the known upper bound\n",
    "                    lower_bound[e] = max(lower_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    else:\n",
    "                        const[e] *= 10\n",
    "                        \n",
    "        return o_bestadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = AttackV2(sess, model, l1_rep, \n",
    "                  X_train, rep_train_nm[0], y_train, \n",
    "                  pert_norm=np.inf,\n",
    "                  batch_size=5, \n",
    "                  min_dist=0,\n",
    "                  pert_bound=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 5\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.200503\n",
      "  Number of iterations: 61\n",
      "  Number of functions evaluations: 62\n"
     ]
    }
   ],
   "source": [
    "X_adv = attack.attack(X_37_test[:5], rep_37_test[0][:5], y_37_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "[7 7 3 9 3]\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test[:5], query, y_train)\n",
    "print(acc)\n",
    "print(np.argmax(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 3\n",
    "plt.imshow(X_37_test[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_adv[i,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6045725 , 3.89791851, 3.98171894, 3.10472688, 3.74187468])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((X_adv - X_37_test[:5])**2, (1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = AttackV2(sess, model, l1_rep, \n",
    "                  X_train, rep_train_nm[0], y_train, \n",
    "                  pert_norm=np.inf,\n",
    "                  batch_size=32,\n",
    "                  min_dist=0.,\n",
    "                  pert_bound=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.200702\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n",
      "Running Baseline Attack on instance 32 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.185852\n",
      "  Number of iterations: 51\n",
      "  Number of functions evaluations: 52\n",
      "Running Baseline Attack on instance 64 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.188620\n",
      "  Number of iterations: 46\n",
      "  Number of functions evaluations: 47\n",
      "Running Baseline Attack on instance 96 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.202556\n",
      "  Number of iterations: 49\n",
      "  Number of functions evaluations: 50\n",
      "Running Baseline Attack on instance 128 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.187034\n",
      "  Number of iterations: 55\n",
      "  Number of functions evaluations: 56\n",
      "Running Baseline Attack on instance 160 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.178478\n",
      "  Number of iterations: 35\n",
      "  Number of functions evaluations: 36\n",
      "Running Baseline Attack on instance 192 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.190678\n",
      "  Number of iterations: 58\n",
      "  Number of functions evaluations: 59\n",
      "Running Baseline Attack on instance 224 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.180982\n",
      "  Number of iterations: 60\n",
      "  Number of functions evaluations: 61\n",
      "Running Baseline Attack on instance 256 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.185214\n",
      "  Number of iterations: 42\n",
      "  Number of functions evaluations: 43\n",
      "Running Baseline Attack on instance 288 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.178330\n",
      "  Number of iterations: 37\n",
      "  Number of functions evaluations: 38\n",
      "Running Baseline Attack on instance 320 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.184394\n",
      "  Number of iterations: 62\n",
      "  Number of functions evaluations: 63\n",
      "Running Baseline Attack on instance 352 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.196918\n",
      "  Number of iterations: 45\n",
      "  Number of functions evaluations: 46\n",
      "Running Baseline Attack on instance 384 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.188117\n",
      "  Number of iterations: 48\n",
      "  Number of functions evaluations: 49\n",
      "Running Baseline Attack on instance 416 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.200435\n",
      "  Number of iterations: 38\n",
      "  Number of functions evaluations: 39\n",
      "Running Baseline Attack on instance 448 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.180475\n",
      "  Number of iterations: 52\n",
      "  Number of functions evaluations: 53\n",
      "Running Baseline Attack on instance 480 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.187663\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n",
      "Running Baseline Attack on instance 512 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.198823\n",
      "  Number of iterations: 59\n",
      "  Number of functions evaluations: 60\n",
      "Running Baseline Attack on instance 544 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.182828\n",
      "  Number of iterations: 42\n",
      "  Number of functions evaluations: 43\n",
      "Running Baseline Attack on instance 576 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.186073\n",
      "  Number of iterations: 48\n",
      "  Number of functions evaluations: 49\n",
      "Running Baseline Attack on instance 608 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.195579\n",
      "  Number of iterations: 63\n",
      "  Number of functions evaluations: 64\n",
      "Running Baseline Attack on instance 640 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.184149\n",
      "  Number of iterations: 48\n",
      "  Number of functions evaluations: 49\n",
      "Running Baseline Attack on instance 672 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.195043\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n",
      "Running Baseline Attack on instance 704 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.193139\n",
      "  Number of iterations: 61\n",
      "  Number of functions evaluations: 62\n",
      "Running Baseline Attack on instance 736 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.203035\n",
      "  Number of iterations: 40\n",
      "  Number of functions evaluations: 41\n",
      "Running Baseline Attack on instance 768 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.192122\n",
      "  Number of iterations: 50\n",
      "  Number of functions evaluations: 51\n",
      "Running Baseline Attack on instance 800 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.201923\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 40\n",
      "Running Baseline Attack on instance 832 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.209096\n",
      "  Number of iterations: 48\n",
      "  Number of functions evaluations: 49\n",
      "Running Baseline Attack on instance 864 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.190221\n",
      "  Number of iterations: 50\n",
      "  Number of functions evaluations: 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 896 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.200670\n",
      "  Number of iterations: 51\n",
      "  Number of functions evaluations: 52\n",
      "Running Baseline Attack on instance 928 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.180258\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 40\n",
      "Running Baseline Attack on instance 960 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.177439\n",
      "  Number of iterations: 44\n",
      "  Number of functions evaluations: 45\n",
      "Running Baseline Attack on instance 992 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.164212\n",
      "  Number of iterations: 40\n",
      "  Number of functions evaluations: 41\n",
      "Running Baseline Attack on instance 1024 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.149829\n",
      "  Number of iterations: 37\n",
      "  Number of functions evaluations: 38\n",
      "Running Baseline Attack on instance 1056 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.188034\n",
      "  Number of iterations: 46\n",
      "  Number of functions evaluations: 47\n",
      "Running Baseline Attack on instance 1088 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.189601\n",
      "  Number of iterations: 42\n",
      "  Number of functions evaluations: 43\n",
      "Running Baseline Attack on instance 1120 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.190985\n",
      "  Number of iterations: 38\n",
      "  Number of functions evaluations: 39\n",
      "Running Baseline Attack on instance 1152 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.183664\n",
      "  Number of iterations: 34\n",
      "  Number of functions evaluations: 35\n",
      "Running Baseline Attack on instance 1184 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.160256\n",
      "  Number of iterations: 55\n",
      "  Number of functions evaluations: 56\n",
      "Running Baseline Attack on instance 1216 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.184955\n",
      "  Number of iterations: 69\n",
      "  Number of functions evaluations: 70\n",
      "Running Baseline Attack on instance 1248 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.177601\n",
      "  Number of iterations: 36\n",
      "  Number of functions evaluations: 37\n",
      "Running Baseline Attack on instance 1280 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.164679\n",
      "  Number of iterations: 42\n",
      "  Number of functions evaluations: 43\n",
      "Running Baseline Attack on instance 1312 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.168724\n",
      "  Number of iterations: 38\n",
      "  Number of functions evaluations: 39\n",
      "Running Baseline Attack on instance 1344 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.135476\n",
      "  Number of iterations: 30\n",
      "  Number of functions evaluations: 31\n",
      "Running Baseline Attack on instance 1376 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.147433\n",
      "  Number of iterations: 45\n",
      "  Number of functions evaluations: 46\n",
      "Running Baseline Attack on instance 1408 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.173545\n",
      "  Number of iterations: 57\n",
      "  Number of functions evaluations: 58\n",
      "Running Baseline Attack on instance 1440 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.186117\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 40\n",
      "Running Baseline Attack on instance 1472 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.174376\n",
      "  Number of iterations: 37\n",
      "  Number of functions evaluations: 38\n",
      "Running Baseline Attack on instance 1504 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.155325\n",
      "  Number of iterations: 40\n",
      "  Number of functions evaluations: 41\n",
      "Running Baseline Attack on instance 1536 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.176642\n",
      "  Number of iterations: 34\n",
      "  Number of functions evaluations: 35\n",
      "Running Baseline Attack on instance 1568 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.192329\n",
      "  Number of iterations: 33\n",
      "  Number of functions evaluations: 34\n",
      "Running Baseline Attack on instance 1600 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.166826\n",
      "  Number of iterations: 34\n",
      "  Number of functions evaluations: 35\n",
      "Running Baseline Attack on instance 1632 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.172681\n",
      "  Number of iterations: 32\n",
      "  Number of functions evaluations: 33\n",
      "Running Baseline Attack on instance 1664 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.194622\n",
      "  Number of iterations: 30\n",
      "  Number of functions evaluations: 31\n",
      "Running Baseline Attack on instance 1696 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.252798\n",
      "  Number of iterations: 38\n",
      "  Number of functions evaluations: 39\n",
      "Running Baseline Attack on instance 1728 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.196429\n",
      "  Number of iterations: 74\n",
      "  Number of functions evaluations: 75\n",
      "Running Baseline Attack on instance 1760 of 1888\n",
      "  Finding nn representation as target...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.202580\n",
      "  Number of iterations: 54\n",
      "  Number of functions evaluations: 55\n",
      "Running Baseline Attack on instance 1792 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.179952\n",
      "  Number of iterations: 40\n",
      "  Number of functions evaluations: 41\n",
      "Running Baseline Attack on instance 1824 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.167998\n",
      "  Number of iterations: 39\n",
      "  Number of functions evaluations: 40\n",
      "Running Baseline Attack on instance 1856 of 1888\n",
      "  Finding nn representation as target...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.148098\n",
      "  Number of iterations: 43\n",
      "  Number of functions evaluations: 44\n"
     ]
    }
   ],
   "source": [
    "X_adv = attack.attack(X_37_test, rep_37_test[0], y_37_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6350635593220338\n",
      "[7 7 3 ... 3 7 3]\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test, query, y_train)\n",
    "print(acc)\n",
    "print(np.argmax(p, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. AttackV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nn_l2(Q, X, k):\n",
    "    assert Q.shape[1:] == X.shape[1:]\n",
    "    nn = np.zeros((len(Q), k), dtype=np.int32)\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    for i, q in enumerate(Q):\n",
    "        ind = np.argsort(np.sum((X - q)**2, axis=axis))[:k]\n",
    "        nn[i] = ind\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackV3(object):\n",
    "    \n",
    "    def __init__(self, sess, model, get_rep, X, X_rep, y_X, \n",
    "                 pert_norm=np.inf, batch_size=1000, lr=1e-3, \n",
    "                 abort_early=True, init_const=1, pert_bound=0.3,\n",
    "                 min_dist=None, m=100, target_nn=38):\n",
    "        \"\"\"\n",
    "        X_rep must be normalized and flattened\n",
    "        m: (int) number of neighbors to consider\n",
    "        \"\"\"\n",
    "    \n",
    "        self.sess = sess\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.X_rep = X_rep\n",
    "        self.y_X = y_X\n",
    "        self.n_layers = len(X_rep)\n",
    "        self.batch_size = batch_size\n",
    "        self.abort_early = abort_early\n",
    "        self.init_const = init_const\n",
    "        self.pert_norm = pert_norm\n",
    "        self.pert_bound = pert_bound\n",
    "        if min_dist is None:\n",
    "            min_dist = [0.1]*self.n_layers\n",
    "        self.min_dist = min_dist\n",
    "        self.m = m\n",
    "        self.target_nn = target_nn\n",
    "        \n",
    "        assert self.n_layers == len(get_rep)\n",
    "        \n",
    "        input_ndim = X.ndim\n",
    "        input_axis = np.arange(1, input_ndim)\n",
    "        input_shape = (batch_size, ) + X.shape[1:]\n",
    "\n",
    "        \n",
    "        # =============== Set up variables and placeholders =============== #\n",
    "        # Objective variable\n",
    "        modifier = tf.Variable(np.zeros(input_shape), dtype=tf.float32)\n",
    "\n",
    "        # These are variables to be more efficient in sending data to tf\n",
    "        q_var = tf.Variable(np.zeros(input_shape), dtype=tf.float32, name='q_var')\n",
    "        x_var = []\n",
    "        for l in range(self.n_layers):\n",
    "            rep_shape = (batch_size, m, X_rep[l].shape[1])\n",
    "            x_var.append(tf.Variable(np.zeros(rep_shape), \n",
    "                                     dtype=tf.float32, \n",
    "                                     name='x_var_{}'.format(l)))\n",
    "        w_var = tf.Variable(np.zeros((batch_size, m, 1)), \n",
    "                            dtype=tf.float32, \n",
    "                            name='w_var_{}'.format(l))\n",
    "        const_var = tf.Variable(\n",
    "            np.zeros(batch_size), dtype=tf.float32, name='const_var')\n",
    "        steep_var = tf.Variable(\n",
    "            np.zeros((batch_size, 1, 1)), dtype=tf.float32, name='const_var')\n",
    "\n",
    "        # and here's what we use to assign them\n",
    "        self.assign_q = tf.placeholder(tf.float32, input_shape, name='assign_q')\n",
    "        self.assign_x = []\n",
    "        for l in range(self.n_layers):\n",
    "            rep_shape = (batch_size, m, X_rep[l].shape[1])\n",
    "            self.assign_x.append(tf.placeholder(tf.float32, \n",
    "                                                rep_shape, \n",
    "                                                name='assign_x_{}'.format(l)))\n",
    "        self.assign_w = tf.placeholder(tf.float32, \n",
    "                                       [batch_size, m, 1], \n",
    "                                       name='assign_w_{}'.format(l))\n",
    "        self.assign_const = tf.placeholder(\n",
    "            tf.float32, [batch_size], name='assign_const')\n",
    "        self.assign_steep = tf.placeholder(\n",
    "            tf.float32, [batch_size, 1, 1], name='assign_steep')\n",
    "\n",
    "        \n",
    "        # ================= Get reprentation tensor ================= #\n",
    "        # Clip to ensure pixel value is between 0 and 1\n",
    "        self.new_q = tf.clip_by_value(q_var + modifier, 0., 1.)\n",
    "        self.rep = []\n",
    "        for l in range(self.n_layers):\n",
    "            rep = get_rep[l](self.new_q)\n",
    "            rep = tf.reshape(rep, [batch_size, 1, -1])\n",
    "            rep = rep / tf.norm(rep, axis=2, keepdims=True)\n",
    "            self.rep.append(rep)\n",
    "\n",
    "        # L2 perturbation loss\n",
    "        l2dist = tf.reduce_sum(tf.square(modifier), input_axis)\n",
    "        self.l2dist = tf.maximum(0., l2dist - self.pert_bound**2)\n",
    "        \n",
    "        \n",
    "        # ================== Approximate NN loss ================== #\n",
    "        def sigmoid(x, a=1):\n",
    "            return 1/(1 + tf.exp(-a*x))\n",
    "        \n",
    "        self.nn_loss = 0\n",
    "        for l in range(self.n_layers):\n",
    "            dist = tf.norm(self.rep[l] - x_var[l], axis=2, keepdims=True)\n",
    "            self.nn_loss += tf.reduce_sum(\n",
    "                w_var * sigmoid(min_dist[l] - dist, steep_var), (1, 2))\n",
    "        \n",
    "        \n",
    "        # ==================== Setup optimizer ==================== #\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        if pert_norm == 2:\n",
    "            # For L-2 norm constraint, we use Adam optimizer with\n",
    "            # a penalty term\n",
    "            self.loss = tf.reduce_mean(const_var*self.nn_loss + self.l2dist)\n",
    "            optimizer = tf.train.AdamOptimizer(lr)\n",
    "            self.train_step = optimizer.minimize(self.loss, var_list=[modifier])\n",
    "        elif pert_norm == np.inf:\n",
    "            # For L-inf norm constraint, we use L-BFGS-B optimizer \n",
    "            # to provide correct bound, optimizer setup is moved to attack()\n",
    "            self.loss = tf.reduce_mean(self.nn_loss)\n",
    "            self.modifier = modifier\n",
    "        else:\n",
    "            raise ValueError('Invalid choice for perturbation norm!')\n",
    "            \n",
    "            \n",
    "        # DEBUG\n",
    "        self.dist = dist\n",
    "        self.rep_db = rep\n",
    "        self.gradient = tf.gradients(self.nn_loss, modifier)\n",
    "        print('rep: ', self.rep)\n",
    "        # dist: (batch_size, m, 1)\n",
    "        print('dist: ', dist)\n",
    "        # sigmoid: (batch_size, m, 1)\n",
    "        print('sigmoid: ', sigmoid(min_dist[l] - dist, steep_var))\n",
    "        # weights: (batch_size, m, 1)\n",
    "        print('weights: ', w_var * sigmoid(min_dist[l] - dist, steep_var))\n",
    "        # loss, nn_loss: (batch_size, )\n",
    "        print('loss: ', tf.reduce_sum(\n",
    "            w_var * sigmoid(min_dist[l] - dist, steep_var), (1, 2)))\n",
    "        print('nn_loss: ', self.nn_loss)\n",
    "        \n",
    "            \n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "\n",
    "        self.setup = []\n",
    "        self.setup.append(q_var.assign(self.assign_q))\n",
    "        self.setup.extend([x_var[l].assign(self.assign_x[l]) \n",
    "                           for l in range(self.n_layers)])\n",
    "        self.setup.append(w_var.assign(self.assign_w))\n",
    "        self.setup.append(steep_var.assign(self.assign_steep))\n",
    "        self.setup.append(const_var.assign(self.assign_const))\n",
    "        self.init = tf.variables_initializer(var_list=[modifier] + new_vars)\n",
    "        \n",
    "    def attack(self, Q, y_Q, bin_search_steps=5, max_iter=200):\n",
    "        r = []\n",
    "        for i in range(0, len(Q), self.batch_size):\n",
    "            print(\"Running Baseline Attack on instance {} of {}\".format(\n",
    "                i, len(Q)))\n",
    "            r.extend(self.attack_batch(Q[i:i + self.batch_size],\n",
    "                                       y_Q[i:i + self.batch_size],\n",
    "                                       bin_search_steps=bin_search_steps,\n",
    "                                       max_iter=max_iter))\n",
    "        return np.array(r)\n",
    "\n",
    "        \n",
    "    def attack_batch(self, Q, y_Q, bin_search_steps=5, max_iter=200):   \n",
    "        \n",
    "        # Find closest rep of different class\n",
    "        print(\"  Finding nn representation as target...\")\n",
    "        \n",
    "        # TODO: \n",
    "        # nn = find_nn_diff_class_l2(Q, y_Q, self.X, self.y_X, self.m)\n",
    "        nn = find_nn_l2(Q, self.X, self.m)\n",
    "        rep_m = [np.squeeze(rep[nn]) for rep in self.X_rep]\n",
    "        \n",
    "        # Get weights w\n",
    "        w = 2*(self.y_X[nn] == y_Q[:, np.newaxis]).astype(np.float32) - 1\n",
    "        print(np.mean(w == -1, axis=1))\n",
    "        \n",
    "        # Initialize steep\n",
    "        steep = np.ones((self.batch_size, 1, 1))\n",
    "        \n",
    "        # Find nn to target rep to save nn search time during optimization\n",
    "        # check_rep = find_nn(target_rep, self.X_rep, 100)\n",
    "        \n",
    "        # ============ Optimizing with L-inf norm constraints =========== #\n",
    "        # L-BFGS-B optimizer only needs to be called once\n",
    "        if self.pert_norm == np.inf:\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            const = np.ones(self.batch_size) * self.init_const\n",
    "            \n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            setup_dict = {self.assign_q: Q_batch,\n",
    "                          self.assign_w: w[:, :, np.newaxis],\n",
    "                          self.assign_const: const,\n",
    "                          self.assign_steep: steep}\n",
    "            for l in range(self.n_layers):\n",
    "                setup_dict[self.assign_x[l]] = rep_m[l]\n",
    "            self.sess.run(self.setup, feed_dict=setup_dict)\n",
    "            \n",
    "            # Set up variables bound and optimizer\n",
    "            upper_bound = np.minimum(self.pert_bound, 1 - Q_batch)\n",
    "            lower_bound = np.maximum(-self.pert_bound, -Q_batch)\n",
    "            var_to_bounds = {self.modifier: (lower_bound, upper_bound)}\n",
    "            optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                self.loss, \n",
    "                var_list=[self.modifier], \n",
    "                var_to_bounds=var_to_bounds, \n",
    "                method='L-BFGS-B')\n",
    "            \n",
    "            # Call optimizer\n",
    "            optimizer.minimize(self.sess)\n",
    "            return self.sess.run(self.new_q)\n",
    "            \n",
    "        # ============= Optimizing with L2 norm constraints ============ #\n",
    "        o_bestl2 = [1e9] * self.batch_size\n",
    "        o_bestadv = np.zeros_like(Q[:self.batch_size])\n",
    "        \n",
    "        # Set the lower and upper bounds\n",
    "        lower_bound = np.zeros(self.batch_size)\n",
    "        const = np.ones(self.batch_size) * self.init_const\n",
    "        upper_bound = np.ones(self.batch_size) * 1e9\n",
    "       \n",
    "        for outer_step in range(bin_search_steps):\n",
    "\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            \n",
    "            bestl2 = [1e9] * self.batch_size\n",
    "            bestadv = np.zeros_like(Q_batch)\n",
    "            print(\"  Binary search step {} of {}\".format(\n",
    "                outer_step, bin_search_steps))\n",
    "\n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            setup_dict = {self.assign_q: Q_batch,\n",
    "                          self.assign_w: w[:, :, np.newaxis],\n",
    "                          self.assign_const: const,\n",
    "                          self.assign_steep: steep}\n",
    "            for l in range(self.n_layers):\n",
    "                setup_dict[self.assign_x[l]] = rep_m[l]\n",
    "            self.sess.run(self.setup, feed_dict=setup_dict)\n",
    "\n",
    "            prev = 1e6\n",
    "            for iteration in range(max_iter):\n",
    "                # Take one step in optimization\n",
    "                _, l, l2s, dls, reps, qs = self.sess.run([self.train_step, \n",
    "                                                          self.loss, \n",
    "                                                          self.l2dist,\n",
    "                                                          self.nn_loss,\n",
    "                                                          self.rep, \n",
    "                                                          self.new_q])\n",
    "                # DEBUG\n",
    "#                 print(self.sess.run(self.dist))\n",
    "#                 grad = self.sess.run(self.gradient)\n",
    "#                 print(grad)\n",
    "#                 rep = self.sess.run(self.rep_db)\n",
    "#                 print(rep.shape)\n",
    "#                 print(np.sum(rep**2, axis=2))\n",
    "                \n",
    "                if iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    print((\"    Iteration {} of {}: loss={:.3g} l2={:.3g}\").format(\n",
    "                        iteration, max_iter, l, np.mean(l2s)))\n",
    "                \n",
    "                # Abort early if stop improving\n",
    "                if self.abort_early and iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    if l > prev * .9999:\n",
    "                        print(\"    Failed to make progress; stop early\")\n",
    "                        break\n",
    "                    prev = l\n",
    "                \n",
    "                # Check termination condition\n",
    "                # nn = find_nn(reps, self.X_rep, 1)\n",
    "                # y_pred = classify(nn, self.y_X)\n",
    "                # suc_ind = np.where(y_pred != y_Q)[0]\n",
    "                # suc_ind = np.where(dls <= 1e-1)[0]\n",
    "                if (iteration + 1) % 10 == 0:\n",
    "                    p, _ = dknn_acc(A, get_all_rep_nm(qs), y_Q, query, self.y_X)\n",
    "                    suc_ind = np.where(np.argmax(p, 1) != y_Q)[0]\n",
    "                    for ind in suc_ind:\n",
    "                        if l2s[ind] < bestl2[ind]:\n",
    "                            bestl2[ind] = l2s[ind]\n",
    "                            bestadv[ind] = qs[ind]\n",
    "                        \n",
    "            # Adjust const according to results\n",
    "            for e in range(self.batch_size):\n",
    "                if bestl2[e] < 1e9:\n",
    "                    # Success, divide const by two\n",
    "                    upper_bound[e] = min(upper_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    if bestl2[e] < o_bestl2[e]:\n",
    "                        o_bestl2[e] = bestl2[e]\n",
    "                        o_bestadv[e] = bestadv[e]\n",
    "                else:\n",
    "                    # Failure, either multiply by 10 if no solution found yet\n",
    "                    #          or do binary search with the known upper bound\n",
    "                    lower_bound[e] = max(lower_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    else:\n",
    "                        const[e] *= 10\n",
    "                        \n",
    "        return o_bestadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to approximate min_dist (epsilon) by calculating average distance \n",
    "# between queries and their 75th NN\n",
    "min_dist = []\n",
    "for l in range(4):\n",
    "#     nn = find_nn_l2(rep_test_nm[l], rep_train_nm[l], 75)\n",
    "    nn = query_nn(query[l], rep_test_nm[l], 75)\n",
    "    dist = np.sqrt(np.sum((rep_test_nm[l] - rep_train_nm[l][nn[:, -1]])**2, axis=1))\n",
    "    min_dist.append(np.mean(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist = [0.7484518915597577, 0.742514077896593, 0.5667317128548899, 0.19457440222463473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep:  [<tf.Tensor 'truediv_470:0' shape=(5, 1, 12544) dtype=float32>, <tf.Tensor 'truediv_471:0' shape=(5, 1, 6272) dtype=float32>, <tf.Tensor 'truediv_472:0' shape=(5, 1, 1152) dtype=float32>, <tf.Tensor 'truediv_473:0' shape=(5, 1, 10) dtype=float32>]\n",
      "dist:  Tensor(\"norm_327/Sqrt:0\", shape=(5, 500, 1), dtype=float32)\n",
      "sigmoid:  Tensor(\"truediv_478:0\", shape=(5, 500, 1), dtype=float32)\n",
      "weights:  Tensor(\"mul_549:0\", shape=(5, 500, 1), dtype=float32)\n",
      "loss:  Tensor(\"Sum_348:0\", shape=(5,), dtype=float32)\n",
      "nn_loss:  Tensor(\"add_558:0\", shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attack = AttackV3(sess, model, \n",
    "                  [l1_rep, l2_rep, l3_rep, l4_rep], \n",
    "                  X_train, rep_train_nm, y_train, \n",
    "                  pert_norm=np.inf,\n",
    "                  batch_size=5, \n",
    "                  min_dist=min_dist,\n",
    "                  pert_bound=0.3,\n",
    "                  m=500, \n",
    "                  target_nn=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 5\n",
      "  Finding nn representation as target...\n",
      "[0.002 0.006 0.35  0.144 0.078]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 453.059662\n",
      "  Number of iterations: 2081\n",
      "  Number of functions evaluations: 2106\n"
     ]
    }
   ],
   "source": [
    "X_adv = attack.attack(X_37_test[:5], y_37_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[6 6 6 0 0]\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test[:5], query, y_train)\n",
    "print(acc)\n",
    "print(np.argmax(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 4\n",
    "plt.imshow(X_37_test[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_adv[i,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep:  [<tf.Tensor 'truediv_481:0' shape=(5, 1, 12544) dtype=float32>, <tf.Tensor 'truediv_482:0' shape=(5, 1, 6272) dtype=float32>, <tf.Tensor 'truediv_483:0' shape=(5, 1, 1152) dtype=float32>, <tf.Tensor 'truediv_484:0' shape=(5, 1, 10) dtype=float32>]\n",
      "dist:  Tensor(\"norm_335/Sqrt:0\", shape=(5, 500, 1), dtype=float32)\n",
      "sigmoid:  Tensor(\"truediv_489:0\", shape=(5, 500, 1), dtype=float32)\n",
      "weights:  Tensor(\"mul_563:0\", shape=(5, 500, 1), dtype=float32)\n",
      "loss:  Tensor(\"Sum_354:0\", shape=(5,), dtype=float32)\n",
      "nn_loss:  Tensor(\"add_570:0\", shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attack = AttackV3(sess, model, \n",
    "                  [l1_rep, l2_rep, l3_rep, l4_rep], \n",
    "                  X_train, rep_train_nm, y_train, \n",
    "                  pert_norm=2,\n",
    "                  batch_size=5, \n",
    "                  min_dist=min_dist,\n",
    "                  pert_bound=0,\n",
    "                  m=500, \n",
    "                  target_nn=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 5\n",
      "  Finding nn representation as target...\n",
      "[0.002 0.006 0.35  0.144 0.078]\n",
      "  Binary search step 0 of 5\n",
      "    Iteration 0 of 200: loss=755 l2=0\n",
      "    Iteration 20 of 200: loss=743 l2=0.186\n",
      "    Iteration 40 of 200: loss=731 l2=0.659\n",
      "    Iteration 60 of 200: loss=717 l2=1.36\n",
      "    Iteration 80 of 200: loss=702 l2=2.31\n",
      "    Iteration 100 of 200: loss=684 l2=3.55\n",
      "    Iteration 120 of 200: loss=664 l2=5.07\n",
      "    Iteration 140 of 200: loss=644 l2=6.81\n",
      "    Iteration 160 of 200: loss=625 l2=8.67\n",
      "    Iteration 180 of 200: loss=608 l2=10.6\n",
      "  Binary search step 1 of 5\n",
      "    Iteration 0 of 200: loss=4.17e+03 l2=0\n",
      "    Iteration 20 of 200: loss=4.12e+03 l2=0.186\n",
      "    Iteration 40 of 200: loss=4.06e+03 l2=0.657\n",
      "    Iteration 60 of 200: loss=4e+03 l2=1.34\n",
      "    Iteration 80 of 200: loss=3.92e+03 l2=2.28\n",
      "    Iteration 100 of 200: loss=3.82e+03 l2=3.46\n",
      "    Iteration 120 of 200: loss=3.71e+03 l2=4.92\n",
      "    Iteration 140 of 200: loss=3.6e+03 l2=6.55\n",
      "    Iteration 160 of 200: loss=3.49e+03 l2=8.27\n",
      "    Iteration 180 of 200: loss=3.4e+03 l2=10.1\n",
      "  Binary search step 2 of 5\n",
      "    Iteration 0 of 200: loss=4e+04 l2=0\n",
      "    Iteration 20 of 200: loss=3.95e+04 l2=0.183\n",
      "    Iteration 40 of 200: loss=3.9e+04 l2=0.636\n",
      "    Iteration 60 of 200: loss=3.84e+04 l2=1.28\n",
      "    Iteration 80 of 200: loss=3.76e+04 l2=2.15\n",
      "    Iteration 100 of 200: loss=3.67e+04 l2=3.23\n",
      "    Iteration 120 of 200: loss=3.56e+04 l2=4.53\n",
      "    Iteration 140 of 200: loss=3.46e+04 l2=5.99\n",
      "    Iteration 160 of 200: loss=3.36e+04 l2=7.51\n",
      "    Iteration 180 of 200: loss=3.27e+04 l2=9.04\n",
      "  Binary search step 3 of 5\n",
      "    Iteration 0 of 200: loss=3.99e+05 l2=0\n",
      "    Iteration 20 of 200: loss=3.94e+05 l2=0.177\n",
      "    Iteration 40 of 200: loss=3.89e+05 l2=0.595\n",
      "    Iteration 60 of 200: loss=3.83e+05 l2=1.17\n",
      "    Iteration 80 of 200: loss=3.75e+05 l2=1.92\n",
      "    Iteration 100 of 200: loss=3.66e+05 l2=2.85\n",
      "    Iteration 120 of 200: loss=3.55e+05 l2=3.96\n",
      "    Iteration 140 of 200: loss=3.45e+05 l2=5.17\n",
      "    Iteration 160 of 200: loss=3.35e+05 l2=6.44\n",
      "    Iteration 180 of 200: loss=3.26e+05 l2=7.73\n",
      "  Binary search step 4 of 5\n",
      "    Iteration 0 of 200: loss=3.99e+06 l2=0\n",
      "    Failed to make progress; stop early\n"
     ]
    }
   ],
   "source": [
    "X_adv = attack.attack(X_37_test[:5], y_37_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test[:5], query, y_train)\n",
    "print(acc)\n",
    "print(np.argmax(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas, _ = dknn_classify(get_all_rep_nm(X_adv), query, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[75., 31., 72., 75., 65., 72., 69., 71., 72., 73.],\n",
       "        [75., 31., 72., 75., 65., 72., 69., 71., 72., 73.],\n",
       "        [73., 75., 75., 38., 75., 47., 74., 75., 68., 75.],\n",
       "        [75., 75., 75., 75., 75., 75., 75.,  1., 75., 74.],\n",
       "        [75., 75., 75., 16., 75., 67., 75., 72., 75., 70.]],\n",
       "\n",
       "       [[74., 74., 62., 56., 74., 67., 65., 65., 65., 73.],\n",
       "        [74., 74., 62., 56., 74., 67., 65., 65., 65., 73.],\n",
       "        [72., 75., 75., 34., 75., 47., 75., 75., 72., 75.],\n",
       "        [75., 75., 75., 75., 75., 75., 75.,  1., 75., 74.],\n",
       "        [75., 75., 75., 29., 75., 51., 75., 74., 75., 71.]],\n",
       "\n",
       "       [[75., 75., 75., 74., 75.,  1., 75., 75., 75., 75.],\n",
       "        [75., 75., 75., 74., 75.,  1., 75., 75., 75., 75.],\n",
       "        [74., 75., 75., 42., 75., 34., 75., 75., 75., 75.],\n",
       "        [75., 75., 75., 73., 75., 15., 75., 63., 75., 74.],\n",
       "        [75., 75., 75., 66., 75.,  9., 75., 75., 75., 75.]],\n",
       "\n",
       "       [[75., 75., 75., 75., 75., 70., 75., 75.,  5., 75.],\n",
       "        [75., 75., 75., 75., 75., 70., 75., 75.,  5., 75.],\n",
       "        [75., 75., 75., 70., 75., 28., 75., 75., 52., 75.],\n",
       "        [75., 75., 75., 74., 75.,  1., 75., 75., 75., 75.],\n",
       "        [75., 75., 75., 73., 75.,  2., 75., 75., 75., 75.]]])"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 4\n",
    "plt.imshow(X_37_test[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_adv[i,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.69212263, 8.73673037, 0.84017921, 2.39951935, 2.83094509])"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((X_37_test[:5] - X_adv)**2, (1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep:  [<tf.Tensor 'truediv:0' shape=(32, 1, 12544) dtype=float32>, <tf.Tensor 'truediv_1:0' shape=(32, 1, 6272) dtype=float32>, <tf.Tensor 'truediv_2:0' shape=(32, 1, 1152) dtype=float32>, <tf.Tensor 'truediv_3:0' shape=(32, 1, 10) dtype=float32>]\n",
      "dist:  Tensor(\"norm_7/Sqrt:0\", shape=(32, 500, 1), dtype=float32)\n",
      "sigmoid:  Tensor(\"truediv_8:0\", shape=(32, 500, 1), dtype=float32)\n",
      "weights:  Tensor(\"mul_10:0\", shape=(32, 500, 1), dtype=float32)\n",
      "loss:  Tensor(\"Sum_5:0\", shape=(32,), dtype=float32)\n",
      "nn_loss:  Tensor(\"add_8:0\", shape=(32,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attack = AttackV3(sess, model, \n",
    "                  [l1_rep, l2_rep, l3_rep, l4_rep], \n",
    "                  X_train, rep_train_nm, y_train, \n",
    "                  pert_norm=np.inf,\n",
    "                  batch_size=32, \n",
    "                  min_dist=min_dist,\n",
    "                  pert_bound=0.3,\n",
    "                  m=500, \n",
    "                  target_nn=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.002 0.006 0.35  0.144 0.078 0.06  0.016 0.018 0.7   0.222 0.028 0.616\n",
      " 0.182 0.086 0.006 0.268 0.114 0.018 0.696 0.26  0.006 0.206 0.136 0.136\n",
      " 0.712 0.288 0.228 0.272 0.644 0.2   0.038 0.328]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 303.337769\n",
      "  Number of iterations: 3978\n",
      "  Number of functions evaluations: 3992\n",
      "Running Baseline Attack on instance 32 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.132 0.286 0.116 0.172 0.828 0.924 0.12  0.666 0.014 0.174 0.002 0.112\n",
      " 0.256 0.21  0.49  0.888 0.024 0.24  0.004 0.046 0.164 0.442 0.262 0.338\n",
      " 0.242 0.182 0.374 0.126 0.142 0.042 0.38  0.016]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 237.400604\n",
      "  Number of iterations: 1529\n",
      "  Number of functions evaluations: 1549\n",
      "Running Baseline Attack on instance 64 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.172 0.804 0.734 0.178 0.188 0.94  0.06  0.082 0.142 0.092 0.012 0.532\n",
      " 0.004 0.054 0.086 0.04  0.048 0.558 0.264 0.062 0.338 0.958 0.33  0.088\n",
      " 0.106 0.    0.    0.348 0.492 0.068 0.578 0.408]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 218.490204\n",
      "  Number of iterations: 2943\n",
      "  Number of functions evaluations: 2954\n",
      "Running Baseline Attack on instance 96 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.23  0.158 0.604 0.282 0.338 0.97  0.002 0.11  0.378 0.056 0.04  0.022\n",
      " 0.29  0.856 0.086 0.058 0.036 0.144 0.492 0.06  0.002 0.89  0.008 0.034\n",
      " 0.26  0.006 0.08  0.408 0.218 0.896 0.188 0.002]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 240.123917\n",
      "  Number of iterations: 2950\n",
      "  Number of functions evaluations: 2964\n",
      "Running Baseline Attack on instance 128 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.126 0.116 0.22  0.856 0.052 0.204 0.634 0.4   0.04  0.124 0.036 0.67\n",
      " 0.318 0.164 0.398 0.15  0.092 0.022 0.046 0.44  0.256 0.076 0.808 0.082\n",
      " 0.036 0.07  0.052 0.01  0.062 0.004 0.014 0.414]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 305.763733\n",
      "  Number of iterations: 1877\n",
      "  Number of functions evaluations: 1895\n",
      "Running Baseline Attack on instance 160 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.064 0.216 0.312 0.126 0.204 0.106 0.112 0.03  0.088 0.01  0.568 0.132\n",
      " 0.336 0.322 0.788 0.08  0.012 0.008 0.026 0.054 0.84  0.088 0.592 0.004\n",
      " 0.782 0.286 0.542 0.504 0.252 0.776 0.352 0.456]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 206.146271\n",
      "  Number of iterations: 4681\n",
      "  Number of functions evaluations: 4693\n",
      "Running Baseline Attack on instance 192 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.108 0.228 0.124 0.582 0.134 0.016 0.212 0.988 0.088 0.402 0.964 0.14\n",
      " 0.164 0.214 0.046 0.562 0.54  0.77  0.11  0.632 0.114 0.002 0.024 0.054\n",
      " 0.006 0.576 0.562 0.666 0.27  0.026 0.516 0.814]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 132.181335\n",
      "  Number of iterations: 3802\n",
      "  Number of functions evaluations: 3815\n",
      "Running Baseline Attack on instance 224 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.242 0.022 0.028 0.102 0.154 0.38  0.422 0.03  0.034 0.686 0.022 0.882\n",
      " 0.014 0.742 0.626 0.232 0.976 0.282 0.418 0.098 0.986 0.134 0.096 0.008\n",
      " 0.924 0.05  0.402 0.196 0.41  0.286 0.044 0.47 ]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 134.364288\n",
      "  Number of iterations: 8098\n",
      "  Number of functions evaluations: 8140\n",
      "Running Baseline Attack on instance 256 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.014 0.41  0.296 0.488 0.18  0.202 0.024 0.008 0.    0.268 0.812 0.026\n",
      " 0.228 0.05  0.016 0.514 0.01  0.062 0.054 0.126 0.53  0.516 0.59  0.\n",
      " 0.002 0.14  0.348 0.172 0.146 0.05  0.156 0.764]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 295.391357\n",
      "  Number of iterations: 2034\n",
      "  Number of functions evaluations: 2052\n",
      "Running Baseline Attack on instance 288 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.3   0.05  0.098 0.258 0.004 0.036 0.044 0.444 0.072 0.498 0.124 0.438\n",
      " 0.03  0.162 0.2   0.72  0.046 0.192 0.802 0.618 0.112 0.118 0.16  0.022\n",
      " 0.164 0.56  0.046 0.49  0.996 0.008 0.118 0.008]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 250.047791\n",
      "  Number of iterations: 11455\n",
      "  Number of functions evaluations: 11490\n",
      "Running Baseline Attack on instance 320 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.184 0.03  0.03  0.884 0.942 0.632 0.766 0.114 0.046 0.01  0.804 0.012\n",
      " 0.25  0.796 0.954 0.354 0.302 0.172 0.036 0.08  0.082 0.196 0.002 0.272\n",
      " 0.07  0.23  0.216 0.002 0.058 0.004 0.022 0.164]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 200.510437\n",
      "  Number of iterations: 3083\n",
      "  Number of functions evaluations: 3096\n",
      "Running Baseline Attack on instance 352 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.532 0.442 0.21  0.092 0.    0.018 0.468 0.096 0.624 0.214 0.13  0.774\n",
      " 0.216 0.004 0.024 0.028 0.    0.518 0.028 0.    0.104 0.    0.046 0.18\n",
      " 0.19  0.104 0.148 0.66  0.92  0.062 0.764 0.33 ]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 259.219849\n",
      "  Number of iterations: 3480\n",
      "  Number of functions evaluations: 3495\n",
      "Running Baseline Attack on instance 384 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.754 0.004 0.04  0.018 0.174 0.272 0.996 0.1   0.812 0.09  0.18  0.018\n",
      " 0.318 0.206 0.03  0.324 0.438 0.968 0.226 0.048 0.06  0.092 0.012 0.144\n",
      " 0.256 0.214 0.002 0.5   0.    0.166 0.224 0.048]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 265.013306\n",
      "  Number of iterations: 4291\n",
      "  Number of functions evaluations: 4309\n",
      "Running Baseline Attack on instance 416 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.026 0.02  0.006 0.156 0.092 0.212 0.1   0.206 0.004 0.036 0.004 0.492\n",
      " 0.008 0.13  0.    0.274 0.236 0.222 0.014 0.028 0.608 0.23  0.228 0.134\n",
      " 0.15  0.916 0.012 0.166 0.026 0.526 0.06  0.148]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 363.231262\n",
      "  Number of iterations: 3984\n",
      "  Number of functions evaluations: 4004\n",
      "Running Baseline Attack on instance 448 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.168 0.124 0.052 0.002 0.282 0.002 0.064 0.05  0.386 0.    0.388 0.162\n",
      " 0.21  0.084 0.23  0.002 0.088 0.196 0.036 0.102 0.086 0.336 0.154 0.674\n",
      " 0.148 0.354 0.822 0.518 0.24  0.338 0.24  0.018]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "  Objective function value: 321.648560\n",
      "  Number of iterations: 3193\n",
      "  Number of functions evaluations: 3234\n",
      "Running Baseline Attack on instance 480 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.6   0.004 0.668 0.024 0.14  0.092 0.152 0.806 0.166 0.326 0.15  0.024\n",
      " 0.002 0.08  0.992 0.234 0.366 0.102 0.27  0.214 0.25  0.11  0.06  0.216\n",
      " 0.484 0.074 0.35  0.058 0.556 0.    0.168 0.436]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 238.747467\n",
      "  Number of iterations: 1674\n",
      "  Number of functions evaluations: 1694\n",
      "Running Baseline Attack on instance 512 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.896 0.644 0.356 0.084 0.752 0.238 0.3   0.07  0.392 0.138 0.804 0.308\n",
      " 0.01  0.104 0.39  0.276 0.592 0.502 0.008 0.    0.044 0.044 0.092 0.\n",
      " 0.494 0.372 0.016 0.254 0.002 0.286 0.146 0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "  Objective function value: 237.117310\n",
      "  Number of iterations: 5621\n",
      "  Number of functions evaluations: 5662\n",
      "Running Baseline Attack on instance 544 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.248 0.002 0.112 0.576 0.436 0.344 0.15  0.868 0.348 0.808 0.37  0.73\n",
      " 0.026 0.12  0.002 0.024 0.038 0.198 0.724 0.294 0.194 0.042 0.102 0.214\n",
      " 0.14  0.042 0.54  0.036 0.062 0.226 0.418 0.192]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 235.618835\n",
      "  Number of iterations: 2763\n",
      "  Number of functions evaluations: 2781\n",
      "Running Baseline Attack on instance 576 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.12  0.002 0.864 0.    0.016 0.074 0.082 0.304 0.25  0.162 0.362 0.048\n",
      " 0.352 0.112 0.06  0.492 0.806 0.472 0.102 0.246 0.396 0.004 0.148 0.18\n",
      " 0.964 0.388 0.672 0.01  0.006 0.812 0.894 0.03 ]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 179.510544\n",
      "  Number of iterations: 1240\n",
      "  Number of functions evaluations: 1255\n",
      "Running Baseline Attack on instance 608 of 1888\n",
      "  Finding nn representation as target...\n",
      "[0.034 0.212 0.532 0.354 0.074 0.482 0.044 0.046 0.926 0.654 0.084 0.25\n",
      " 0.896 0.544 0.232 0.244 0.204 0.352 0.026 0.016 0.136 0.498 0.298 0.002\n",
      " 0.004 0.656 0.104 0.002 0.916 0.084 0.204 0.052]\n"
     ]
    }
   ],
   "source": [
    "X_adv = attack.attack(X_37_test, y_37_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026483050847457626\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test, query, y_train)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/1888 [==============================] - 1s 465us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.7309036820621815, 0.0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_adv, y_37_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 4\n",
    "plt.imshow(X_37_test[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_adv[i,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AttackV4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackV4(object):\n",
    "    \n",
    "    def __init__(self, sess, model, get_rep, X, X_rep, y_X, \n",
    "                 pert_norm=np.inf, batch_size=1000, lr=1e-3, \n",
    "                 abort_early=True, init_const=1, pert_bound=0.3,\n",
    "                 min_dist=None, m=100, target_nn=38):\n",
    "        \"\"\"\n",
    "        X_rep must be normalized and flattened\n",
    "        m: (int) number of neighbors to consider\n",
    "        \"\"\"\n",
    "    \n",
    "        self.sess = sess\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.X_rep = X_rep\n",
    "        self.y_X = y_X\n",
    "        self.n_layers = len(X_rep)\n",
    "        self.batch_size = batch_size\n",
    "        self.abort_early = abort_early\n",
    "        self.init_const = init_const\n",
    "        self.pert_norm = pert_norm\n",
    "        self.pert_bound = pert_bound\n",
    "        # If min_dist is not given, assign arbritary number\n",
    "        if min_dist is None:\n",
    "            min_dist = [0.1]*self.n_layers\n",
    "        self.min_dist = min_dist\n",
    "        self.m = m\n",
    "        self.target_nn = target_nn\n",
    "        \n",
    "        assert self.n_layers == len(get_rep)\n",
    "        \n",
    "        input_ndim = X.ndim\n",
    "        input_axis = np.arange(1, input_ndim)\n",
    "        input_shape = (batch_size, ) + X.shape[1:]\n",
    "\n",
    "        \n",
    "        # =============== Set up variables and placeholders =============== #\n",
    "        # Objective variable\n",
    "        modifier = tf.Variable(np.zeros(input_shape), dtype=tf.float32)\n",
    "\n",
    "        # These are variables to be more efficient in sending data to tf\n",
    "        q_var = tf.Variable(np.zeros(input_shape), dtype=tf.float32, name='q_var')\n",
    "        x_var = []\n",
    "        for l in range(self.n_layers):\n",
    "            rep_shape = (batch_size, m, X_rep[l].shape[1])\n",
    "            x_var.append(tf.Variable(np.zeros(rep_shape), \n",
    "                                     dtype=tf.float32, \n",
    "                                     name='x_var_{}'.format(l)))\n",
    "        w_var = tf.Variable(np.zeros((batch_size, m, 1)), \n",
    "                            dtype=tf.float32, \n",
    "                            name='w_var_{}'.format(l))\n",
    "        const_var = tf.Variable(\n",
    "            np.zeros(batch_size), dtype=tf.float32, name='const_var')\n",
    "        steep_var = tf.Variable(\n",
    "            np.zeros((batch_size, 1, 1)), dtype=tf.float32, name='const_var')\n",
    "\n",
    "        # and here's what we use to assign them\n",
    "        self.assign_q = tf.placeholder(tf.float32, input_shape, name='assign_q')\n",
    "        self.assign_x = []\n",
    "        for l in range(self.n_layers):\n",
    "            rep_shape = (batch_size, m, X_rep[l].shape[1])\n",
    "            self.assign_x.append(tf.placeholder(tf.float32, \n",
    "                                                rep_shape, \n",
    "                                                name='assign_x_{}'.format(l)))\n",
    "        self.assign_w = tf.placeholder(\n",
    "            tf.float32, [batch_size, m, 1], name='assign_w_{}'.format(l))\n",
    "        self.assign_const = tf.placeholder(\n",
    "            tf.float32, [batch_size], name='assign_const')\n",
    "        self.assign_steep = tf.placeholder(\n",
    "            tf.float32, [batch_size, 1, 1], name='assign_steep')\n",
    "\n",
    "        \n",
    "        # ================= Get reprentation tensor ================= #\n",
    "        # Clip to ensure pixel value is between 0 and 1\n",
    "        self.new_q = tf.clip_by_value(q_var + modifier, 0., 1.)\n",
    "        self.rep = []\n",
    "        for l in range(self.n_layers):\n",
    "            rep = get_rep[l](self.new_q)\n",
    "            rep = tf.reshape(rep, [batch_size, 1, -1])\n",
    "            rep = rep / tf.norm(rep, axis=2, keepdims=True)\n",
    "            self.rep.append(rep)\n",
    "\n",
    "        # L2 perturbation loss\n",
    "        l2dist = tf.reduce_sum(tf.square(modifier), input_axis)\n",
    "        self.l2dist = tf.maximum(0., l2dist - self.pert_bound**2)\n",
    "        \n",
    "        \n",
    "        # ================== Approximate NN loss ================== #\n",
    "        def sigmoid(x, a=1):\n",
    "            return 1/(1 + tf.exp(-a*x))\n",
    "        \n",
    "        self.nn_loss = 0\n",
    "        for l in range(self.n_layers):\n",
    "            dist = tf.norm(self.rep[l] - x_var[l], axis=2, keepdims=True)\n",
    "            self.nn_loss += tf.reduce_sum(\n",
    "                w_var * sigmoid(min_dist[l] - dist, steep_var), (1, 2))\n",
    "        \n",
    "        \n",
    "        # ==================== Setup optimizer ==================== #\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        if pert_norm == 2:\n",
    "            # For L-2 norm constraint, we use Adam optimizer with\n",
    "            # a penalty term\n",
    "            self.loss = tf.reduce_mean(const_var*self.nn_loss + self.l2dist)\n",
    "            optimizer = tf.train.AdamOptimizer(lr)\n",
    "            self.train_step = optimizer.minimize(self.loss, var_list=[modifier])\n",
    "        elif pert_norm == np.inf:\n",
    "            # For L-inf norm constraint, we use L-BFGS-B optimizer \n",
    "            # to provide correct bound, optimizer setup is moved to attack()\n",
    "            self.loss = tf.reduce_mean(self.nn_loss)\n",
    "            self.modifier = modifier\n",
    "        else:\n",
    "            raise ValueError('Invalid choice for perturbation norm!')\n",
    "            \n",
    "            \n",
    "        # DEBUG\n",
    "        self.dist = dist\n",
    "        self.rep_db = rep\n",
    "        self.gradient = tf.gradients(self.nn_loss, modifier)\n",
    "        print('rep: ', self.rep)\n",
    "        # dist: (batch_size, m, 1)\n",
    "        print('dist: ', dist)\n",
    "        # sigmoid: (batch_size, m, 1)\n",
    "        print('sigmoid: ', sigmoid(min_dist[l] - dist, steep_var))\n",
    "        # weights: (batch_size, m, 1)\n",
    "        print('weights: ', w_var * sigmoid(min_dist[l] - dist, steep_var))\n",
    "        # loss, nn_loss: (batch_size, )\n",
    "        print('loss: ', tf.reduce_sum(\n",
    "            w_var * sigmoid(min_dist[l] - dist, steep_var), (1, 2)))\n",
    "        print('nn_loss: ', self.nn_loss)\n",
    "        \n",
    "            \n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "\n",
    "        self.setup = []\n",
    "        self.setup.append(q_var.assign(self.assign_q))\n",
    "        self.setup.extend([x_var[l].assign(self.assign_x[l]) \n",
    "                           for l in range(self.n_layers)])\n",
    "        self.setup.append(w_var.assign(self.assign_w))\n",
    "        self.setup.append(steep_var.assign(self.assign_steep))\n",
    "        self.setup.append(const_var.assign(self.assign_const))\n",
    "        self.init = tf.variables_initializer(var_list=[modifier] + new_vars)\n",
    "        \n",
    "        \n",
    "    def attack(self, Q, y_Q, bin_search_steps=5, max_iter=200):\n",
    "        r = []\n",
    "        for i in range(0, len(Q), self.batch_size):\n",
    "            print(\"Running Baseline Attack on instance {} of {}\".format(\n",
    "                i, len(Q)))\n",
    "            r.extend(self.attack_batch(Q[i:i + self.batch_size],\n",
    "                                       y_Q[i:i + self.batch_size],\n",
    "                                       bin_search_steps=bin_search_steps,\n",
    "                                       max_iter=max_iter))\n",
    "        return np.array(r)\n",
    "\n",
    "        \n",
    "    def attack_batch(self, Q, y_Q, bin_search_steps=5, max_iter=200):   \n",
    "        \n",
    "        # Find closest rep of different class\n",
    "        print(\"  Finding nn representation as target...\")\n",
    "        \n",
    "        # TODO: \n",
    "        # nn = find_nn_diff_class_l2(Q, y_Q, self.X, self.y_X, self.m)\n",
    "        # nn = find_nn_l2(Q, self.X, self.m)\n",
    "        nn = find_2nd_nn_l2(Q, self.X, self.m)\n",
    "        \n",
    "        rep_m = [np.squeeze(rep[nn]) for rep in self.X_rep]\n",
    "        \n",
    "        # Get weights w\n",
    "        w = 2*(self.y_X[nn] == y_Q[:, np.newaxis]).astype(np.float32) - 1\n",
    "        print(np.mean(w == -1, axis=1))\n",
    "        \n",
    "        # Initialize steep\n",
    "        steep = np.ones((self.batch_size, 1, 1))\n",
    "        \n",
    "        # Find nn to target rep to save nn search time during optimization\n",
    "        # check_rep = find_nn(target_rep, self.X_rep, 100)\n",
    "        \n",
    "        # ============ Optimizing with L-inf norm constraints =========== #\n",
    "        # L-BFGS-B optimizer only needs to be called once\n",
    "        if self.pert_norm == np.inf:\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            const = np.ones(self.batch_size) * self.init_const\n",
    "            \n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            setup_dict = {self.assign_q: Q_batch,\n",
    "                          self.assign_w: w[:, :, np.newaxis],\n",
    "                          self.assign_const: const,\n",
    "                          self.assign_steep: steep}\n",
    "            for l in range(self.n_layers):\n",
    "                setup_dict[self.assign_x[l]] = rep_m[l]\n",
    "            self.sess.run(self.setup, feed_dict=setup_dict)\n",
    "            \n",
    "            # Set up variables bound and optimizer\n",
    "            upper_bound = np.minimum(self.pert_bound, 1 - Q_batch)\n",
    "            lower_bound = np.maximum(-self.pert_bound, -Q_batch)\n",
    "            var_to_bounds = {self.modifier: (lower_bound, upper_bound)}\n",
    "            optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                self.loss, \n",
    "                var_list=[self.modifier], \n",
    "                var_to_bounds=var_to_bounds, \n",
    "                method='L-BFGS-B')\n",
    "            \n",
    "            # Call optimizer\n",
    "            optimizer.minimize(self.sess)\n",
    "            return self.sess.run(self.new_q)\n",
    "            \n",
    "        # ============= Optimizing with L2 norm constraints ============ #\n",
    "        o_bestl2 = [1e9] * self.batch_size\n",
    "        o_bestadv = np.zeros_like(Q[:self.batch_size])\n",
    "        \n",
    "        # Set the lower and upper bounds\n",
    "        lower_bound = np.zeros(self.batch_size)\n",
    "        const = np.ones(self.batch_size) * self.init_const\n",
    "        upper_bound = np.ones(self.batch_size) * 1e9\n",
    "       \n",
    "        for outer_step in range(bin_search_steps):\n",
    "\n",
    "            self.sess.run(self.init)\n",
    "            Q_batch = Q[:self.batch_size]\n",
    "            \n",
    "            bestl2 = [1e9] * self.batch_size\n",
    "            bestadv = np.zeros_like(Q_batch)\n",
    "            print(\"  Binary search step {} of {}\".format(\n",
    "                outer_step, bin_search_steps))\n",
    "\n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            setup_dict = {self.assign_q: Q_batch,\n",
    "                          self.assign_w: w[:, :, np.newaxis],\n",
    "                          self.assign_const: const,\n",
    "                          self.assign_steep: steep}\n",
    "            for l in range(self.n_layers):\n",
    "                setup_dict[self.assign_x[l]] = rep_m[l]\n",
    "            self.sess.run(self.setup, feed_dict=setup_dict)\n",
    "\n",
    "            prev = 1e6\n",
    "            for iteration in range(max_iter):\n",
    "                # Take one step in optimization\n",
    "                _, l, l2s, dls, reps, qs = self.sess.run([self.train_step, \n",
    "                                                          self.loss, \n",
    "                                                          self.l2dist,\n",
    "                                                          self.nn_loss,\n",
    "                                                          self.rep, \n",
    "                                                          self.new_q])\n",
    "                # DEBUG\n",
    "#                 print(self.sess.run(self.dist))\n",
    "#                 grad = self.sess.run(self.gradient)\n",
    "#                 print(grad)\n",
    "#                 rep = self.sess.run(self.rep_db)\n",
    "#                 print(rep.shape)\n",
    "#                 print(np.sum(rep**2, axis=2))\n",
    "                \n",
    "                if iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    print((\"    Iteration {} of {}: loss={:.3g} l2={:.3g}\").format(\n",
    "                        iteration, max_iter, l, np.mean(l2s)))\n",
    "                \n",
    "                # Abort early if stop improving\n",
    "                if self.abort_early and iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    if l > prev * .9999:\n",
    "                        print(\"    Failed to make progress; stop early\")\n",
    "                        break\n",
    "                    prev = l\n",
    "                \n",
    "                # Check termination condition\n",
    "                # nn = find_nn(reps, self.X_rep, 1)\n",
    "                # y_pred = classify(nn, self.y_X)\n",
    "                # suc_ind = np.where(y_pred != y_Q)[0]\n",
    "                # suc_ind = np.where(dls <= 1e-1)[0]\n",
    "                if (iteration + 1) % 10 == 0:\n",
    "                    p, _ = dknn_acc(A, get_all_rep_nm(qs), y_Q, query, self.y_X)\n",
    "                    suc_ind = np.where(np.argmax(p, 1) != y_Q)[0]\n",
    "                    for ind in suc_ind:\n",
    "                        if l2s[ind] < bestl2[ind]:\n",
    "                            bestl2[ind] = l2s[ind]\n",
    "                            bestadv[ind] = qs[ind]\n",
    "                        \n",
    "            # Adjust const according to results\n",
    "            for e in range(self.batch_size):\n",
    "                if bestl2[e] < 1e9:\n",
    "                    # Success, divide const by two\n",
    "                    upper_bound[e] = min(upper_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    if bestl2[e] < o_bestl2[e]:\n",
    "                        o_bestl2[e] = bestl2[e]\n",
    "                        o_bestadv[e] = bestadv[e]\n",
    "                else:\n",
    "                    # Failure, either multiply by 10 if no solution found yet\n",
    "                    #          or do binary search with the known upper bound\n",
    "                    lower_bound[e] = max(lower_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    else:\n",
    "                        const[e] *= 10\n",
    "                        \n",
    "        return o_bestadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2nd_nn_l2(Q, y_Q, X, y_X, k):\n",
    "    assert Q.shape[1:] == X.shape[1:]\n",
    "    nn = np.zeros((len(Q), k), dtype=np.int32)\n",
    "    axis = tuple(np.arange(1, X.ndim, dtype=np.int32))\n",
    "    for i, q in enumerate(Q):\n",
    "        dist = np.sum((X - q)**2, axis=axis)\n",
    "        ind = np.argsort(dist)\n",
    "        mean_dist = np.zeros((10,))\n",
    "        for j in range(10):\n",
    "            ind_j = ind[y_X[ind] == j]\n",
    "            dist_j = dist[ind_j][:k]\n",
    "            mean_dist[j] = np.mean(dist_j)\n",
    "        ind_dist = np.argsort(mean_dist)\n",
    "        if ind_dist[0] == y_Q[i]:\n",
    "            nn[i] = ind[y_X[ind] == ind_dist[1]][:k]\n",
    "        else:\n",
    "            nn[i] = ind[y_X[ind] == ind_dist[0]][:k]\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep:  [<tf.Tensor 'truediv_22:0' shape=(5, 1, 12544) dtype=float32>, <tf.Tensor 'truediv_23:0' shape=(5, 1, 6272) dtype=float32>, <tf.Tensor 'truediv_24:0' shape=(5, 1, 1152) dtype=float32>, <tf.Tensor 'truediv_25:0' shape=(5, 1, 10) dtype=float32>]\n",
      "dist:  Tensor(\"norm_23/Sqrt:0\", shape=(5, 500, 1), dtype=float32)\n",
      "sigmoid:  Tensor(\"truediv_30:0\", shape=(5, 500, 1), dtype=float32)\n",
      "weights:  Tensor(\"mul_36:0\", shape=(5, 500, 1), dtype=float32)\n",
      "loss:  Tensor(\"Sum_17:0\", shape=(5,), dtype=float32)\n",
      "nn_loss:  Tensor(\"add_32:0\", shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attack = AttackV4(sess, model, \n",
    "                  [l1_rep, l2_rep, l3_rep, l4_rep], \n",
    "                  X_train, rep_train_nm, y_train, \n",
    "                  pert_norm=np.inf,\n",
    "                  batch_size=5, \n",
    "                  min_dist=[0.1, 0.1, 0.1, 0.1],\n",
    "                  pert_bound=0.3,\n",
    "                  m=500, \n",
    "                  target_nn=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 5\n",
      "  Finding nn representation as target...\n",
      "[1. 1. 1. 1. 1.]\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: -732.149109\n",
      "  Number of iterations: 259\n",
      "  Number of functions evaluations: 276\n"
     ]
    }
   ],
   "source": [
    "X_adv = attack.attack(X_37_test[:5], y_37_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[9 9 5 9 5]\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test[:5], query, y_train)\n",
    "print(acc)\n",
    "print(np.argmax(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.08666667, 0.1       , 0.26133333, 0.132     ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(p, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16666667],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00133333, 0.        , 0.08666667],\n",
       "       [0.        , 0.        , 0.        , 0.00133333, 0.        ,\n",
       "        0.1       , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26133333],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.132     , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "plt.imshow(X_37_test[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_adv[i,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[7 7 3 7 3]\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_37_test[:5]), y_37_test[:5], query, y_train)\n",
    "print(acc)\n",
    "print(np.argmax(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.044     , 0.        ,\n",
       "        0.00266667, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AttackV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackV5(object):\n",
    "    \n",
    "    def __init__(self, sess, model, get_rep, X, X_rep, y_X, \n",
    "                 pert_norm=np.inf, batch_size=1000, lr=1e-3, \n",
    "                 abort_early=True, init_const=1, pert_bound=0.3,\n",
    "                 min_dist=None, m=100, target_nn=38):\n",
    "        \"\"\"\n",
    "        X_rep must be normalized and flattened\n",
    "        m: (int) number of neighbors to consider\n",
    "        \"\"\"\n",
    "    \n",
    "        self.sess = sess\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.X_rep = X_rep\n",
    "        self.y_X = y_X\n",
    "        self.n_layers = len(X_rep)\n",
    "        self.batch_size = batch_size\n",
    "        self.abort_early = abort_early\n",
    "        self.init_const = init_const\n",
    "        self.pert_norm = pert_norm\n",
    "        self.pert_bound = pert_bound\n",
    "        # If min_dist is not given, assign arbritary number\n",
    "        if min_dist is None:\n",
    "            min_dist = [0.1]*self.n_layers\n",
    "        self.min_dist = min_dist\n",
    "        self.m = m\n",
    "        self.target_nn = target_nn\n",
    "        \n",
    "        assert self.n_layers == len(get_rep)\n",
    "        \n",
    "        input_ndim = X.ndim\n",
    "        input_axis = np.arange(1, input_ndim)\n",
    "        input_shape = (batch_size, ) + X.shape[1:]\n",
    "\n",
    "        \n",
    "        # =============== Set up variables and placeholders =============== #\n",
    "        # Objective variable\n",
    "        modifier = tf.Variable(np.zeros(input_shape), dtype=tf.float32)\n",
    "\n",
    "        # These are variables to be more efficient in sending data to tf\n",
    "        q_var = tf.Variable(np.zeros(input_shape), dtype=tf.float32, name='q_var')\n",
    "        x_var = []\n",
    "        for l in range(self.n_layers):\n",
    "            rep_shape = (batch_size, m, X_rep[l].shape[1])\n",
    "            x_var.append(tf.Variable(np.zeros(rep_shape), \n",
    "                                     dtype=tf.float32, \n",
    "                                     name='x_var_{}'.format(l)))\n",
    "        w_var = tf.Variable(np.zeros((batch_size, m, 1)), \n",
    "                            dtype=tf.float32, \n",
    "                            name='w_var_{}'.format(l))\n",
    "        const_var = tf.Variable(\n",
    "            np.zeros(batch_size), dtype=tf.float32, name='const_var')\n",
    "        steep_var = tf.Variable(\n",
    "            np.zeros((batch_size, 1, 1)), dtype=tf.float32, name='const_var')\n",
    "        clipmin_var = tf.Variable(\n",
    "            np.zeros(input_shape), dtype=tf.float32, name='clipmin_var')\n",
    "        clipmax_var = tf.Variable(\n",
    "            np.zeros(input_shape), dtype=tf.float32, name='clipmax_var')\n",
    "\n",
    "        # and here's what we use to assign them\n",
    "        self.assign_q = tf.placeholder(tf.float32, input_shape, name='assign_q')\n",
    "        self.assign_x = []\n",
    "        for l in range(self.n_layers):\n",
    "            rep_shape = (batch_size, m, X_rep[l].shape[1])\n",
    "            self.assign_x.append(tf.placeholder(tf.float32, \n",
    "                                                rep_shape, \n",
    "                                                name='assign_x_{}'.format(l)))\n",
    "        self.assign_w = tf.placeholder(\n",
    "            tf.float32, [batch_size, m, 1], name='assign_w_{}'.format(l))\n",
    "        self.assign_const = tf.placeholder(\n",
    "            tf.float32, [batch_size], name='assign_const')\n",
    "        self.assign_steep = tf.placeholder(\n",
    "            tf.float32, [batch_size, 1, 1], name='assign_steep')\n",
    "        self.assign_clipmin = tf.placeholder(\n",
    "            tf.float32, input_shape, name='assign_clipmin')\n",
    "        self.assign_clipmax = tf.placeholder(\n",
    "            tf.float32, input_shape, name='assign_clipmax')\n",
    "\n",
    "        \n",
    "        # ================= Get reprentation tensor ================= #\n",
    "        # Clip to ensure pixel value is between 0 and 1\n",
    "        self.new_q = (tf.tanh(modifier + q_var) + 1) / 2\n",
    "        self.new_q = self.new_q * (clipmax_var - clipmin_var) + clipmin_var\n",
    "        # Distance to the input data\n",
    "        orig = (tf.tanh(q_var) + 1) / \\\n",
    "            2 * (clipmax_var - clipmin_var) + clipmin_var\n",
    "        self.rep = []\n",
    "        for l in range(self.n_layers):\n",
    "            rep = get_rep[l](self.new_q)\n",
    "            rep = tf.reshape(rep, [batch_size, 1, -1])\n",
    "            rep = rep / tf.norm(rep, axis=2, keepdims=True)\n",
    "            self.rep.append(rep)\n",
    "\n",
    "        # L2 perturbation loss\n",
    "        l2dist = tf.reduce_sum(tf.square(self.new_q - orig), input_axis)\n",
    "        self.l2dist = tf.maximum(0., l2dist - self.pert_bound**2)\n",
    "        \n",
    "        \n",
    "        # ================== Approximate NN loss ================== #\n",
    "        def sigmoid(x, a=1):\n",
    "            return 1/(1 + tf.exp(-a*x))\n",
    "        \n",
    "        self.nn_loss = 0\n",
    "        for l in range(self.n_layers):\n",
    "            dist = tf.norm(self.rep[l] - x_var[l], axis=2, keepdims=True)\n",
    "            self.nn_loss += tf.reduce_sum(\n",
    "                w_var * sigmoid(min_dist[l] - dist, steep_var), (1, 2))\n",
    "        \n",
    "        \n",
    "        # ==================== Setup optimizer ==================== #\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        if pert_norm == 2 or pert_norm == np.inf:\n",
    "            # For L-2 norm constraint, we use a penalty term\n",
    "            self.loss = tf.reduce_mean(const_var*self.nn_loss + self.l2dist)\n",
    "        elif pert_norm == np.inf:\n",
    "            # For L-inf norm constraint, we do not use penalty term as\n",
    "            # change of variable provides box constraint\n",
    "            self.loss = tf.reduce_mean(self.nn_loss)\n",
    "        else:\n",
    "            raise ValueError('Invalid choice for perturbation norm!')\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "        self.train_step = optimizer.minimize(self.loss, var_list=[modifier])  \n",
    "            \n",
    "        # DEBUG\n",
    "        self.dist = dist\n",
    "        self.rep_db = rep\n",
    "        self.gradient = tf.gradients(self.nn_loss, modifier)\n",
    "        print('rep: ', self.rep)\n",
    "        # dist: (batch_size, m, 1)\n",
    "        print('dist: ', dist)\n",
    "        # sigmoid: (batch_size, m, 1)\n",
    "        print('sigmoid: ', sigmoid(min_dist[l] - dist, steep_var))\n",
    "        # weights: (batch_size, m, 1)\n",
    "        print('weights: ', w_var * sigmoid(min_dist[l] - dist, steep_var))\n",
    "        # loss, nn_loss: (batch_size, )\n",
    "        print('loss: ', tf.reduce_sum(\n",
    "            w_var * sigmoid(min_dist[l] - dist, steep_var), (1, 2)))\n",
    "        print('nn_loss: ', self.nn_loss)\n",
    "        \n",
    "            \n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "\n",
    "        self.setup = []\n",
    "        self.setup.append(q_var.assign(self.assign_q))\n",
    "        self.setup.extend([x_var[l].assign(self.assign_x[l]) \n",
    "                           for l in range(self.n_layers)])\n",
    "        self.setup.append(w_var.assign(self.assign_w))\n",
    "        self.setup.append(steep_var.assign(self.assign_steep))\n",
    "        self.setup.append(const_var.assign(self.assign_const))\n",
    "        self.setup.append(clipmin_var.assign(self.assign_clipmin))\n",
    "        self.setup.append(clipmax_var.assign(self.assign_clipmax))\n",
    "        self.init = tf.variables_initializer(var_list=[modifier] + new_vars)\n",
    "        \n",
    "        \n",
    "    def attack(self, Q, y_Q, bin_search_steps=5, max_iter=200, \n",
    "               rnd_start=0):\n",
    "        r = []\n",
    "        for i in range(0, len(Q), self.batch_size):\n",
    "            print(\"Running Baseline Attack on instance {} of {}\".format(\n",
    "                i, len(Q)))\n",
    "            t1 = timeit.default_timer()\n",
    "            Q_batch = Q[i:i + self.batch_size]\n",
    "            y_batch = y_Q[i:i + self.batch_size]\n",
    "            real_len = Q_batch.shape[0]\n",
    "            if real_len != self.batch_size:\n",
    "                pad_Q = ((0, self.batch_size - real_len), (0, 0), (0, 0), (0, 0))\n",
    "                pad_y = ((0, self.batch_size - real_len))\n",
    "                Q_batch = np.pad(Q_batch, pad_Q, 'constant')\n",
    "                y_batch = np.pad(y_batch, pad_y, 'constant')\n",
    "            r.extend(self.attack_batch(Q_batch,\n",
    "                                       y_batch,\n",
    "                                       bin_search_steps=bin_search_steps,\n",
    "                                       max_iter=max_iter,\n",
    "                                       rnd_start=rnd_start))\n",
    "            t2 = timeit.default_timer()\n",
    "            print(\"Time this batch: {:.0f}s\".format(t2 - t1))\n",
    "        return np.array(r)\n",
    "\n",
    "        \n",
    "    def attack_batch(self, Q, y_Q, bin_search_steps=5, max_iter=200,\n",
    "                     rnd_start=0):   \n",
    "        \n",
    "        # Find closest rep of different class\n",
    "        print(\"  Finding nn representation as target...\")\n",
    "        \n",
    "        # TODO: \n",
    "        # nn = find_nn_diff_class_l2(Q, y_Q, self.X, self.y_X, self.m)\n",
    "        # nn = find_nn_l2(Q, self.X, self.m)\n",
    "        nn = find_2nd_nn_l2(Q, y_Q, self.X, self.y_X, self.m)\n",
    "        \n",
    "        rep_m = [np.squeeze(rep[nn]) for rep in self.X_rep]\n",
    "        \n",
    "        # Get weights w\n",
    "        w = 2*(self.y_X[nn] == y_Q[:, np.newaxis]).astype(np.float32) - 1\n",
    "        print(np.mean(w == -1, axis=1))\n",
    "        \n",
    "        # Initialize steep\n",
    "        steep = np.ones((self.batch_size, 1, 1))\n",
    "        \n",
    "        # Find nn to target rep to save nn search time during optimization\n",
    "        # check_rep = find_nn(target_rep, self.X_rep, 100)\n",
    "        \n",
    "        o_bestl2 = [1e9] * self.batch_size\n",
    "        o_bestadv = np.zeros_like(Q[:self.batch_size])\n",
    "        \n",
    "        # Set the lower and upper bounds\n",
    "        lower_bound = np.zeros(self.batch_size)\n",
    "        const = np.ones(self.batch_size) * self.init_const\n",
    "        upper_bound = np.ones(self.batch_size) * 1e9\n",
    "       \n",
    "        for outer_step in range(bin_search_steps):\n",
    "            \n",
    "            noise = rnd_start * np.random.rand(*Q.shape)\n",
    "            Q_tanh = np.clip(Q + noise, 0., 1.)\n",
    "\n",
    "            # Calculate bound with L-inf norm constraints\n",
    "            if self.pert_norm == np.inf:\n",
    "                # Re-scale instances to be within range [x-d, x+d]\n",
    "                # for d is pert_bound\n",
    "                clipmin = np.clip(Q_tanh - self.pert_bound, 0., 1.)\n",
    "                clipmax = np.clip(Q_tanh + self.pert_bound, 0., 1.)\n",
    "\n",
    "            # Calculate bound with L2 norm constraints\n",
    "            elif self.pert_norm == 2:\n",
    "            # Re-scale instances to be within range [0, 1]\n",
    "                clipmin = np.zeros_like(Q_tanh)\n",
    "                clipmax = np.ones_like(Q_tanh)\n",
    "            \n",
    "            Q_tanh = (Q_tanh - clipmin) / (clipmax - clipmin)\n",
    "            Q_tanh = (Q_tanh * 2) - 1\n",
    "            Q_tanh = np.arctanh(Q_tanh * .999999)\n",
    "            Q_batch = Q_tanh[:self.batch_size]\n",
    "            \n",
    "            bestl2 = [1e9] * self.batch_size\n",
    "            bestadv = np.zeros_like(Q_batch)\n",
    "            print(\"  Binary search step {} of {}\".format(\n",
    "                outer_step, bin_search_steps))\n",
    "            \n",
    "            # Set the variables so that we don't have to send them over again\n",
    "            self.sess.run(self.init)\n",
    "            setup_dict = {self.assign_q: Q_batch,\n",
    "                          self.assign_w: w[:, :, np.newaxis],\n",
    "                          self.assign_const: const,\n",
    "                          self.assign_steep: steep,\n",
    "                          self.assign_clipmin: clipmin,\n",
    "                          self.assign_clipmax: clipmax}\n",
    "            for l in range(self.n_layers):\n",
    "                setup_dict[self.assign_x[l]] = rep_m[l]\n",
    "            self.sess.run(self.setup, feed_dict=setup_dict)\n",
    "\n",
    "            prev = 1e6\n",
    "            for iteration in range(max_iter):\n",
    "                # Take one step in optimization\n",
    "                _, l, l2s, qs = self.sess.run([self.train_step, \n",
    "                                               self.loss, \n",
    "                                               self.l2dist,\n",
    "                                               self.new_q])\n",
    "                # DEBUG\n",
    "#                 print(self.sess.run(self.dist))\n",
    "#                 grad = self.sess.run(self.gradient)\n",
    "#                 print(grad)\n",
    "#                 print(np.max(qs[0]))\n",
    "#                 print(np.min(qs[0]))\n",
    "#                 rep = self.sess.run(self.rep_db)\n",
    "#                 print(rep.shape)\n",
    "#                 print(np.sum(rep**2, axis=2))\n",
    "                \n",
    "                if iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    print((\"    Iteration {} of {}: loss={:.3g} l2={:.3g}\").format(\n",
    "                        iteration, max_iter, l, np.mean(l2s)))\n",
    "                \n",
    "                # Abort early if stop improving\n",
    "                if self.abort_early and iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    if l > prev * .9999:\n",
    "                        print(\"    Failed to make progress; stop early\")\n",
    "                        break\n",
    "                    prev = l\n",
    "                \n",
    "                # Check success of adversarial examples\n",
    "                if iteration % ((max_iter // 10) or 1) == 0:\n",
    "                    p, _ = dknn_acc(A, get_all_rep_nm(qs), y_Q, query, self.y_X)\n",
    "                    suc_ind = np.where(np.argmax(p, 1) != y_Q)[0]\n",
    "                    for ind in suc_ind:\n",
    "                        if l2s[ind] < bestl2[ind]:\n",
    "                            bestl2[ind] = l2s[ind]\n",
    "                            bestadv[ind] = qs[ind]\n",
    "                        \n",
    "            # Adjust const according to results\n",
    "            for e in range(self.batch_size):\n",
    "                if bestl2[e] < 1e9:\n",
    "                    # Success, divide const by two\n",
    "                    upper_bound[e] = min(upper_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    if bestl2[e] < o_bestl2[e]:\n",
    "                        o_bestl2[e] = bestl2[e]\n",
    "                        o_bestadv[e] = bestadv[e]\n",
    "                else:\n",
    "                    # Failure, either multiply by 10 if no solution found yet\n",
    "                    #          or do binary search with the known upper bound\n",
    "                    lower_bound[e] = max(lower_bound[e], const[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        const[e] = (lower_bound[e] + upper_bound[e]) / 2\n",
    "                    else:\n",
    "                        const[e] *= 10\n",
    "        \n",
    "        # Also save unsuccessful samples\n",
    "        ind = np.where(o_bestl2 == 1e9)[0]\n",
    "        o_bestadv[ind] = qs[ind]\n",
    "\n",
    "        return o_bestadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep:  [<tf.Tensor 'truediv_15:0' shape=(80, 1, 12544) dtype=float32>, <tf.Tensor 'truediv_16:0' shape=(80, 1, 6272) dtype=float32>, <tf.Tensor 'truediv_17:0' shape=(80, 1, 1152) dtype=float32>, <tf.Tensor 'truediv_18:0' shape=(80, 1, 10) dtype=float32>]\n",
      "dist:  Tensor(\"norm_15/Sqrt:0\", shape=(80, 500, 1), dtype=float32)\n",
      "sigmoid:  Tensor(\"truediv_23:0\", shape=(80, 500, 1), dtype=float32)\n",
      "weights:  Tensor(\"mul_29:0\", shape=(80, 500, 1), dtype=float32)\n",
      "loss:  Tensor(\"Sum_11:0\", shape=(80,), dtype=float32)\n",
      "nn_loss:  Tensor(\"add_29:0\", shape=(80,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attack = AttackV5(sess, model, \n",
    "                  [l1_rep, l2_rep, l3_rep, l4_rep], \n",
    "                  X_train, rep_train_nm, y_train, \n",
    "                  pert_norm=2,\n",
    "                  batch_size=80, \n",
    "                  lr=1e-1,\n",
    "                  min_dist=min_dist,\n",
    "                  pert_bound=0.,\n",
    "                  m=500, \n",
    "                  target_nn=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 1888\n",
      "  Finding nn representation as target...\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  Binary search step 0 of 5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[80,500,12544] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Assign_19 = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=false, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_var_0_3, _arg_assign_x_0_1_0_6/_2311)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Assign_19/_2321 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Assign_19\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Assign_19', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-f79a1529055a>\", line 10, in <module>\n    target_nn=38)\n  File \"<ipython-input-22-b9e6d3f2e52a>\", line 147, in __init__\n    for l in range(self.n_layers)])\n  File \"<ipython-input-22-b9e6d3f2e52a>\", line 147, in <listcomp>\n    for l in range(self.n_layers)])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 645, in assign\n    return state_ops.assign(self._variable, value, use_locking=use_locking)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[80,500,12544] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Assign_19 = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=false, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_var_0_3, _arg_assign_x_0_1_0_6/_2311)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Assign_19/_2321 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Assign_19\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[80,500,12544] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Assign_19 = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=false, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_var_0_3, _arg_assign_x_0_1_0_6/_2311)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Assign_19/_2321 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Assign_19\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2c9ba588144e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_37_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_37_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-b9e6d3f2e52a>\u001b[0m in \u001b[0;36mattack\u001b[0;34m(self, Q, y_Q, bin_search_steps, max_iter, rnd_start)\u001b[0m\n\u001b[1;32m    173\u001b[0m                                        \u001b[0mbin_search_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbin_search_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                                        \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                                        rnd_start=rnd_start))\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time this batch: {:.0f}s\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b9e6d3f2e52a>\u001b[0m in \u001b[0;36mattack_batch\u001b[0;34m(self, Q, y_Q, bin_search_steps, max_iter, rnd_start)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0msetup_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrep_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msetup_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[80,500,12544] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Assign_19 = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=false, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_var_0_3, _arg_assign_x_0_1_0_6/_2311)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Assign_19/_2321 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Assign_19\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Assign_19', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-f79a1529055a>\", line 10, in <module>\n    target_nn=38)\n  File \"<ipython-input-22-b9e6d3f2e52a>\", line 147, in __init__\n    for l in range(self.n_layers)])\n  File \"<ipython-input-22-b9e6d3f2e52a>\", line 147, in <listcomp>\n    for l in range(self.n_layers)])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 645, in assign\n    return state_ops.assign(self._variable, value, use_locking=use_locking)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[80,500,12544] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Assign_19 = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=false, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_var_0_3, _arg_assign_x_0_1_0_6/_2311)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Assign_19/_2321 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_54_Assign_19\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "X_adv = attack.attack(X_37_test, y_37_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[9 9 5 9 5]\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test[:5], query, y_train)\n",
    "print(acc)\n",
    "print(np.argmax(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 3\n",
    "plt.imshow(X_37_test[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_adv[i,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep:  [<tf.Tensor 'truediv_89:0' shape=(5, 1, 12544) dtype=float32>, <tf.Tensor 'truediv_90:0' shape=(5, 1, 6272) dtype=float32>, <tf.Tensor 'truediv_91:0' shape=(5, 1, 1152) dtype=float32>, <tf.Tensor 'truediv_92:0' shape=(5, 1, 10) dtype=float32>]\n",
      "dist:  Tensor(\"norm_67/Sqrt:0\", shape=(5, 500, 1), dtype=float32)\n",
      "sigmoid:  Tensor(\"truediv_97:0\", shape=(5, 500, 1), dtype=float32)\n",
      "weights:  Tensor(\"mul_113:0\", shape=(5, 500, 1), dtype=float32)\n",
      "loss:  Tensor(\"Sum_47:0\", shape=(5,), dtype=float32)\n",
      "nn_loss:  Tensor(\"add_112:0\", shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attack = AttackV5(sess, model, \n",
    "                  [l1_rep, l2_rep, l3_rep, l4_rep], \n",
    "                  X_train, rep_train_nm, y_train, \n",
    "                  pert_norm=np.inf,\n",
    "                  batch_size=5, \n",
    "                  lr=1e-3,\n",
    "                  min_dist=min_dist,\n",
    "                  pert_bound=0.3,\n",
    "                  m=500, \n",
    "                  target_nn=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Attack on instance 0 of 5\n",
      "  Finding nn representation as target...\n",
      "[1. 1. 1. 1. 1.]\n",
      "  Binary search step 0 of 5\n",
      "    Iteration 0 of 200: loss=-784 l2=0\n",
      "    Iteration 20 of 200: loss=-784 l2=0\n",
      "    Iteration 40 of 200: loss=-785 l2=0\n",
      "    Iteration 60 of 200: loss=-786 l2=0\n",
      "    Iteration 80 of 200: loss=-787 l2=0\n",
      "    Iteration 100 of 200: loss=-787 l2=0\n",
      "    Iteration 120 of 200: loss=-788 l2=3.6e-05\n",
      "    Iteration 140 of 200: loss=-789 l2=0.00627\n",
      "    Iteration 160 of 200: loss=-789 l2=0.0278\n",
      "    Iteration 180 of 200: loss=-790 l2=0.0549\n",
      "  Binary search step 1 of 5\n",
      "    Iteration 0 of 200: loss=-7.84e+03 l2=0\n",
      "    Iteration 20 of 200: loss=-7.84e+03 l2=0\n",
      "    Iteration 40 of 200: loss=-7.85e+03 l2=0\n",
      "    Iteration 60 of 200: loss=-7.86e+03 l2=0\n",
      "    Iteration 80 of 200: loss=-7.87e+03 l2=0\n",
      "    Iteration 100 of 200: loss=-7.87e+03 l2=0\n",
      "    Iteration 120 of 200: loss=-7.88e+03 l2=3.6e-05\n",
      "    Iteration 140 of 200: loss=-7.89e+03 l2=0.00659\n",
      "    Iteration 160 of 200: loss=-7.89e+03 l2=0.0294\n",
      "    Iteration 180 of 200: loss=-7.9e+03 l2=0.059\n",
      "  Binary search step 2 of 5\n",
      "    Iteration 0 of 200: loss=-7.84e+04 l2=0\n",
      "    Iteration 20 of 200: loss=-7.84e+04 l2=0\n",
      "    Iteration 40 of 200: loss=-7.85e+04 l2=0\n",
      "    Iteration 60 of 200: loss=-7.86e+04 l2=0\n",
      "    Iteration 80 of 200: loss=-7.87e+04 l2=0\n",
      "    Iteration 100 of 200: loss=-7.87e+04 l2=0\n",
      "    Iteration 120 of 200: loss=-7.88e+04 l2=3.6e-05\n",
      "    Iteration 140 of 200: loss=-7.89e+04 l2=0.00662\n",
      "    Iteration 160 of 200: loss=-7.89e+04 l2=0.0296\n",
      "    Iteration 180 of 200: loss=-7.9e+04 l2=0.0595\n",
      "  Binary search step 3 of 5\n",
      "    Iteration 0 of 200: loss=-7.84e+05 l2=0\n",
      "    Iteration 20 of 200: loss=-7.84e+05 l2=0\n",
      "    Iteration 40 of 200: loss=-7.85e+05 l2=0\n",
      "    Iteration 60 of 200: loss=-7.86e+05 l2=0\n",
      "    Iteration 80 of 200: loss=-7.87e+05 l2=0\n",
      "    Iteration 100 of 200: loss=-7.87e+05 l2=0\n",
      "    Iteration 120 of 200: loss=-7.88e+05 l2=3.6e-05\n",
      "    Iteration 140 of 200: loss=-7.89e+05 l2=0.00662\n",
      "    Iteration 160 of 200: loss=-7.89e+05 l2=0.0296\n",
      "    Iteration 180 of 200: loss=-7.9e+05 l2=0.0595\n",
      "  Binary search step 4 of 5\n",
      "    Iteration 0 of 200: loss=-7.84e+06 l2=0\n",
      "    Iteration 20 of 200: loss=-7.84e+06 l2=0\n",
      "    Iteration 40 of 200: loss=-7.85e+06 l2=0\n",
      "    Iteration 60 of 200: loss=-7.86e+06 l2=0\n",
      "    Iteration 80 of 200: loss=-7.87e+06 l2=0\n",
      "    Iteration 100 of 200: loss=-7.87e+06 l2=0\n",
      "    Iteration 120 of 200: loss=-7.88e+06 l2=3.6e-05\n",
      "    Iteration 140 of 200: loss=-7.89e+06 l2=0.00662\n",
      "    Iteration 160 of 200: loss=-7.89e+06 l2=0.0296\n",
      "    Iteration 180 of 200: loss=-7.9e+06 l2=0.0595\n"
     ]
    }
   ],
   "source": [
    "X_adv = attack.attack(X_37_test[:5], y_37_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "p, acc = dknn_acc(A, get_all_rep_nm(X_adv), y_37_test[:5], query, y_train)\n",
    "print(acc)\n",
    "print(np.argmax(p, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "plt.imshow(X_37_test[i,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_adv[i,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4\n"
     ]
    }
   ],
   "source": [
    "print(\"a{:.0f}\".format(3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (np.pad(X_train[0:3], ((0, 1), (0, 0), (0, 0), (0, 0)),'constant', constant_values=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.24705882352941"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
